
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [0 历史和原理概述](#0-历史和原理概述)
* [1 初始化工作队列](#1-初始化工作队列)
	* [1.1 工作任务struct work\_struct](#11-工作任务struct-work_struct)
	* [1.2 工作线程struct worker](#12-工作线程struct-worker)
	* [1.3 工作线程池struct worker\_pool](#13-工作线程池struct-worker_pool)
	* [1.4 连接workqueue(工作队列)和worker\-pool(工作线程池)的桥梁struct pool\_workqueue](#14-连接workqueue工作队列和worker-pool工作线程池的桥梁struct-pool_workqueue)
	* [1.5 工作队列struct workqueue\_struct](#15-工作队列struct-workqueue_struct)
	* [1.6 数据结构关系图](#16-数据结构关系图)
	* [1.7 系统初始化几个默认的workqueue](#17-系统初始化几个默认的workqueue)
		* [1.7.1 create\_worker()创建工作线程](#171-create_worker创建工作线程)
* [2 创建工作队列workqueue](#2-创建工作队列workqueue)
	* [2.1 \_\_alloc\_workqueue\_key创建工作队列](#21-__alloc_workqueue_key创建工作队列)
		* [2.1.1 pool\_workqueue分配以及初始化函数alloc\_and\_link\_pwqs()](#211-pool_workqueue分配以及初始化函数alloc_and_link_pwqs)
			* [2.1.1.1 BOUND类型的workqueue](#2111-bound类型的workqueue)
			* [2.1.1.2 ORDERED类型和UNBOUND类型的workqueue](#2112-ordered类型和unbound类型的workqueue)
* [3 调度一个work](#3-调度一个work)
	* [3.1 初始化一个work](#31-初始化一个work)
	* [3.2 schedule\_work()调度work](#32-schedule_work调度work)
	* [3.3 工作线程处理函数worker\_thread()](#33-工作线程处理函数worker_thread)
* [4 取消一个work](#4-取消一个work)
* [5 和调度器的交互](#5-和调度器的交互)
* [6 小结](#6-小结)
	* [6.1 背景和原理](#61-背景和原理)
	* [6.2 数据结构](#62-数据结构)

<!-- /code_chunk_output -->


思考题:

- workqueue是运行在中断上下文，还是进程上下文？其回调函数允许睡眠吗？
- 旧版本(Linux 2.6.25)的 workqueue机制在实际过程中遇到了哪些问题和挑战？
- CMWQ机制如何动态管理工作线程池的线程呢？
- 如果有多个work挂入一个工作线程中执行，当某个work的回调函数执行了阻塞操作，那么剩下的work该怎么办？

# 0 历史和原理概述

工作队列机制(workqueue)是除了软中断和tasklet以外最常用的一种下半部机制. 工作队列的**基本原理**是把**work(需要推迟执行的函数**)交由一个**内核线程**来执行，它总是在**进程上下文**中执行. 工作队列的优点是利用**进程上下文**来执行**中断下半部操作**，因此工作队列允许**重新调度**和**睡眠**，是异步执行的**进程上下文**，另外它还能解决**软中断**和**tasklet**执行时间过长导致**系统实时性下降**等问题. 

当驱动程序或者内核子系统在进程上下文中有异步执行的工作任务时，可以使用**work item**来描述工作任务，包括该工作任务的执行回调函数，**把work item添加到一个队列**中，然后**一个内核线程**会去执行这个**工作任务的回调函数**. 这里**work item被称为工作**，**队列被称为workqueue**，即工作队列，**内核线程被称为worker**. 

工作队列最早是在Linux 2.5.x内核开发期间被引入的机制，早期的工作队列的设计比较简单，由**多线程(Multi threaded，每个CPU默认一个工作线程**)和**单线程(Single threaded, 用户可以自行创建工作线程**)组成. 在长期测试中发现如下问题:

- **内核线程数量太多**. 虽然系统中有默认的一套工作线程(kevents)，但是有很多驱动和子系统喜欢自行创建工作线程，例如调用create\_workqueue()函数，这样在大型系统(CPU数量比较多的机器)中可能内核启动结束之后就耗尽了系统PID资源. 
- **并发性比较差**. Multi threaded的工作线程和CPU是一一绑定的，例如CPU0上的某个工作线程有A 、B 和 C 三个work. 假设执行work A上回调函数时发生了睡眠和调度，CPU0就会调度出去执行其他的进程，对 于 B 和 C 来说，它们只能等待CPU0重新调度执行该工作线程，尽管其他CPU比较空闲，也没有办法迁移到其他CPU上执行. 
- **死锁问题**. 系统有一个默认的工作队列kevents, 如果有很多work运行在默认的工作队列kevents上，并且它们有一些数据上依赖关系，那么很有可能会产生死锁. 解决办法是为每一个有可能产生死锁的work创建一个专职的工作线程，这样又回到问题1了. 

为此社区专家Tejun Heo在Linux 2.6.36中提出了一套解决方案**concurrency\-managed workqueues(CMWQ**). 

执行**work任务的线程**称为**worker**或**工作线程**. **工作线程**会**串行化地执行**挂入到队列中**所有的work**. 如果队列中**没有work**, 那么该**工作线程**就会变成**idle状态**. 

为了管理众多**工作线程**，CMWQ提出了**工作线程池(worker\-pool**)概念，worker\-pool有**两种**，一是**BOUND类型**的，可以理解为**Per\-CPU类型**，每个CPU都有worker\-pool; 另一种是**UNBOUND类型**的，即不和具体CPU绑定. 这**两种worker\-pool**都会定义**两个线程池**，一个给**普通优先级的work**使用，另一个给**高优先级的work**使用. 这些工作线程池中的**线程数量**是**动态分配**和管理的，而不是固定的. 当**工作线程睡眠**时，会去检查是否需要唤醒更多的工作线程，如有需要，会去**唤醒同一个工作线程池中idle状态**的工作线程. 

# 1 初始化工作队列

## 1.1 工作任务struct work\_struct

**workqueue**机制**最小的调度单元是work item**, 有的书中称为工作任务，由struct work\_struct数据结构来抽象和描述，本章简称为work或工作任务. 

```c
[include/linux/workqueue.h]
struct work_struct {
	atomic_long_t data;
	struct list_head entry;
	work_func_t func;
};
```

struct work\_struct数据结构定义比较简单. 

- data成员包括**两部分**，**低比特位部分**是work的**标志位**，**剩余的比特位**通常用于存放**上一次运行的worker\_pool**的**ID号**或**pool\_workqueue的指针**,存放的内容由**WORK\_STRUCT\_PWQ标志位来决定**. 
- func是工作任务的处理函数
- entry用于把**work挂到其他队列**上. 

## 1.2 工作线程struct worker

**work**运行在**内核线程**中，这个**内核线程在代码中被称为worker**, 类似流水线中的工人，work类似工人的工作，本章简称为**工作线程或worker**. 

**工作线程**用**struct worker**数据结构来描述: 

```c
[kernel/workqueue_internal.h]
struct worker {
	/* on idle list while idle, on busy hash table while busy */
	union {
		struct list_head	entry;	/* L: while idle */
		struct hlist_node	hentry;	/* L: while busy */
	};

	struct work_struct	    *current_work;	/* L: work being processed */
	work_func_t		        current_func;	/* L: current_work's fn */
	struct pool_workqueue	*current_pwq;   /* L: current_work's pwq */
	struct list_head	    scheduled;	    /* L: scheduled works */
    struct list_head	    node;		    /* A: anchored at pool->workers */
						                    /* A: runs through worker->node */
	struct task_struct	    *task;		    /* I: worker task */
	struct worker_pool	    *pool;		    /* I: the associated pool */
	int			            id;		        /* I: worker id */
    ...
};
```

- current\_work: 当前**正在处理的work**. 
- current\_func: 当前**正在执行的work回调函数**. 
- current\_pwq: 当前**work所属的pool\_workqueue**. 
- scheduled: 所有被调度并正**准备执行的work都挂入该链表**中. 
- task: 该**工作线程**的task\_struct数据结构. 
- pool: 该工作线程所属的**worker\_pool**. 
- id: 工作线程的**ID号**. 
- node: 可以把该worker挂入到**worker\_pool\->workers链表**中. 

## 1.3 工作线程池struct worker\_pool

CMWQ提出了**工作线程池**概念，代码中使用struct worker\_pool数据结构来抽象和描述，本章简称worker\-pool或者工作线程池. 

简化后的**struct worker\_pool**数据结构如下: 

```c
[kernel/workqueue.c]
struct worker_pool {
	spinlock_t		lock;		/* the pool lock */
	int			    cpu;		/* I: the associated cpu */
	int			    node;		/* I: the associated node ID */
	int			    id;		    /* I: pool ID */
	unsigned int	flags;		/* X: flags */

	struct list_head	worklist;	/* L: list of pending works */
	int			        nr_workers;	/* L: total number of workers */
	int			        nr_idle;	/* L: currently idle ones */

	struct list_head	idle_list;	/* X: list of idle workers */
	struct list_head	workers;	/* A: attached workers */
	struct workqueue_attrs	*attrs;		/* I: worker attributes */
	atomic_t		nr_running ____cacheline_aligned_in_smp;
	struct rcu_head		rcu;
	...
} ____cacheline_aligned_in_smp;
```

- lock: 用于**保护worker\-pool的自旋锁**. 
- cpu: 对应**BOUND类型**的**workqueue**来说，cpu表示**绑定的CPU ID**, 对应**UNBOUND类型**，该**值为\-1**. 
- node: 对于**UNBOUND类型的workqueue**，node表示该**worker\-pool所属内存节点的ID**编号. 
- id: 该**worker\-pool的ID号**. 
- worklist: **pending状态**的**work**会挂入**该链表**中. 
- nr\_workers: **工作线程的数量**. 
- nr\_idle: 处于**idle状态**的**工作线程的数量**. 
- idle\_list: 处于**idle状态**的**工作线程(！！！**)会挂入**该链表**中. 
- workers: 该worker\-pool管理的**工作线程**会挂入**该链表**中. 
- attrs: **工作线程的属性**. 
- nr\_running: **统计计数**，用于管理**worker**的**创建和销毁**，表示**正在运行中的worker数量**. 在**进程调度器**中**唤醒进程时(try\_to\_wake\_up**())，**其他CPU**有可能会**同时访问该成员**，该成员**频繁在多核之间读写**，因此让**该成员独占一个缓冲行(！！！**)，避免**多核CPU**在**读写该成员**时引发其他临近的成员“颠簸”现象，这也是所谓的“**缓存行伪共享**”的问题. 
- rcu: RCU锁. 

**worker\-pool是Per\-CPU**概念，每个CPU都有worker\-pool, 准确来说**每个CPU有两个worker\-pool**, 一个用于**普通优先级的工作线程**，另一个用于**高优先级的工作线程**. 

```c
[kernel/workqueue.c]
/* the per-cpu worker pools */
static DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS],
				     cpu_worker_pools);
```

## 1.4 连接workqueue(工作队列)和worker\-pool(工作线程池)的桥梁struct pool\_workqueue

CMWQ还定义了一个**pool\_workqueue**的数据结构，它是**连接workqueue和worker\-pool的枢纽**. 

```c
[kernel/workqueue.c]
struct pool_workqueue {
	struct worker_pool	    *pool;		/* I: the associated pool */
	struct workqueue_struct *wq;		/* I: the owning workqueue */
	int			            nr_active;	/* L: nr of active works */
	int			            max_active;	/* L: max active works */
	struct list_head	    delayed_works;	/* L: delayed works */
	struct rcu_head		    rcu;
	...
} __aligned(1 << WORK_STRUCT_FLAG_BITS);
```

其中，**WORK\_STRUCT\_FLAG\_BITS为8**, 因此pool\_workqueue数据结构是按照**256Byte对齐**的，这样方便把该**数据结构指针的bit[8:31]位存放到work\->data**中，work\->data字段的**低8位**用于存放一些**标志位**，见set\_work\_pwq()和get\_work\_pwq()函数. 

- pool: 指向**worker\-pool指针**. 
- wq: 指向**所属的工作队列**. 
- nr\_active: **活跃的work数量**. 
- max\_active: **活跃的work最大数量**. 
- delayed\_works: 链表头，被**延迟执行的works可以挂入该链表**. 
- rcu: rcu锁. 

## 1.5 工作队列struct workqueue\_struct

系统中**所有的工作队列**，包括系统**默认的工作队列**，例如system\_wq或system\_highpri\_wq等，以及驱动开发者新创建的工作队列，它们**共享一组worker\-pool**. 而对于**BOUND类型的工作队列**，**每个CPU**只有**两个工作线程池**，**每个工作线程池**可以和**多个workqueue**对应，**每个workqueue**也**只能对应这几个工作线程池**. 

**工作队列**由struct **workqueue\_struct**数据结构来描述: 

```c
[kernel/workqueue.c]
struct workqueue_struct {
	struct list_head	pwqs;		/* WR: all pwqs of this wq */
	struct list_head	list;		/* PL: list of all workqueues */

	struct list_head	maydays;	/* MD: pwqs requesting rescue */
	struct worker		*rescuer;	/* I: rescue worker */

	struct workqueue_attrs	*unbound_attrs;	/* WQ: only for unbound wqs */
	struct pool_workqueue	*dfl_pwq;	/* WQ: only for unbound wqs */

	char			name[WQ_NAME_LEN]; /* I: workqueue name */

	/* hot fields used during command issue, aligned to cacheline */
	unsigned int		flags ____cacheline_aligned; /* WQ: WQ_* flags */
	struct pool_workqueue __percpu *cpu_pwqs; /* I: per-cpu pwqs */
	...
};
```

- pwqs: **所有的pool\-workqueue**数据结构都**挂入链表**中. 
- list: **链表节点**. 系统定义一个**全局的链表workqueues**，**所有的workqueue**挂入**该链表**. 
- maydays: **所有rescue状态**下的**pool\-workqueue**数据结构**挂入该链表**. 
- rescuer: **rescue内核线程**. **内存紧张**时**创建新的工作线程**可能会失败，如果**创建workqueue**时设置了**WQ\_MEM\_RECLAIM**标志位，那么**rescuer线程会接管这种情况**. 
- unbound attrs: **UNBOUND类型属性**. 
- dfl\_pwq: 指向**UNBOUND类型的pool\_workqueue**.
- name: 该**workqueue的名字**. 
- flags: 标志位经常被**不同CPU访问**，因此要和**cache line对齐**. 标志位包括WQ\_UNBOUND、WQ\_HIGHPRI、WQ\_FREEZABLE等. 
- cpu\_pwqs: 指向**Per\-CPU类型**的**pool workqueue**. 

## 1.6 数据结构关系图

**一个work挂入workqueue**中，最终还要**通过worker\-pool**中的**工作线程来处理其回调函数**，worker-pool是**系统共享的(！！！**)，因此**workqueue**需要查找到一个**合适的worker\-pool**，然后从worker\-pool中分派一个**合适的工作线程**，pool\_workqueue数据结构在其中起到**桥梁**作用. 这有些类似IT类公司的人力资源池的概念，具体关系如图5.7所示. 

![config](./images/11.png)

![config](./images/14.gif)

![config](./images/13.png)

- **work\_struct**结构体代表的是**一个任务**，它指向一个待异步执行的函数，不管驱动还是子系统什么时候要执行这个函数，都必须把**work**加入到一个**workqueue**. 

- **worker**结构体代表一个**工作者线程(worker thread**)，它主要**一个接一个的执行挂入到队列中的work**，如果没有work了，那么工作者线程就挂起，这些工作者线程被worker\-pool管理. 

对于**驱动和子系统**的开发人员来说，接触到的**只有work**，而背后的处理机制是管理worker\-pool和处理挂入的work. 

- **worker\_pool**结构体用来**管理worker**，对于**每一种worker pool**都分**两种情况**: 一种是处理**普通work**，另一种是处理**高优先级的work**. 

- **workqueue\_struct**结构体代表的是**工作队列**，工作队列分**unbound workqueue**和**bound workqueue**. bound workqueue就是**绑定到cpu**上的，**挂入到此队列中的work**只会在**相对应的cpu**上运行. **unbound workqueue不绑定到特定的cpu**，而且**后台线程池的数量也是动态**的，具体**workqueue关联到哪个worker pool**，这是由**workqueue\_attrs决定**的. 

## 1.7 系统初始化几个默认的workqueue

总结:

(1) 创建一个**pool\_workqueue结构的slab缓存对象**, workqueue针对NUMA系统做一些初始化

(2) 为**所有可用CPU(！！！包括离线的！！！**)创建**两个工作线程池**struct worker\_pool(**普通优先级**的和**高优先级**的)并初始化

(3) 为**每个在线CPU(！！！**)的**每个工作线程池(每个CPU有两个**)分别创建**一个工作线程**(调用**create\_worker**(), 详细见下面)

(4) 创建**UNBOUND类型**和**ordered类型**的**workqueue属性**, 分别是**两个**, 对应**普通优先级**和**高优先级**, 可以供后续使用

(5) 调用**alloc\_workqueue**(), 创建几个**默认的workqueue**

在**系统启动**时，会通过**init\_workqueues**()函数来**初始化几个系统默认的workqueue**. 

```c 
[kernel/workqueue.c]
// per cpu的pool数目
NR_STD_WORKER_POOLS	= 2,		/* # standard pools per cpu */

/* I: attributes used when instantiating standard unbound pools on demand */
static struct workqueue_attrs *unbound_std_wq_attrs[NR_STD_WORKER_POOLS];

/* I: attributes used when instantiating ordered pools on demand */
static struct workqueue_attrs *ordered_wq_attrs[NR_STD_WORKER_POOLS];

static int __init init_workqueues(void)
{
	int std_nice[NR_STD_WORKER_POOLS] = { 0, HIGHPRI_NICE_LEVEL };
	int i, cpu;
    // 位置1
	pwq_cache = KMEM_CACHE(pool_workqueue, SLAB_PANIC);

	cpu_notifier(workqueue_cpu_up_callback, CPU_PRI_WORKQUEUE_UP);
	hotcpu_notifier(workqueue_cpu_down_callback, CPU_PRI_WORKQUEUE_DOWN);
    // 位置2
	wq_numa_init();

	/* initialize CPU pools */
	// 位置3
	for_each_possible_cpu(cpu) {
		struct worker_pool *pool;

		i = 0;
		// 位置4
		for_each_cpu_worker_pool(pool, cpu) {
			BUG_ON(init_worker_pool(pool));
			pool->cpu = cpu;
			cpumask_copy(pool->attrs->cpumask, cpumask_of(cpu));
			pool->attrs->nice = std_nice[i++];
			pool->node = cpu_to_node(cpu);

			/* alloc pool ID */
			mutex_lock(&wq_pool_mutex);
			BUG_ON(worker_pool_assign_id(pool));
			mutex_unlock(&wq_pool_mutex);
		}
	}

	/* create the initial worker */
	// 位置5
	for_each_online_cpu(cpu) {
		struct worker_pool *pool;

		for_each_cpu_worker_pool(pool, cpu) {
			pool->flags &= ~POOL_DISASSOCIATED;
			BUG_ON(!create_worker(pool));
		}
	}
    // 位置6
	/* create default unbound and ordered wq attrs */
	for (i = 0; i < NR_STD_WORKER_POOLS; i++) {
		struct workqueue_attrs *attrs;

		BUG_ON(!(attrs = alloc_workqueue_attrs(GFP_KERNEL)));
		attrs->nice = std_nice[i];
		unbound_std_wq_attrs[i] = attrs;

		BUG_ON(!(attrs = alloc_workqueue_attrs(GFP_KERNEL)));
		attrs->nice = std_nice[i];
		attrs->no_numa = true;
		ordered_wq_attrs[i] = attrs;
	}
    // 位置7
	system_wq = alloc_workqueue("events", 0, 0);
	system_highpri_wq = alloc_workqueue("events_highpri", WQ_HIGHPRI, 0);
	system_long_wq = alloc_workqueue("events_long", 0, 0);
	system_unbound_wq = alloc_workqueue("events_unbound", WQ_UNBOUND,
					    WQ_UNBOUND_MAX_ACTIVE);
	system_freezable_wq = alloc_workqueue("events_freezable",
					      WQ_FREEZABLE, 0);
	system_power_efficient_wq = alloc_workqueue("events_power_efficient",
					      WQ_POWER_EFFICIENT, 0);
	system_freezable_power_efficient_wq = alloc_workqueue("events_freezable_power_efficient",
					      WQ_FREEZABLE | WQ_POWER_EFFICIENT,
					      0);
	return 0;
}
early_initcall(init_workqueues);
```

位置1, 创建一个**pool\_workqueue**数据结构的**slab缓存对象**. 

位置2, **workqueue**考虑了**NUMA系统**情况的一些特殊处理. 

位置3, 为系统中**所有可用的CPU**(cpu\_possible\_mask) 分别**创建struct worker\_pool数据结构**. 

位置4, for\_each\_cpu\_worker\_pool()为**每个CPU**创建**两个worker\_pool**, 一个是**普通优先级**的工作线程池, 另一个是**高优先级**的工作线程池, **init\_worker\_pool**()函数用于**初始化一个worker\_pool**. 这里初始化的都是BOUND类型的worker\_pool, 所以worker\_pool\-\>cpu都相应设置了; node都设置成为了当前cpu所属的内存节点

注意位置4的**for\_each\_cpu\_worker\_pool**宏**遍历CPU中两个worker\_pool**:

```c
[kernel/workqueue.c]
#define for_each_cpu_worker_pool(pool, cpu)				\
	for ((pool) = &per_cpu(cpu_worker_pools, cpu)[0];		\
	     (pool) < &per_cpu(cpu_worker_pools, cpu)[NR_STD_WORKER_POOLS]; \
	     (pool)++)
```

位置5, 为系统每一个**在线(online)CPU**中的**每个worker\_pool**分别**创建一个工作线程**. 

位置6, 创建**UNBOUND类型**和**ordered类型的workqueue属性**，**ordered类型**的**workqueue**表示**同一个时刻只能有一个work item在运行(！！！**). 

位置7到最后, **创建系统默认的workqueue**，这里使用**创建工作队列**的API函数**alloc\_workqueue**().

- **普通优先级BOUND类型**的**工作队列system\_wq**, 名称为“**events**”，可以理解为**默认工作队列**. 
- **高优先级BOUND类型**的工作队列**system\_highpri\_wq** ，名称为“**events\_highpri**”. 
- **UNBOUND类型**的工作队列**system\_unbound\_wq**，名称为“**system\_unbound\_wq**”. 
- **Freezable类型**的工作队列**system\_freezable\_wq**，名称为“**events\_freezable**”. 
- **省电类型**的工作队列**system\_freezable\_wq**，名称为 “**events\_power\_efficient**”. 

### 1.7.1 create\_worker()创建工作线程

总结:

(1) 获取一个**ID**

(2) **工作线程池对应的内存节点**分配一个**worker**

(3) 在**工作线程池对应的内存节点**上创建一个**内核线程给分配的worker**, 执行函数为**worker\_thread**, 参数为**worker(struct worker**), 内核线程名字是"**kworker/u \+ CPU\_ID \+ : \+ worker\_idH**", 高优先级的才有H, UNBOUND类型的才有u

(4) 设置**线程(worker\->task\->flags**)的**PF\_NO\_SETAFFINITY**标志位, **防止修改CPU亲和性**

(5) 将创建的**worker挂到worker\_pool**: **线程池**如果**没有绑定到某个CPU**, 那么设置**worker不绑定CPU**, 可在任意CPU上运行; 将**worker**加到**工作线程池的workers链表**

(6) 使**worker进入idle状态**

(7) **唤醒worker的内核线程**

(8) 返回该worker

上面位置5, 会为**每个online的CPU**的**每个worker\_pool**分别创建**一个工作线程**.

下面来看**create\_worker**()函数是如何创建工作线程的. 

```c
[init_workqueues()->create_worker()]
static struct worker *create_worker(struct worker_pool *pool)
{
	struct worker *worker = NULL;
	int id = -1;
	char id_buf[16];
    // 位置1
	/* ID is needed to determine kthread name */
	id = ida_simple_get(&pool->worker_ida, 0, 0, GFP_KERNEL);
    // 位置2
	worker = alloc_worker(pool->node);

	worker->pool = pool;
	worker->id = id;
    // 位置3
	if (pool->cpu >= 0)
		snprintf(id_buf, sizeof(id_buf), "%d:%d%s", pool->cpu, id,
			 pool->attrs->nice < 0  ? "H" : "");
	else
		snprintf(id_buf, sizeof(id_buf), "u%d:%d", pool->id, id);
    // 位置4
	worker->task = kthread_create_on_node(worker_thread, worker, pool->node,
					      "kworker/%s", id_buf);

	set_user_nice(worker->task, pool->attrs->nice);

	/* prevent userland from meddling with cpumask of workqueue workers */
	// 位置5
	worker->task->flags |= PF_NO_SETAFFINITY;

	/* successful, attach the worker to the pool */
	// 位置6
	worker_attach_to_pool(worker, pool);

	/* start the newly created worker */
	spin_lock_irq(&pool->lock);
	// 位置7
	worker->pool->nr_workers++;
	// 位置8
	worker_enter_idle(worker);
	// 位置9
	wake_up_process(worker->task);
	spin_unlock_irq(&pool->lock);

	return worker;
}
```

位置1, 通过**IDA子系统**获取一个**ID号**. 

位置2, 在**worker\_pool**对应的**内存节点中分配一个worker**数据结构. 

位置3到位置4之间，**pool\->cpu \>= 0**, 表示**BOUND类型的工作线程**. worker的名字一般是 “**kworker/ \+ CPU\_ID \+ worker\_id**”，如果属于**高优先级**类型的workqueue，即**nice值小于 0**，那么还要**加上“H**”.  **pool\->cpu \< 0**，表示**UNBOUND类型的工作线程**，名字为“**kworker/u + CPU\_ID + worker\_id**”. 

位置4，通过**kthread\_create\_on\_node**()函数在**工作线程池对应的node！！！**中**创建一个内核线程用于worker**，在这个内存节点上分配该内核线程相关的struct task\_struct等数据结构. 

注意, **线程执行函数为worker\_thread！！！worker(struct worker)是执行函数的参数, 在工作线程池对应的node上创建, 线程名是位置3设置的！！！**

位置5，设置**工作线程(task的flags！！！**)的**PF\_NO\_SETAFFINITY**标志位，**防止用户程序修改其CPU亲和性**. 在**位置6**代码中会设置**这个worker允许运行的cpumask(！！！**). 

位置6，**worker\_attach\_to\_pool**()函数把刚分配的**工作线程**挂入**worker\_pool**中. 

```c
[create_worker() ->worker_attach_to_pool()]
static void worker_attach_to_pool(struct worker *worker,
				   struct worker_pool *pool)
{
	mutex_lock(&pool->attach_mutex);
	set_cpus_allowed_ptr(worker->task, pool->attrs->cpumask);

	if (pool->flags & POOL_DISASSOCIATED)
		worker->flags |= WORKER_UNBOUND;

	list_add_tail(&worker->node, &pool->workers);
	mutex_unlock(&pool->attach_mutex);
}
```

**worker\_attach\_to\_pool**()函数最主要的工作是将**该worker工作线程**加入**worker\_pool\->workers链表**中. 

**POOL\_DISASSOCIATED**是**worker\-pool(工作线程池使用的！！！)内部使用的标志位**，**一个线程池**可以是**associated**状态或**disassociated**状态. associated状态的**线程池**表示有**绑定到某个CPU**上, disassociated状态的**线程池**表示**没有绑定某个CPU**, 也有可能是**绑定的CPU被offline(！！！**)了，因此可以在**任意CPU上运行(！！！**). 

回到create\_worker()函数中，位置7代码中的**nr\_workers**统计该**worker\_pool中的工作线程的个数**. 注意这里nr\_workers变量需要用**spinlock锁**来保护，因为**每个worker\_pool**定义了一个**timer**，用于**动态删除过多的空闲的worker(！！！**)，见**idle\_worker\_timeout**()函数. 

位置8，worker\_enter\_idle()函数**让该工作线程进入idle状态**. 

位置9, wake\_up\_process()函数**唤醒该工作线程**. 

# 2 创建工作队列workqueue

创建工作队列API有很多，并且基本上和旧版本的workqueue兼容. 

```c
[include/linux/workqueue.h]
#define alloc_workqueue(fmt, flags, max_active, args...)		\
	__alloc_workqueue_key((fmt), (flags), (max_active),		\
			      NULL, NULL, ##args)

#define alloc_ordered_workqueue(fmt, flags, args...)			\
	alloc_workqueue(fmt, WQ_UNBOUND | __WQ_ORDERED | (flags), 1, ##args)

#define create_workqueue(name)						\
	alloc_workqueue("%s", WQ_MEM_RECLAIM, 1, (name))
#define create_freezable_workqueue(name)				\
	alloc_workqueue("%s", WQ_FREEZABLE | WQ_UNBOUND | WQ_MEM_RECLAIM, \
			1, (name))
#define create_singlethread_workqueue(name)				\
	alloc_ordered_workqueue("%s", WQ_MEM_RECLAIM, name)
```

最常见是**alloc\_workqueue**(), 有3个参数, 分别是**name, flags和max\_active**. 其他API和该API类似, **只是调用的flags不相同(！！！**).

(1) **WQ\_UNBOUND**: **工作任务work**会加入**UNBOUND工作队列**中，UNBOUND工作队列的**工作线程没有绑定到具体的CPU**上. UNBOUND类型的work**不需要额外的同步管理**，UNBOUND工作线程池会尝试尽快执行它的work. **这类work会牺牲一部分性能**(局部原理带来的性能提升)，但是比较适用于如下场景. 

- **一些应用**会**在不同的CPU上跳跃**，这样如果**创建Bound类型的工作队列**，会创建**很多没用的工作线程**. 
- **长时间运行**的**CPU消耗类型的应用**(标记**WQ\_CPU\_INTENSIVE标志位**)通常会创建UNBOUND类型的workqueue, **进程调度器**会管理这类工作线程在**哪个CPU**上运行. 

(2) **WQ\_FREEZABLE**: 一个标记着WQ\_FREEZABLE的工作队列会参与到**系统的suspend过程**中，这会让**工作线程**处理完成**当前所有的work**才完成**进程冻结**，并且这个过程**不会再新开始一个work**的执行，直到**进程被解冻**. 

(3) **WQ\_MEM\_RECLAIM**: 当**内存紧张**时，创建**新的工作线程可能会失败**，系统还有一个**rescuer内核线程**会去接管这种情况. 

(4) **WQ\_HIGHPRI**: 属于**高优先级的worker\-pool**, 即比较**低的nice值**. 

(5) **WQ\_CPU\_INTENSIVE**: 属于**特别消耗CPU资源**的一类work, 这类work的执行会得到**系统进程调度器的监管**. 排在这类work后面的**non\-CPU\-intensive类型**的work可能会**推迟执行**. 

(6) \_\_**WQ\_ORDERED**: 表示**同一个时间只能执行一个work item**. 

参数**max\_active**也值得关注，它决定**每个CPU最多可以有多少个work**挂入一个**工作队列**中. 例如**max\_active=16**，说明**每个CPU最多可以有16个work**挂入到**工作队列中执行(！！！**). 

- 通常对于**BOUND类型**的工作队列，**max\_active**最大可以是**512**，如果**max\_active**参数传入**0**，则表示指定为**256**. 
- 对于**UNBOUND类型**工作队列，max\_active可以取**512**和**4 \* num\_possible\_cpus**()之间的**最大值**. 

通常建议**驱动开发**者使用**max\_active=0**作为参数，有些驱动开发者希望使用一个**严格串行执行**的**工作队列**，**alloc\_ordered\_workqueue**()API可以满足这方面的需求，这里使用**max\_active=1**和**WQ\_UNBOUND**的组合，**同一时刻只有一个work可以执行**. 

## 2.1 \_\_alloc\_workqueue\_key创建工作队列

总结:

(1) 分配一个workqueue\_struct并初始化

(2) 对于UNBOUND类型, 创建一个UNBOUND类型的workqueue属性

(3) BOUND类型的workqueue, 

```c
[kernel/workqueue.c]
struct workqueue_struct *__alloc_workqueue_key(const char *fmt,
					       unsigned int flags,
					       int max_active,
					       struct lock_class_key *key,
					       const char *lock_name, ...)
{
	size_t tbl_size = 0;
	va_list args;
	struct workqueue_struct *wq;
	struct pool_workqueue *pwq;

	/* see the comment above the definition of WQ_POWER_EFFICIENT */
	// 位置1
	if ((flags & WQ_POWER_EFFICIENT) && wq_power_efficient)
		flags |= WQ_UNBOUND;

	/* allocate wq and format name */
	if (flags & WQ_UNBOUND)
		tbl_size = nr_node_ids * sizeof(wq->numa_pwq_tbl[0]);
    // 位置2
	wq = kzalloc(sizeof(*wq) + tbl_size, GFP_KERNEL);
	if (!wq)
		return NULL;
    // 位置3
	if (flags & WQ_UNBOUND) {
		wq->unbound_attrs = alloc_workqueue_attrs(GFP_KERNEL);
		if (!wq->unbound_attrs)
			goto err_free_wq;
	}

	va_start(args, lock_name);
	vsnprintf(wq->name, sizeof(wq->name), fmt, args);
	va_end(args);

	max_active = max_active ?: WQ_DFL_ACTIVE;
	max_active = wq_clamp_max_active(max_active, flags, wq->name);

	/* init wq */
	wq->flags = flags;
	wq->saved_max_active = max_active;
	mutex_init(&wq->mutex);
	atomic_set(&wq->nr_pwqs_to_flush, 0);
	INIT_LIST_HEAD(&wq->pwqs);
	INIT_LIST_HEAD(&wq->flusher_queue);
	INIT_LIST_HEAD(&wq->flusher_overflow);
	INIT_LIST_HEAD(&wq->maydays);

	lockdep_init_map(&wq->lockdep_map, lock_name, key, 0);
	INIT_LIST_HEAD(&wq->list);

	if (alloc_and_link_pwqs(wq) < 0)
		goto err_free_wq;
```

位置1, **WQ\_POWER\_EFFICIENT**标志位考虑**系统的功耗**问题. 

- 对于**BOUND类型的workqueue**, 它是**Per\-CPU类型**的，会**利用cache的局部性原理来提高性能**. 也就是说，它**不会从这个CPU迁移**到另外一个CPU, 也**不希望进程调度器来打扰**它们. 
- 设置成**UNBOUND类型的workqueue**后，究竟选择**哪个CPU上唤醒**交由**进程调度器决定**. 

**Per\-CPU类型**的**workqueue**会让**idle状态的CPU从idle状态唤醒**，从而增加了功耗. 如果系统配置了**CONNG\_WQ\_POWER\_EFFICIENT\_DEFAULT选项**，那么创建**workqueue**会把标记了**WQ\_POWER\_EFFIOENT**的**workqueue**设置成**UNBOUND类型**，这样**进程调度器**就可以参与**选择CPU**来执行.

```c
[kernel/workqueue.c]
#ifdef CONFIG_WQ_POWER_EFFICIENT_DEFAULT
static bool wq_power_efficient = true;
#else
static bool wq_power_efficient;
#endif
```

位置2以及后面, 是分配一个**workqueue\_struct**数据结构并初始化. 

位置3, 对于**UNBOUND类型**, 创建一个UNBOUND类型的**workqueue属性**

### 2.1.1 pool\_workqueue分配以及初始化函数alloc\_and\_link\_pwqs()

接下来看**pool\_workqueue分配**以及初始化

#### 2.1.1.1 BOUND类型的workqueue

总结:

(1) 给**每个CPU**分配一个**Per\-CPU**的**pool\_workqueue**

(2) **遍历每个CPU**, 通过CPU的这个**pool\_workqueue**将**系统静态定义的Per\-CPU类型的高优先级worker\_pool(也就是init\_workqueues()初始化的)**和**传入的workqueue连接**起来, 并将**这个pool\_workqueue**添加到传入的**workqueue\->pwqs链表**.

```c
[alloc_workqueue() ->alloc_and_link_pwqs()]
[kernel/workqueue.c]
static int alloc_and_link_pwqs(struct workqueue_struct *wq)
{
	bool highpri = wq->flags & WQ_HIGHPRI;
	int cpu, ret;
    // 位置1
	if (!(wq->flags & WQ_UNBOUND)) {
	    // 为每个CPU分配一个Per-CPU类型的pool_workqueue
		wq->cpu_pwqs = alloc_percpu(struct pool_workqueue);
		// 遍历所有可用CPU
		for_each_possible_cpu(cpu) {
		    // 得到当前CPU的pool_workqueue
			struct pool_workqueue *pwq =
				per_cpu_ptr(wq->cpu_pwqs, cpu);
			// 得到当前CPU的worker_pool
			struct worker_pool *cpu_pools =
				per_cpu(cpu_worker_pools, cpu);
            // 通过当前CPU的pool_workqueue将当前CPU的高优先级worker_pool和传入的workqueue连接起来
			init_pwq(pwq, wq, &cpu_pools[highpri]);

			mutex_lock(&wq->mutex);
			// 将当前CPU的pool_workqueue加到传入的workqueue->pwqs链表
			link_pwq(pwq);
			mutex_unlock(&wq->mutex);
		}
		return 0;
	// 位置2
	} else if (wq->flags & __WQ_ORDERED) {
		ret = apply_workqueue_attrs(wq, ordered_wq_attrs[highpri]);
		/* there should only be single pwq for ordering guarantee */
		WARN(!ret && (wq->pwqs.next != &wq->dfl_pwq->pwqs_node ||
			      wq->pwqs.prev != &wq->dfl_pwq->pwqs_node),
		     "ordering guarantee broken for workqueue %s\n", wq->name);
		return ret;
	// 位置3
	} else {
		return apply_workqueue_attrs(wq, unbound_std_wq_attrs[highpri]);
	}
}
```

位置1的整个if, 处理**BOUND类型的workqueue**. 给**每个CPU**分配一个**Per\-CPU**的**pool\_workqueue**, **遍历每个CPU**, 通过CPU的这个**pool\_workqueue**将**系统静态定义的Per\-CPU类型的高优先级的worker\_pool(也就是init\_workqueues()初始化的)**和**传入的workqueue连接**起来, 并将**这个pool\_workqueue**添加到传入的**workqueue\->pwqs链表**. 

cpu\_pwqs是一个Per\-CPU类型的指针，**alloc\_percpu**()为**每个CPU分配一个Per\-CPU类型的pool\_workqueue**数据结构. 

**cpu\_worker\_pools**是**系统静态定义的Per\-CPU类型**的**worker\_pool数据结构**，**wq\->cpu\_pwqs**是**动态分配**的**Per\-CPU类型的pool\_workqueue**数据结构. 

**init\_pwq**()函数把**这两个数据结构连接起来**，即**pool\_workqueue\->pool**指向**worker\_pool**数据结构，**pool\_workqueue\->wq**指向**workqueue\_struct**数据结构. 

**link\_pwq()函数**主要是把**pool\_workqueue**添加到**workqueue\_struct\->pwqs链表**中. 

位置2和位置3处理**ORDERED类型**和**UNBOUND类型**的workqueue

#### 2.1.1.2 ORDERED类型和UNBOUND类型的workqueue

总结:

都通过调用**apply\_workqueue\_attrs**()函数来实现, 出入的workqueue\_attrs属性参数不同, 一个是**ordered\_wq\_attrs[highpri**], 一个是**unbound\_std\_wq\_attrs[highpri**], 这两个不同之处在于属性里面的no\_numa在ordered中是true, 这些都是在**系统初始化init\_workqueues()阶段完成**的

(1) 通过系统全局哈希表unbound\_pool\_hash(管理所有UNBOUND类型的work\_pool)根据属性查找worker\_pool, 找到将其引用计数加1, 并返回, 没有的话重新分配并初始化一个(创建pool, 为pool创建一个工作线程worker<会唤醒线程>), 将新pool加入哈希表

(2) 分配一个**pool\_workqueue**

(3) 初始化该pwq, 将worker\_pool和workqueue\_struct连接起来, 为pool\_workqueue初始化一个工作work(通过INIT\_WORK()), 回调函数是pwq\_unbound\_release\_workfn(), 该work执行: 从work中找到相应的pwq, 该work只对UNBOUND类型的workqueue有效, 如果work\-\>pwq\-\>wq\-\>pwqs(所有pool\_workqueue都在这个链表)中当前pool\_workqueue是最后一个, 释放pool\_workqueue相关结构

执行代码片段如下:

```c
[alloc_workqueue() -> alloc_and_link_pwqs() -> apply_workqueue_attrs()]
int apply_workqueue_attrs(struct workqueue_struct *wq,
			  const struct workqueue_attrs *attrs)
{
	struct workqueue_attrs *new_attrs, *tmp_attrs;
	struct pool_workqueue **pwq_tbl, *dfl_pwq;
	int node, ret;
    // 分配pool_workqueue
	pwq_tbl = kzalloc(nr_node_ids * sizeof(pwq_tbl[0]), GFP_KERNEL);

	mutex_lock(&wq_pool_mutex);
    // 查找或新建一个pool_workqueue
	dfl_pwq = alloc_unbound_pwq(wq, new_attrs);

	for_each_node(node) {
		dfl_pwq->refcnt++;
		pwq_tbl[node] = dfl_pwq;
	}

	mutex_unlock(&wq_pool_mutex);

    mutex_lock(&wq->mutex);

	/* save the previous pwq and install the new one */
	for_each_node(node)
		pwq_tbl[node] = numa_pwq_tbl_install(wq, node, pwq_tbl[node]);

	/* @dfl_pwq might not have been used, ensure it's linked */
	link_pwq(dfl_pwq);
	swap(wq->dfl_pwq, dfl_pwq);

	mutex_unlock(&wq->mutex);

	/* put the old pwqs */
	for_each_node(node)
	    // 位置1
		put_pwq_unlocked(pwq_tbl[node]);
	put_pwq_unlocked(dfl_pwq);

	put_online_cpus();
	ret = 0;
	return ret;
}
```

首先分配一个**pool\_workqueue**数据结构, 然后调用**alloc\_unbound\_pwq**()来**查找或新建一个pool\_workqueue**.

```c
[apply_workqueue_attrs() ->alloc_unbound_pwq()]
[kernel/workqueue.c]
static struct pool_workqueue *alloc_unbound_pwq(struct workqueue_struct *wq,
					const struct workqueue_attrs *attrs)
{
	struct worker_pool *pool;
	struct pool_workqueue *pwq;
    // 查找相同属性的worker_pool
	pool = get_unbound_pool(attrs);
    // 给pool_workqueue 分配内存
	pwq = kmem_cache_alloc_node(pwq_cache, GFP_KERNEL, pool->node);
	init_pwq(pwq, wq, pool);
	// 返回pool_workqueue
	return pwq;
}
```

首先通过**get\_unbound\_pool**()去系统中**查找有没有相同属性的worker\_pool**. 

```c
[kernel/workqueue.c]
static struct worker_pool *get_unbound_pool(const struct workqueue_attrs *attrs)
{
    // 根据attrs计算对应的散列值
	u32 hash = wqattrs_hash(attrs);
	struct worker_pool *pool;
	int node;

	/* do we already have a matching pool? */
	// 从全局散列表unbound_pool_hash中，根据attrs对比找到存在的worker_pool，找到就返回
	hash_for_each_possible(unbound_pool_hash, pool, hash_node, hash) {
		if (wqattrs_equal(pool->attrs, attrs)) {
			pool->refcnt++;
			return pool;
		}
	}
    // 走到这一步说明没有找到存在的worker_pool，那么下面就得新创建一个
	/* nope, create a new one */
	// 创建一个worker_pool
	pool = kzalloc(sizeof(*pool), GFP_KERNEL);
    
    lockdep_set_subclass(&pool->lock, 1);   /* see put_pwq() */
    // copy属性给worker_pool
    copy_workqueue_attrs(pool->attrs, attrs);

    /*
     * no_numa isn't a worker_pool attribute, always clear it.  See
     * 'struct workqueue_attrs' comments for detail.
     */
    pool->attrs->no_numa = false;

	if (worker_pool_assign_id(pool) < 0)
		goto fail;

	/* create and start the initial worker */
	// 创建工作者线程
	if (!create_worker(pool))
		goto fail;

	/* install */
	// 加入到全局unbound_pool_hash散列表中
	hash_add(unbound_pool_hash, &pool->hash_node, hash);

	return pool;
fail:
	if (pool)
		put_unbound_pool(pool);
	return NULL;
}
```

系统定义了一个**哈希表unbound\_pool\_hash(！！！**)，用于**管理系统中所有的UNBOUND类型的worker\_pool**，通过**wqattrs\_equal**()判断系统中**是否己经有了类型相关的worker\_pool**, **wqattrs\_equal**()函数首先会**比较nice值**，然后**比较cpumask位图是否一致**. 

如果哈希表有**worker\_pool**, 那将**该pool引用计数加1**, 并**返回该pool**

如果哈希表**没有**，那就**重新分配和初始化一个(创建pool, 为该pool创建一个worker<会唤醒线程>, 将当前pool加入到哈希表**), 最后**返回新建的pool**. 

回到**alloc\_unbound\_pwq**()函数中，找到**worker\_pool**后**还需要一个连接器pool\_workqueue**，最后通过**init\_pwq**()函数把**worker\_pool**和**workqueue\_struct串联**起来. 

回到apply\_workqueue\_attrs()函数中的numa\_pwq\_tbl\_install()函数. 

```c
[kernel/workqueue.c]
static struct pool_workqueue *numa_pwq_tbl_install(struct workqueue_struct *wq,
						   int node,
						   struct pool_workqueue *pwq)
{
	struct pool_workqueue *old_pwq;

	lockdep_assert_held(&wq->mutex);

	/* link_pwq() can handle duplicate calls */
	link_pwq(pwq);

	old_pwq = rcu_access_pointer(wq->numa_pwq_tbl[node]);
	rcu_assign_pointer(wq->numa_pwq_tbl[node], pwq);
	return old_pwq;
}
```

**link\_pwq**()把找到的**pool\_workqueue**添加到**workqueue\_struct\->pwqs链表**中. 

接下来利用**RCU锁机制**来保护**pool\_workqueue数据结构**，首先old\_pwq和pwq\_tbl\[node\]指向wq\->numa\_pwq\_tbl\[node\]中旧的数据，rcu\_assign\_pointer()之后wq\->numa\_pwq\_tbl[node]指针指向新的数据. 那RCU什么时候会删除旧数据呢？看apply\_workqueue\_attrs()函数位置1处的代码，其中参数**pwq\_tbl\[node\]指向旧数据**. 

```c
[put_pwq_unlocked() ->put_pwq()]
[kernel/workqueue.c]
static void put_pwq(struct pool_workqueue *pwq)
{
	lockdep_assert_held(&pwq->pool->lock);
	if (likely(--pwq->refcnt))
		return;
	if (WARN_ON_ONCE(!(pwq->wq->flags & WQ_UNBOUND)))
		return;

	schedule_work(&pwq->unbound_release_work);
}
```

当**pool\_workqueue\->refcnt成员计数小于0**时，会通过**schedule\_work**()调度一个系统**默认的work**，**每个pool\_workqueue有初始化一个work！！！**，见**init\_pwq()函数**. 

```c
[kernel/workqueue.c]
static void init_pwq(struct pool_workqueue *pwq, struct workqueue_struct *wq,
		     struct worker_pool *pool)
{
	BUG_ON((unsigned long)pwq & WORK_STRUCT_FLAG_MASK);

	memset(pwq, 0, sizeof(*pwq));

	pwq->pool = pool;
	pwq->wq = wq;
	pwq->flush_color = -1;
	pwq->refcnt = 1;
	INIT_LIST_HEAD(&pwq->delayed_works);
	INIT_LIST_HEAD(&pwq->pwqs_node);
	INIT_LIST_HEAD(&pwq->mayday_node);
	INIT_WORK(&pwq->unbound_release_work, pwq_unbound_release_workfn);
}
```

直接看**该work**的回调函数**pwq\_unbound\_release\_workfn**()

```c
[put_pwq_unlocked() ->put_pwq() ->pwq_unbound_release_workfn()]
[kernel/workqueue.c]
static void pwq_unbound_release_workfn(struct work_struct *work)
{
	struct pool_workqueue *pwq = container_of(work, struct pool_workqueue,
						  unbound_release_work);
	struct workqueue_struct *wq = pwq->wq;
	struct worker_pool *pool = pwq->pool;
	bool is_last;

	if (WARN_ON_ONCE(!(wq->flags & WQ_UNBOUND)))
		return;

	mutex_lock(&wq->mutex);
	list_del_rcu(&pwq->pwqs_node);
	is_last = list_empty(&wq->pwqs);
	mutex_unlock(&wq->mutex);

	mutex_lock(&wq_pool_mutex);
	put_unbound_pool(pool);
	mutex_unlock(&wq_pool_mutex);

	call_rcu_sched(&pwq->rcu, rcu_free_pwq);

	/*
	 * If we're the last pwq going away, @wq is already dead and no one
	 * is gonna access it anymore.  Free it.
	 */
	if (is_last) {
		free_workqueue_attrs(wq->unbound_attrs);
		kfree(wq);
	}
}
```

首先从**work**中找到pool\_workqueue**数据结构指针pwq**，注意该**work只对UNBOUND类型的workqueue有效**. 当有需要释放pool\_workqueue数据结构时，会调用call\_rcu\_sched()来对旧数据进行保护，让所有访问该旧数据的读临界区都经历过了Grace Period之后才会释放旧数据. 

# 3 调度一个work

## 3.1 初始化一个work

初始化一个work: 宏INIT\_WORK(work, func)

Linux内核推荐**驱动开发**者使用**默认的workqueue**, 而**不是新创建workqueue**. 要使用**系统默认的workqueue**，首先需要**初始化一个work**, 内核提供了**相应的宏INIT\_WORK**(). 

```c
[include/linux/workqueue.h]
#define INIT_WORK(_work, _func)						\
	__INIT_WORK((_work), (_func), 0)

#define __INIT_WORK(_work, _func, _onstack)				\
	do {								\
		__init_work((_work), _onstack);				\
		(_work)->data = (atomic_long_t) WORK_DATA_INIT();	\
		INIT_LIST_HEAD(&(_work)->entry);			\
		(_work)->func = (_func);				\
	} while (0)
```

struct work\_struct数据结构不复杂，主要是对data、entry和回调函数func的赋值. **data成员**被划分成**两个域**，**低比特位域**用于存放**work相关的flags**, **高比特位域**用于存放**上次执行该work的worker\_pool的ID号**或**保存上一次pool\_workqueue数据结构指针**. 

```c
[include/linux/workqueue.h]
enum {
	WORK_STRUCT_PENDING_BIT	= 0,	/* work item is pending execution */
	WORK_STRUCT_DELAYED_BIT	= 1,	/* work item is delayed */
	WORK_STRUCT_PWQ_BIT	= 2,	/* data points to pwq */
	WORK_STRUCT_LINKED_BIT	= 3,	/* next work is linked to this one */
	WORK_STRUCT_COLOR_SHIFT	= 4,	/* color for workqueue flushing */
	WORK_STRUCT_COLOR_BITS	= 4,
    ...
	WORK_OFFQ_FLAG_BITS	= 1,
	...
};
```

以32bit的CPU来说，当**data字段**包含**WORK\_STRUCT\_PWQ\_BIT标志位**时，表示**高比特位域**保存着**上一次pool\_workqueue数据结构指针**，这时**低8位**用于存放一些标志位. 当**data字段没有包含WORK\_STRUCT\_PWQ\_BIT标志位**时，表示其**高比特位域**存放**上次执行该work的worker\_pool的ID号**，**低5位**用于存放一些**标志位**，见get\_work\_pool()函数. 

常见的标志位如下. 

- WORK\_STRUCT\_PENDING\_BIT: 表示该work正在pending执行, 已经在工作队列中. 
- WORK\_STRUCT\_DELAYED\_BIT: 表示该work被延迟执行了. 
- WORK\_STRUCT\_PWQ\_BIT: 表示work的data成员指向pwqs数据结构的指针，其中pwqs需要按照256Byte对齐，这样pwqs指针的低8位可以忽略，只需要其余的比特位就可以找回pwqs指针.  struct pool\_workqueue数据结构按照256Byte对齐. 
- WORK\_STRUCT\_LINKED\_BIT: 表示下一个work连接到该work上. 

## 3.2 schedule\_work()调度work

总结:

调度一个work: schedule\_work(work\_struct), 将work挂入**系统默认的BOUND类型**的workqueue工作队列**system\_wq**

(2) 关闭本地中断

(3) work已经有WORK\_STRUCT\_PENDING\_BIT标志位, 说明该work正在pending执行, 已经在队列中, 不用重复添加, 恢复本地中断并返回, 否则设置该标志位, 继续

(4) 找到一个合适的pool\_workqueue. 优先选择**本地CPU**或**本地CPU的node节点**对应的pool\_workqueue，如果该work上次执行的worker\_pool和刚选择的pwq\-\>pool不等, 并且**该work**正在其上次执行的**工作线程池**中**运行**，而且**运行这个work的worker**对应的**pwq**对应的**workqueue**等于**调度传入的workqueue**(**worker\-\>current\_pwq\->wq == wq**), 则优先选择这个正在运行的worker\->current\_pwq. 利用其缓存热度.

(5) 判断当前pool\_workqueue活跃的work数量, 少于最高限值, 加入pwq\-\>pool\-\>worklist(pool的pending链表), 否则加入pwq\-\>delayed\_works(pwq的被延迟执行的works链表)

(6) 当前pwq\-\>pool工作线程池存在pending状态的work并且pool中正运行的worker数量为0的话, 找到pool中第一个idle的worker并唤醒worker\-\>task

**初始化完一个work**后，就可以**调用schedule\_work**()函数来**把work挂入系统的默认的workqueue**中. 

```c
[include/linux/workqueue.h]
static inline bool schedule_work(struct work_struct *work)
{
	return queue_work(system_wq, work);
}
```

**schedule\_work**()函数把**work挂入系统默认BOUND类型的工作队列system\_wq**中，该工作队列是在init\_workqueues()时创建的. 

```c
[schedule_work() - >queue_work()]
[include/linux/workqueue.h]
static inline bool queue_work(struct workqueue_struct *wq,
			      struct work_struct *work)
{
	return queue_work_on(WORK_CPU_UNBOUND, wq, work);
}
```

**queue\_work\_on**()有**3个参数**，其中**WORK\_CPU\_UNBOUND**表示**不绑定到任何CPU**上，**建议使用本地CPU**. WORK\_CPU\_UNBOUND宏容易让人产生混淆，其定义为NR\_CPUS. **wq指工作队列**，**work是新创建的工作**. 

```c
[schedule_work() ->queue_work() ->queue_work_on()]
[kernel/workqueue.c]
bool queue_work_on(int cpu, struct workqueue_struct *wq,
		   struct work_struct *work)
{
	bool ret = false;
	unsigned long flags;

	local_irq_save(flags);

	if (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {
		__queue_work(cpu, wq, work);
		ret = true;
	}

	local_irq_restore(flags);
	return ret;
}
EXPORT_SYMBOL(queue_work_on);
```

把**work加入工作队列**中是在**关闭本地中断下运行**的. 如果**开中断**，那么有可能在**处理中断返回时调度其他进程**，**其他进程**有可能调用**cancel\_delayed\_work**()把PENDING位偷走，这种情况在稍后介绍cancel\_delayed\_work()时再详细描述. 

如果该work己经设置**WORK\_STRUCT\_PENDING\_BIT标志位**，说明该**work己经在工作队列**中，不需要重复添加. 

test\_and\_set\_bit()函数设置WORK\_STRUCT\_PENDING\_BIT标志位并**返回旧值**. 

```c
[schedule_work() ->queue_work() ->queue_work_on() ->__queue_work()]
[kernel/workqueue.c]
static void __queue_work(int cpu, struct workqueue_struct *wq,
			 struct work_struct *work)
{
	struct pool_workqueue *pwq;
	struct worker_pool *last_pool;
	struct list_head *worklist;
	unsigned int work_flags;
	unsigned int req_cpu = cpu;
    // 位置1
	WARN_ON_ONCE(!irqs_disabled());

	debug_work_activate(work);

	/* if draining, only works from the same workqueue are allowed */
	if (unlikely(wq->flags & __WQ_DRAINING) &&
	    WARN_ON_ONCE(!is_chained_work(wq)))
		return;
```

位置1代码要判断**当前运行状态**是否处于**关中断**状态，为什么\_\_queue\_work()要运行在关中断的状态下呢？读者可以先思考一下，这个问题稍后讲述cancel\_work\_sync()函数时再详细介绍. 

\_\_WQ\_DRAINING标志位表示要销毁workqueue，那么挂入workqueue中所有的work都要处理完毕才能把这个workqueue销毁. 在销毁过程中, —般不允许再有新的work加入队列中，有一种特例情况是正在清空work时又触发了一个queue work操作，这种情况被称为chained work. 

```c
[__queue_work() ]
retry:
	if (req_cpu == WORK_CPU_UNBOUND)
		cpu = raw_smp_processor_id();

	/* pwq which will be used unless @work is executing elsewhere */
	// 位置4
	if (!(wq->flags & WQ_UNBOUND))
		pwq = per_cpu_ptr(wq->cpu_pwqs, cpu);
	else
		pwq = unbound_pwq_by_node(wq, cpu_to_node(cpu));
    // 位置2
	last_pool = get_work_pool(work);
	if (last_pool && last_pool != pwq->pool) {
		struct worker *worker;

		spin_lock(&last_pool->lock);

		worker = find_worker_executing_work(last_pool, work);

		if (worker && worker->current_pwq->wq == wq) {
			pwq = worker->current_pwq;
		} else {
			/* meh... not running there, queue here */
			spin_unlock(&last_pool->lock);
			spin_lock(&pwq->pool->lock);
		}
	} else {
		spin_lock(&pwq->pool->lock);
	}
    // 位置3
	if (unlikely(!pwq->refcnt)) {
		if (wq->flags & WQ_UNBOUND) {
			spin_unlock(&pwq->pool->lock);
			cpu_relax();
			goto retry;
		}
		/* oops */
		WARN_ONCE(true, "workqueue: per-cpu pwq for %s on cpu%d has 0 refcnt",
			  wq->name, cpu);
	}
```

**pool\_workqueue**数据结构是**桥梁枢纽**，想把work加入到workqueue中，首先需要找到**一个合适的pool\_workqueue枢纽**. 对于**BOUND类型**的**workqueue**，直接使用**本地CPU对应的pool\_workqueue**枢纽; 如果是**UNOUND类型的workqueue**，调用**unbound\_pwq\_by\_node**()函数来寻找**本地node节点**对应的**UNBOUND类型的pool\_workqueue**.

```c
[kernel/workqueue.c]
static struct pool_workqueue *unbound_pwq_by_node(struct workqueue_struct *wq,
						  int node)
{
	return rcu_dereference_raw(wq->numa_pwq_tbl[node]);
}
```

对于**UNBOUND类型**的**workqueue**，**workqueue\_struct**数据结构中的**numa\_pwq\_tbl**\[\]数组存放着**每个系统node节点(！！！**)对应的U**NBOUND类型的pool\_workqueue**枢纽. 

位置2整块代码，**每个work\_struct**数据结构的**data成员**可以用于记录**worker\_pool的ID号**，那么**get\_work\_pool**()函数可以用于查询**该work上一次**是在**哪个worker\_pool**中运行的. 

```c
[kernel/workqueue.c]
static struct worker_pool *get_work_pool(struct work_struct *work)
{
	unsigned long data = atomic_long_read(&work->data);
	int pool_id;

	pool_id = data >> WORK_OFFQ_POOL_SHIFT;
	if (pool_id == WORK_OFFQ_POOL_NONE)
		return NULL;

	return idr_find(&worker_pool_idr, pool_id);
}
```

位置2代码，返回**该work上一次运行的worker\_pool**. 这里有一种情况，就是发现**上一次运行的worker\_pool**和**这一次运行该work的pwq\->pool不一致**. 例如**上一次是在CPU0**对应的worker\_pool，这一次是在**CPU1**上的worker\_pool，这种情况下就要考查**work是不是正运行在CPU0的worker\_pool中的某个工作线程**里. 如果**是**，那么这次work应该**继续添加到CPU0上的worker\_pool**上. find\_worker\_executing\_work()判断一个work是否在某个worker\_pool上正在运行，如果是，则返回这个正在执行的工作线程，这样可以**利用其缓存热度**. 

```c
static struct worker *find_worker_executing_work(struct worker_pool *pool,
						 struct work_struct *work)
{
	struct worker *worker;

	hash_for_each_possible(pool->busy_hash, worker, hentry,
			       (unsigned long)work)
		if (worker->current_work == work &&
		    worker->current_func == work->func)
			return worker;

	return NULL;
}
```

到了位置3代码处，这时**pool\_workqueue应该已确定**，要么是位置4代码通过**本地CPU或node节点找到了pool\_workqueue**; 要么是**上一次的last pool\_workqueue**. 但是对于**UNBOUND类型**的**workqueue**来说，对UNBOUND类型的pool\_workqueue的释放是异步的，因此这里有一个**refcnt计数成员**，当pool\_workqueue\->refcnt减少到0时，说明该pool\_workqueue己经被释放，那么只能跳转到retry标签处**重新选择pool\_workqueue**. 接下来继续看\_\_queue\_work()函数. 

```c
[__queue_work()]
    // 位置5
	if (likely(pwq->nr_active < pwq->max_active)) {
		trace_workqueue_activate_work(work);
		pwq->nr_active++;
		worklist = &pwq->pool->worklist;
	} else {
		work_flags |= WORK_STRUCT_DELAYED;
		worklist = &pwq->delayed_works;
	}

	insert_work(pwq, work, worklist, work_flags);

	spin_unlock(&pwq->pool->lock);
}
```

位置5代码，判断**当前的pool\_workqueue活跃的work数量**，如果**少于最高限值**，就**加入pending链表worker\_pool\-\>worklist**中，否则**加入pool\_workqueue\-\>delayed\_works链表(被延迟执行的works**)中. 

```c
[__queue_work() -> insert_work()]
static void insert_work(struct pool_workqueue *pwq, struct work_struct *work,
			struct list_head *head, unsigned int extra_flags)
{
	struct worker_pool *pool = pwq->pool;

	/* we own @work, set data and link */
	// 位置1
	set_work_pwq(work, pwq, extra_flags);
	// 位置2
	list_add_tail(&work->entry, head);
	// 位置3
	get_pwq(pwq);
    // 位置4
	smp_mb();
    // 位置5
	if (__need_more_worker(pool))
		wake_up_worker(pool);
}
```

位置1, set\_work\_pwq()是设置work\_struct数据结构中的data成员，把pwq指针的值和一些flags设置到data成员中，方便下一次再调用queue\_work()函数把该work重新加入时，可以很方便地知道本次使用哪个pool\_workqueue, 见get\_work\_pwq()函数. 

位置2, 将 work加入worker_pool相应的链表中. 

位置3代码，get\_pwq()增加pool\_workqueue \-\>refcnt成员引用计数，它和put\_pwq()是配对使用的. 

位置4代码，smp\_mb()内存屏障指令保证wake\_up\_worker()唤醒worker时，在\_\_schedule()\-\>wq\_worker\_sleeping()函数中看到这里的list\_add\_tail()添加链表己经完成. 另外也保证位置5代码的\_\_need\_more\_worker()函数去读取worker\_pool\->nr\_running成员时，list\_add\_tail()添加链表己经完成. 

位置5, 判断**当前pwq\-\>pool工作线程池**是否需要**更多工作线程worker**(**pool**中存在**pending状态的work**并且pool中正在运行的worker数量为0), 是的话, 找到pool中第一个idle的worker并唤醒worker\-\>task

至此，驱动开发者调用schedule\_work()函数己经把work加入workqueue中，虽然函数名叫作schedule\_work，但并**没有开始实质调度work执行**，它**只是把work**加入**workqueue**的**PENDING链表**中而己. 

- 加入workqueue的 PENDING链表是**关中断**的环境下进行的. 
- 设置**work\-\>data**成员的**WORK\_STRUCT\_PENDING\_BIT标志位**. 
- 寻找**合适的pool\_workqueue**. 优先选择**本地CPU**或**本地CPU的node节点**对应的pool\_workqueue，如果该work上次执行的worker\_pool和刚选择的pwq\-\>pool不等, 并且**该work**正在其上次执行的**工作线程池**中**运行**，而且**运行这个work的worker**对应的**pwq**对应的**workqueue**等于**调度传入的workqueue**(**worker\-\>current\_pwq\->wq == wq**), 则优先选择这个正在运行的worker\->current\_pwq. 利用其缓存热度.
- 找到**pool\_workqueue**，也就找到**对应的worker\_pool**和**对应的PENDING链表**. 
- 小心处理SMP并发情况. 

## 3.3 工作线程处理函数worker\_thread()

接下来看工作线程是如何处理work的. 

........

worker\_thread()中第39行中的keep\_eorking()函数, 其实是控制活跃工作线程数量的.

```c
static bool keep_working(struct worker_pool *pool)
{
	return !list_empty(&pool->worklist) &&
		atomic_read(&pool->nr_running) <= 1;
}
```

这里判断条件比较简单，如果**pool\-\>worklist**中**还有工作需要处理**且**工作线程池**有**活跃的线程小于等于1**，那么**保持当前工作线程继续工作**，此功能可以**防止工作线程泛滥**. 为什么**限定活跃的工作线程数量小于等于1**呢？在一个CPU上限定一个活跃工作线程的方法比较简单，当然这里没有考虑CPU上线程工作池的负载情况(例如一个CPU上有5个任务，假设它们的权重都是1024,其中3个work类型任务，那么这3个work分布在3个线程和在1个线程中运行，哪种方式能够最快执行完成？). 

简化后的代码逻辑如下:

```c
worker_thread()
{
recheck:
    if(不需要更多的工作线程?)
        goto 睡眠;
        
    if(需要创建更多的工作线程? && 创建线程)
        goto recheck;
        
    do{
        处理工作;
    }(还有工作待完成 && 活跃的工作线程 <= 1)
    
睡眠:
    schedule();
}
```

至此一个work的执行过程已介绍完毕，对工作线程worker总结如下. 

- **动态地创建**和**管理**一个**工作线程池**中的**工作线程**. 假如发现有**PENDING的work**且**当前工作池**中**没有正在运行的工作线程**(worker\_pool\-\>nr\_running = 0)，那就**唤醒idle状态的线程**，否则就**动态创建一个工作线程**. 
- 如果发现**一个work**己经在**同一个工作池**的**另外一个工作线程执行**了，那就**不处理该work**. 
- 动态管理**活跃工作线程数量**，见keep\_working()函数. 

# 4 取消一个work

# 5 和调度器的交互

**CMWQ机制**会**动态地调整一个线程池中工作线程的执行情况**，**不会**因为**某一个work回调函数**执行了**阻塞操作**而**影响到整个线程池中其他work**的执行. 

假设**某个work的回调函数func**()中执行了**睡眠操作**，例如调用**wait\_event\_interruptible**()函数去**睡眠**，在wait\_event\_interruptible()函数中会**设置当前进程的state为TASK\_INTERRUPTIBLE**,然后**执行schedule**()切换进程. 

```c
[kernel/sched/core.c]
static void __sched __schedule(void)
{
    ...
	if (prev->state && !(preempt_count() & PREEMPT_ACTIVE)) {
		if (unlikely(signal_pending_state(prev->state, prev))) {
			prev->state = TASK_RUNNING;
		} else {
			deactivate_task(rq, prev, DEQUEUE_SLEEP);
			prev->on_rq = 0;

			/*
			 * If a worker went to sleep, notify and ask workqueue
			 * whether it wants to wake up a task to maintain
			 * concurrency.
			 */
			// 位置1
			if (prev->flags & PF_WQ_WORKER) {
				struct task_struct *to_wakeup;
                // 重点
				to_wakeup = wq_worker_sleeping(prev, cpu);
				if (to_wakeup)
					try_to_wake_up_local(to_wakeup);
			}
		}
		switch_count = &prev->nvcsw;
	}
	...
}
```

在\_\_schedule()函数中，**prev指当前进程**，即**执行work的工作线程**，它的**state状态为TASK\_INTERRUPTIBLE(其值为1**), 另外**这次调度不是中断返回前的抢占调度**，preempt\_count也没有设置PREEMPT\_ACTIVE,因此会运行到位置1代码处. 

当**一个工作线程要被调度器换出**时，调用**wq\_worker\_sleeping**()看看**是否需要唤醒同一个线程池中的其他内核线程**. 

```c
[kernel/workqueue.c]
struct task_struct *wq_worker_sleeping(struct task_struct *task, int cpu)
{
	struct worker *worker = kthread_data(task), *to_wakeup = NULL;
	struct worker_pool *pool;

	pool = worker->pool;

	if (atomic_dec_and_test(&pool->nr_running) &&
	    !list_empty(&pool->worklist))
		to_wakeup = first_idle_worker(pool);
	return to_wakeup ? to_wakeup->task : NULL;
}
```

**当前的工作线程马上要被换出(睡眠**)，因此先把**worker\_pool->nr\_running引用计数减1**，然后判断该计数是否为0, 为0则说明**当前线程池也没有活跃的工作线程**. **没有活跃的工作线程**且**当前线程池的等待队列中还有work**需要处理，那么就**必须要去找一个idle的工作线程来唤醒**它. first\_idle\_worker()函数比较简单，从pool->idle\_list链表中取一个idle的工作线程即可. 

找到一个**idle工作线程**，调用**try\_to\_wake\_up\_local**()去**唤醒idle工作线程**. 

在唤醒一个工作线程时，需要增加worker\_pool-> nr\_running引用计数来告诉workqueue机制现在**有一个工作线程要被唤醒**了. 

```c
[__schedule() ->try_to_wake_up_local() ->ttwu_activate()]
[kernel/sched/core.c]
static void ttwu_activate(struct rq *rq, struct task_struct *p, int en_flags)
{
	activate_task(rq, p, en_flags);
	p->on_rq = TASK_ON_RQ_QUEUED;

	/* if a worker is waking up, notify workqueue */
	if (p->flags & PF_WQ_WORKER)
		wq_worker_waking_up(p, cpu_of(rq));
}
```

wq\_worker\_waking\_up()函数增加pool\->nr\_running引用计数，表示有一个工作线程马上就会被唤醒，可以投入工作了. 

```c
[kernel/workqueue.c]
void wq_worker_waking_up(struct task_struct *task, int cpu)
{
	struct worker *worker = kthread_data(task);

	if (!(worker->flags & WORKER_NOT_RUNNING)) {
		WARN_ON_ONCE(worker->pool->cpu != cpu);
		atomic_inc(&worker->pool->nr_running);
	}
}
```

worker\_pool\->nr\_running引用计数在workqueue机制中起到非常重要的作用，它是workqueue机制和进程调度器之间的桥梁枢纽. 下面来看引用计数: 

```c
[kernel/workqueue.c]
struct worker_pool {
    atomic_t		nr_running ____cacheline_aligned_in_smp;
	...
}____cacheline_aligned_in_smp;
```

**worker\_pool**数据结构按照**cacheline对齐**，而**nr\_running成员**也是要求和**cacheline对齐**，因为**系统上每个CPU都有可能访问到这个变量**，例如前面看到的schedule()函数和try\_to\_wake\_up()函数，把这个成员放到单独一个cacheline中，有利于提高效率. 

- **工作线程进入执行**时会增加nr\_running 计数，见worker\_thread()\-〉worker\_clr\_flags()函数. 
- 工作线程**退出执行**时会减少nr\_running 计数，见worker\_thread()\-〉worker\_set\_flags()函数. 
- **工作线程进入睡眠**时会减少nr\_running计数，见\_\_schedule()函数. 
- 工作线程**被唤醒时**会增加nr\_running计数，见ttwu\_activate()函数. 

# 6 小结

## 6.1 背景和原理

工作队列的基本原理是把work(需要推迟执行的函数)交由一个**内核线程**来执行，它总是在**进程上下文**中执行. 工作队列的优点是利用进程上下文来执行中断下半部操作，因此工作队列允许**重新调度**和**睡眠**，是**异步执行的进程上下文**，另外它还能解决**软中断**和**tasklet**执行**时间过长**导致系统**实时性下降**等问题. 

早起workqueue比较简单, 由多线程(Multi threaded，每个CPU默认一个工作线程)和单线程(Single threaded, 用户可以自行创建工作线程)组成. 容易导致①内核线程数量太多 ②并发性差(工作线程和CPU是绑定的) ③死锁(同一个队列上的数据有依赖容易死锁)

concurrency\-managed workqueues(CMWQ): BOUND类型(Per\-CPU, 每个CPU一个)和UNBOUND类型, **每种**都有**两个工作线程池(worker\-pool**): 普通优先级的工作(work)使用和高优先级的工作(work)使用. 工作线程池(worker\-pool)中线程数量是动态管理的. 工作线程睡眠时, 检查是否需要唤醒更多工作线程, 有需要则唤醒同一个工作线程池中idle状态的工作线程.

## 6.2 数据结构

工作任务struct work\_struct

```c
[include/linux/workqueue.h]
struct work_struct {
    //低比特位是标志位, 剩余存放上一次运行的worker_pool的ID或pool_workqueue的指针(由WORK_STRUCT_PWQ标志位来决定)
	atomic_long_t data;
	// 把work挂到其他队列上
	struct list_head entry;
	// 工作任务处理函数
	work_func_t func;
};
```

工作线程struct worker

```c
[kernel/workqueue_internal.h]
struct worker {
	/* on idle list while idle, on busy hash table while busy */
	union {
		struct list_head	entry;	/* L: while idle */
		struct hlist_node	hentry;	/* L: while busy */
	};
    // 正在被处理的work
	struct work_struct	    *current_work;	/* L: work being processed */
	// 正在执行的work回调函数
	work_func_t		        current_func;	/* L: current_work's fn */
	// 当前work所属的pool_workqueue
	struct pool_workqueue	*current_pwq;   /* L: current_work's pwq */
	// 所有被调度并正准备执行的work都挂入该链表
	struct list_head	    scheduled;	    /* L: scheduled works */
    // 挂入到worker_pool->workers链表
    struct list_head	    node;		    /* A: anchored at pool->workers */
						                    /* A: runs through worker->node */
	// 工作线程的task_struct
	struct task_struct	    *task;		    /* I: worker task */
	// 该工作线程所属的worker_pool
	struct worker_pool	    *pool;		    /* I: the associated pool */
	// 该工作线程的ID号
	int			            id;		        /* I: worker id */
    ...
};
```

工作线程池struct worker\_pool

```c
[kernel/workqueue.c]
struct worker_pool {
    // 保护worker-pool的自旋锁
	spinlock_t		lock;		/* the pool lock */
	// BOUND类型的workqueue，cpu表示绑定的CPU ID; UNBOUND类型，该值为-1
	int			    cpu;		/* I: the associated cpu */
	// UNBOUND类型的workqueue，表示该worker-pool所属内存节点的ID编号
	int			    node;		/* I: the associated node ID */
	// ID号
	int			    id;		    /* I: pool ID */
	unsigned int	flags;		/* X: flags */
    // pending状态的work会挂入该链表
	struct list_head	worklist;	/* L: list of pending works */
	// 工作线程的数量
	int			        nr_workers;	/* L: total number of workers */
	// idle状态的工作线程的数量
	int			        nr_idle;	/* L: currently idle ones */
    // idle状态的工作线程挂入该链表
	struct list_head	idle_list;	/* X: list of idle workers */
	// 被管理的工作线程会挂入该链表
	struct list_head	workers;	/* A: attached workers */
	// 工作线程的属性
	struct workqueue_attrs	*attrs;		/* I: worker attributes */
	// 正在运行中的worker数量
	atomic_t		nr_running ____cacheline_aligned_in_smp;
	// rcu锁
	struct rcu_head		rcu;
	...
} ____cacheline_aligned_in_smp;
```

连接**workqueue(工作队列**)和**worker\_pool(工作线程池**)的桥梁**struct pool\_workqueue**

```c
[kernel/workqueue.c]
struct pool_workqueue {
    // worker_pool指针
	struct worker_pool	    *pool;		/* I: the associated pool */
	// 工作队列
	struct workqueue_struct *wq;		/* I: the owning workqueue */
	// 活跃的work数量
	int			            nr_active;	/* L: nr of active works */
	// 活跃的work最大数量
	int			            max_active;	/* L: max active works */
	// 被延迟执行的works挂入该链表
	struct list_head	    delayed_works;	/* L: delayed works */
	struct rcu_head		    rcu;
	...
} __aligned(1 << WORK_STRUCT_FLAG_BITS);
```

工作队列struct workqueue\_struct

```c
[kernel/workqueue.c]
struct workqueue_struct {
    // 所有的pool-workqueue数据结构都挂入链表
	struct list_head	pwqs;		/* WR: all pwqs of this wq */
	// 链表节点. 当前workqueue挂入全局的链表workqueues
	struct list_head	list;		/* PL: list of all workqueues */
    // 所有rescue状态下的pool-workqueue数据结构挂入该链表
	struct list_head	maydays;	/* MD: pwqs requesting rescue */
	// rescue内核线程. 创建workqueue时设置WQ_MEM_RECLAIM, 那么内存紧张而创建新的工作线程失败会被该线程接管
	struct worker		*rescuer;	/* I: rescue worker */
    // UNBOUND类型属性
	struct workqueue_attrs	*unbound_attrs;	/* WQ: only for unbound wqs */
	// UNBOUND类型的pool_workqueue
	struct pool_workqueue	*dfl_pwq;	/* WQ: only for unbound wqs */
    // workqueue的名字
	char			name[WQ_NAME_LEN]; /* I: workqueue name */

	/* hot fields used during command issue, aligned to cacheline */
	unsigned int		flags ____cacheline_aligned; /* WQ: WQ_* flags */
	//Per-CPU类型的pool_workqueue
	struct pool_workqueue __percpu *cpu_pwqs; /* I: per-cpu pwqs */
	...
};
```

关系图:

**一个work挂入workqueue**中，最终还要**通过worker\-pool**中的**工作线程来处理其回调函数**，worker-pool是**系统共享的(！！！**)，因此**workqueue**需要查找到一个**合适的worker\-pool**，然后从worker\-pool中分派一个**合适的工作线程**，pool\_workqueue数据结构在其中起到**桥梁**作用. 这有些类似IT类公司的人力资源池的概念，具体关系如图5.7所示. 

![config](./images/11.png)

![config](./images/14.gif)

![config](./images/13.png)

- **work\_struct**结构体代表的是**一个任务**，它指向一个待异步执行的函数，不管驱动还是子系统什么时候要执行这个函数，都必须把**work**加入到一个**workqueue**. 

- **worker**结构体代表一个**工作者线程(worker thread**)，它主要**一个接一个的执行挂入到队列中的work**，如果没有work了，那么工作者线程就挂起，这些工作者线程被worker\-pool管理. 

对于**驱动和子系统**的开发人员来说，接触到的**只有work**，而背后的处理机制是管理worker\-pool和处理挂入的work. 

- **worker\_pool**结构体用来**管理worker**，对于**每一种worker pool**都分**两种情况**: 一种是处理**普通work**，另一种是处理**高优先级的work**. 

- **workqueue\_struct**结构体代表的是**工作队列**，工作队列分**unbound workqueue**和**bound workqueue**. bound workqueue就是**绑定到cpu**上的，**挂入到此队列中的work**只会在**相对应的cpu**上运行. **unbound workqueue不绑定到特定的cpu**，而且**后台线程池的数量也是动态**的，具体**workqueue关联到哪个worker pool**，这是由**workqueue\_attrs决定**的. 

系统初始化阶段(init\_workqueue()): 为**所有CPU(包括离线**的)创建**两个工作线程池worker\_pool**(普通优先级和高优先级); 为每个在线CPU的每个工作线程池(每个CPU有两个)创建一个工作线程(create\_worker); 创建UNBOUND类型和ordered类型的workqueue属性, 分别两个, 对应普通优先级和高优先级, 供后续使用; alloc\_workqueue()创建几个默认的workqueue

- **普通优先级BOUND类型**的**工作队列system\_wq**, 名称为“**events**”，可以理解为**默认工作队列**. 
- **高优先级BOUND类型**的工作队列**system\_highpri\_wq** ，名称为“**events\_highpri**”. 
- **UNBOUND类型**的工作队列**system\_unbound\_wq**，名称为“**system\_unbound\_wq**”. 
- **Freezable类型**的工作队列**system\_freezable\_wq**，名称为“**events\_freezable**”. 
- **省电类型**的工作队列**system\_freezable\_wq**，名称为 “**events\_power\_efficient**”. 

创建工作线程worker(参数是worker\_pool): 获取一个ID; 工作线程池对应的内存节点分配一个worker; 在工作线程池对应的node创建一个内核线程, 名字("**kworker/u \+ CPU\_ID \+ : \+ worker\_idH**", 高优先级的才有H, UNBOUND类型的才有u); 设置线程(worker->task->flags)的PF\_NO\_SETAFFINITY标志位(防止修改CPU亲和性); 工作线程池没有绑定到CPU上, 那么设置worker标志位不绑定CPU; 将worker加到工作线程池的workers链表; 使worker进入idle状态; 唤醒worker的内核线程; 返回该worker

**创建工作队列workqueue**: API很多, 3个参数name, flags和max\_active.

(1) **分配一个workqueue\_struct**并初始化, 对于UNBOUND类型, 创建一个UNBOUND类型的workqueue属性

(2) **分配pool\_workqueue**并初始化alloc\_and\_link\_pwqs()
    
BOUND类型的workqueue: 

- 给**每个CPU**分配一个Per\-CPU的**pool\_workqueue**, 
- 遍历每个CPU, 通过**这个pwq**将系统静态定义的Per\-CPU类型的**高优先级的worker\_pool**(也就是init\_workqueues()初始化的)和**workqueue**连接起来, 并将这个pool\_workqueue添加到传入的workqueue\-\>pwqs链表.

UNBOUND类型和ORDERED类型的workqueue: 都是调用apply\_workqueue\_attrs实现, 不同在于传入的属性一个是ordered\_wq\_attrs[highpri], 一个是unbound\_std\_wq\_attrs[highpri], 这两个不同在于属性里面的no\_numa在ordered中是true, 这两个属性系统初始化阶段完成的. 

- 通过系统**全局哈希表unbound\_pool\_hash**(管理所有UNBOUND类型的work\_pool)根据属性查找**worker\_pool**, 找到将其引用计数加1, 并返回, 没有的话重新分配并初始化一个(创建pool, 为pool创建一个**工作线程worker**<会唤醒线程>), 将新pool加入哈希表
- 分配一个pool\_workqueue
- 初始化该pwq, 将worker\_pool和workqueue\_struct连接起来, 为pool\_workqueue初始化一个**工作work**(通过INIT\_WORK()), 回调函数是pwq\_unbound\_release\_workfn(), 该work执行: 从work中找到相应的pwq, 该work只对UNBOUND类型的workqueue有效, 如果work\-\>pwq\-\>wq\-\>pwqs(所有pool\_workqueue都在这个链表)中当前pool\_workqueue是最后一个, 释放pool\_workqueue相关结构

**初始化一个work**: 宏INIT\_WORK(work, func)

**调度一个work**: schedule\_work(work\_struct), 将work挂入系统默认的BOUND类型的workqueue工作队列system\_wq, queue\_work(workqueue, work)

(1) 关中断

(2) 设置work标志位WORK\_STRUCT\_PENDING\_BIT, 已经有说明正在pending, 已经在队列中, 不用重复添加

(3) 找一个合适的pool\_workqueue. 优先本地CPU或本地CPU的node节点对应的pwq, 如果该work**上次执行的worker\_pool**和刚选择的pwq\-\>pool不等, 并且**该work**正在其**上次执行的工作线程池中运行**，而且运行**这个work的worker对应的pwq**对应的workqueue等于调度**传入的workqueue**(worker\-\>current\_pwq\-\>wq == wq), 则优先选择这个正在运行的worker\-\>current\_pwq. 利用其**缓存热度**.

(4) 判断当前pwq活跃的work数量, 少于最高限值, 加入pwq\-\>pool\-\>worklist(pool的pending链表), 否则加入pwq\-\>delayed\_works(pwq的被延迟执行的works链表)

(5) 当前pwq\-\>pool工作线程池存在pending状态的work并且pool中正运行的worker数量为0的话, 找到pool中第一个idle的worker并唤醒worker\-\>task

(6) 开中断

工作线程处理函数worker\_thread():

```c
worker_thread()
{
recheck:
    if(不需要更多的工作线程?)
        goto 睡眠;
        
    if(需要创建更多的工作线程? && 创建线程)
        goto recheck;
        
    do{
        处理工作;
    }(还有工作待完成 && 活跃的工作线程 <= 1) // 这儿就是keep_working(pool)
    
睡眠:
    schedule();
}
```

- 动态地创建和管理一个工作线程池中的工作线程. 假如发现有PENDING的work且当前工作池中没有正在运行的工作线程(worker\_pool\-\>nr\_running = 0)，那就唤醒idle状态的线程，否则就动态创建一个工作线程. 
- 如果发现一个work己经在同一个工作池的另外一个工作线程执行了，那就不处理该work. 
- 动态管理活跃工作线程数量，见keep\_working()函数. 如果pool\-\>worklist中还有工作需要处理且工作线程池中活跃的线程小于等于1，那么保持当前工作线程继续工作，此功能可以防止工作线程泛滥. 也就是限定活跃的工作线程数量小于等于1.

和调度器交互:

CMWQ机制会动态地调整一个线程池中工作线程的执行情况，不会因为某一个work回调函数执行了阻塞操作而影响到整个线程池中其他work的执行. 

某个work的回调函数func()中执行了睡眠操作(设置当前进程state为TASK\_INTERRUPTIBLE, 然后执行schedule()切换), 在**schedule**()中, 判断**进程的flags是否有PF\_WQ\_WORKER(属于worker线程**), 有的话:

(1) 将**当前worker的worker\_pool中nr\_running引用计数减1**, 如果为0则说明**当前线程池没有活跃的工作线程**, 而**当前线程池的等待队列worklist**有work, 那么从**pool\-\>idle\_list**链表**拿一个idle的工作线程**

(2) 唤醒该工作线程, 增加worker\_pool中nr\_running引用计数

- **工作线程进入执行**时会增加nr\_running 计数，见**worker\_thread**()\-〉worker\_clr\_flags()函数. 
- 工作线程**退出执行**时会减少nr\_running 计数，见worker\_thread()\-〉worker\_set\_flags()函数. 
- **工作线程进入睡眠**时会减少nr\_running计数，见\_\_**schedule**()函数. 
- 工作线程**被唤醒时**会增加nr\_running计数，见ttwu\_activate()函数. 

在驱动开发中使用workqueue是比较简单的，特别是**使用系统默认的工作队列system\_wq**, 步骤如下. 

- 使用**INIT\_WORK**()宏声明一个work和该work的回调函数. 
- **调度一个work**: **schedule\_work**(). 
- **取消一个work**: **cancel\_work\_sync**()
 
此外，有的驱动程序还**自己创建一个workqueue**，特别是**网络子系统**、**块设备子系统**等. 

- 使用**alloc\_workqueue**()创建**新的workqueue**. 
- 使用**INIT\_WORK**()宏声明一个**work**和**该work的回调函数**. 
- 在**新workqueue**上**调度一个work**: **queue\_work**()
- **flush workqueue**上**所有work**: flush\_workqueue()

Linux内核还提供一个**workqueue机制**和**timer机制**结合的**延时机制delayed\_work**

要**理解CMWQ机制**，首先要明白旧版本的workqueue机制遇到了哪些问题，其次要清楚CMWQ机制中几个重要数据结构的关系. **CMWQ机制**把**workqueue**划分为**BOUND类型**和**UNBOUND类型**. 

如图5.8所示是**BOUND类型workqueue机制**的架构图，对于**BOUND类型的workqueue**归纳如下. 

- **每个**新建的workqueue，都有一个struct **workqueue\_struct**数据结构来描述. 
- 对于**每个新建的(！！！)workqueue**，**每个CPU**有**一个pool\_workqueue(！！！**)数据结构来**连接workqueue**和**worker\_pool**.
- **每个CPU只有两个worker\_pool**数据结构来描述**工作池**，一个用于**普通优先级工作线程**，另一个用于**高优先级工作线程**. 
- **worker\_pool**中可以有**多个工作线程**，动态管理工作线程. 
- **worker\_pool**和**workqueue**是**1:N(！！！**)的关系，即**一个worker\_pool**可以对应**多个workqueue**.
- pool\_workqueue是worker\_pool和workqueue之间的桥梁枢纽. 
- **worker\_pool(！！！**)和**worker工作线程(！！！**)也是**1:N(！！！**)的关系. 

![config](./images/12.png)

**BOUND类型的work**是在**哪个CPU**上运行的呢？有几个API接口可以把**一个work**添加到**workqueue**上运行，其中**schedule\_work**()函数**倾向于使用本地CPU**，这样有利于利用**CPU的局部性原理**提高效率，而**queue\_work\_on**()函数可以**指定CPU**的. 

对于**UNBOUND类型的workqueue**来说，其**工作线程没有绑定到某个固定的CPU**上. 对于**UMA**机器，它可以在**全系统的CPU**内运行；对于**NUMA**机器，**每一个node**节点**创建一个worker\_pool**. 

在**驱动开发**中，**UNBOUND类型**的**workqueue不太常用**，举一个典型的例子，Linux内核中有一个**优化启动时间(boot time**)的新接口Asynchronous functioncalls，实现是在kernel/asyn.c文件中. 对于一些**不依赖硬件时序**且不需要串行执行的初始化部分，可以采用这个接口，现在电源管理子系统中有一个选项可以把一部分外设在suspend/resume过程中的操作用异步的方式来实现，从而优化其suspend/resume时间，详见kemel/power/main.c 中关于“pm\_async\_enabled” 的实现. 

对于**长时间占用CPU资源**的一些负载(标记**WQ\_CPU\_INTENSIVE**), Linux内核倾向于**使用UNBOUND类型的workqueue**, 这样可以利用**系统进程调度器**来优化选择在哪个CPU上运行，例如**drivers/md/raid5.c**驱动. 

如下动态管理技术值得读者仔细品味. 

- 动态管理**工作线程数量**，包括**动态创建工作线程**和**动态管理活跃工作线程**等. 
- 动态**唤醒工作线程**. 