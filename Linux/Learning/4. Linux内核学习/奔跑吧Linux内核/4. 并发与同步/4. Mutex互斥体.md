
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [0 概述和历史](#0-概述和历史)
* [1 Mutex互斥体的数据结构](#1-mutex互斥体的数据结构)
* [2 MCS锁机制](#2-mcs锁机制)
	* [2.1 OSQ锁的数据结构](#21-osq锁的数据结构)
	* [2.2 MCS锁初始化](#22-mcs锁初始化)
	* [2.3 申请MCS锁](#23-申请mcs锁)
	* [2.4 释放MCS锁](#24-释放mcs锁)
* [3 Mutex锁的实现](#3-mutex锁的实现)
	* [3.1 Mutex锁初始化](#31-mutex锁初始化)
	* [3.2 Mutex锁申请](#32-mutex锁申请)
		* [3.2.1 慢车道\_\_mutex\_lock\_slowpath()申请](#321-慢车道__mutex_lock_slowpath申请)
	* [3.3 mutex释放锁](#33-mutex释放锁)
* [4 小结](#4-小结)
	* [4.1 MCS锁](#41-mcs锁)
	* [4.2 Mutex锁](#42-mutex锁)

<!-- /code_chunk_output -->


思考如下问题.

- Linux内核已经实现了信号量机制, 为何要单独设置一个**Mutex机制**呢？
- 请简述**MCS锁**机制的实现原理. 
- 在编写内核代码时, 该如何选择**信号量**和**Mutex**?

# 0 概述和历史

在**Linux内核**中, **除信号量以外**, 还有一个类似的实现叫作**互斥体Mutex**. **信号量**是在**并行处理环境**中对**多个处理器**访问**某个公共资源**进行**保护的机制**, **Mutex**用于**互斥操作**. 

信号量根据**初始化count的大小**, 可以分为**计数信号量**和**互斥信号量**. 根据操作系统书籍上著名的**洗手间理论**, **信号量**相当于一个可以**同时容纳N个人的洗手间**, 只要人不满就可以进去, 如果人满了就要在外面等待.  Mutex类似街社的**移动洗手间**, 每次只能**一个人进去**, 里面的人出来后才能让排队中的下一个人使用. 那既然**Mutex类似count计数等于1的信号量(！！！**), 为什么内核社区要重新开发Mutex, 而不是复用信号量的机制呢？

Mutex最早是在Linux 2.6.16中由RedHat公司的资源内核专家 Ingo Molnar 设计和实现的. 信号量的count成员可以初始化为1, 并且DOWN和UP操作也可以实现类似Mutex的作用, 那为什么要单独实现Mutex机制呢？在设计之初, Ingo Molnar解释信号量在Linux内核中的实现没有任何问题, 但是**Mutex的语义**相对于信号量要**简单轻便一些**, 在锁争用激烈的测试场景下, **Mutex比信号量执行速度更快**, 可扩展性更好, 另外**Mutex数据结构的定义比信号量小**, 这些都是在Mutex设计之初Ingo Molnar提到的优点. Mutex上的一些优化方案己经移植到了读写信号量中, 例如自旋等待已应用在读写信号量上. 

# 1 Mutex互斥体的数据结构

下面来看**Mutex数据结构**的定义. 

```c
[include/linux/mutex.h]
struct mutex {
	/* 1: unlocked, 0: locked, negative: locked, possible waiters */
	atomic_t		count;
	spinlock_t		wait_lock;
	struct list_head	wait_list;
#if defined(CONFIG_MUTEX_SPIN_ON_OWNER)
	struct task_struct	*owner;
#endif
#ifdef CONFIG_MUTEX_SPIN_ON_OWNER
	struct optimistic_spin_queue osq; /* Spinner MCS lock */
#endif
};
```

- count: **原子计数**, **1**表示**没人持有锁**; **0**表示**锁被持有**; **负数**表示**锁被持有**且**有人在等待队列中等待**. 
- wait\_lock: **spinlock锁**, 用于**保护wait\_list睡眠等待队列**. 
- wait\_list: 用于管理所有**在该Mutex上睡眠的进程**, 没有成功获取锁的进程会睡眠在此链表上. 
- owner: 要打开**CONFIG\_MUTEX\_SPIN\_ON\_OWNER(一般都会开启**)选项才会有owner, 用于指向**锁持有者的task\_struct数据结构**. 
- osq: 用于实现**MCS锁机制**, 对应的那个MCS锁. 

**Mutex**实现了**自旋等待的机制(optimistic spinning**), 准确地说, 应该是**Mutex**比读写**信号量**更早地实现了自旋等待机制. 

**自旋等待机制**的核心原理是当发现**持有锁者正在临界区执行**并且**没有其他优先级高的进程**要被调度(need\_resched)时, 那么**当前等待进程**坚信锁持有者会很快离开临界区并释放锁, 因此与其睡眠等待不如乐观地自旋等待, 以**减少睡眠唤醒的开销**. 

在实现**自旋等待机制**时, 内核实现了一套**MCS锁机制**来保证**只有一个人自旋等待(！！！)持锁者释放锁**. 

# 2 MCS锁机制

**MCS锁**是一种**自旋锁的优化方案**, 它是由两个发明者Mellor\-Crummey和Scott的名字来命名的. 自旋锁是Linux内核使用**最广泛的一种锁机制(！！！**).在Linux 2.6.25内核中**自旋锁**已经采用**排队自旋算法**进行优化, 以**解决早期自旋锁争用不公平**的问题. 但是在**多处理器和NUMA系统**中, **排队自旋锁**仍然存在一个**比较严重的问题**. 假设在一个锁争用激烈的系统中, **所有自旋等待锁的线程**都在**同一个共享变量**上**自旋**, **申请和释放锁**都在**同一个变量**上修改, 由**cache一致性原理(例如MESI协议**)导致**参与自旋的CPU**中的**cache line变得无效**. 在锁争用激烈过程中, 导致严重的**CPU高速缓存行颠簸现象(CPU cache line bouncing**)现象, 即**多个CPU上的cache line反复失效**, 大大降低系统整体性能. 

**MCS算法**可以解决自旋锁遇到的问题, 显著**减少CPU cache line bouncing问题(！！！**). 

MCS算法的核心思想是**每个锁的申请者**只在**本地CPU**的**变量上自旋**, 而**不是全局的变量**. 虽然MCS算法的设计是**针对自旋锁**的, 但是目前Linux 4.0内核中依然**没有把MCS算法用在自旋锁**上, 其中一个很重要的原因是**MCS算法的实现**需要**比较大的数据结构**, 而**spinlock**常常嵌入到系统中一些比较**关键的数据结构**中, 例如物理页面数据结构struct page, 这类数据结构对**大小相当敏感**, 因此目前**MCS算法**只用在**读写信号量**和**Mutex的自旋等待机制(！！！**)中. 

Linux内核版本的**MCS锁**最早是由社区专家Waiman Long在Linux 3.10中实现的, 后来经过其他的社区专家的不断优化后成为现在的**osq\_lock**, 可以说**OSQ锁**是**MCS锁机制**的**一个具体的实现**, 本节内容混用了这两个概念. 

## 2.1 OSQ锁的数据结构

MCS锁本质上是一种**基于链表结构的自旋锁(！！！**), OSQ锁的实现需要**两个数据结构**. 

```c
[include/linux/osq_lock.h]
struct optimistic_spin_node {
	struct optimistic_spin_node *next, *prev;
	int locked; /* 1 if lock acquired */
	int cpu; /* encoded CPU # + 1 value */
};

struct optimistic_spin_queue {
	/*
	 * Stores an encoded value of the CPU # of the tail node in the queue.
	 * If the queue is empty, then it's set to OSQ_UNLOCKED_VAL.
	 */
	atomic_t tail;
};
```

**每个MCS锁**有一个**optimistic\_spin\_queue(！！！**)数据结构, 该数据结构只有一个成员**tail, 初始化为0**, 指向**链表尾部的CPU编号\<MCS重新编的**\>. 

struct optimistic\_spin\_node数据结构表示**本地CPU上的节点(！！！**), 它可以组织成一个**双向链表(！！！**), 包含**next和prev指针**, lock成员用于表示**加锁状态**, cpu成员用于**重新编码CPU编号**, 表示该node是在**哪个CPU上**. 也就是说**MCS链表是通过Per\-CPU的optimistic\_spin\_node实现的！！！**

**struct optimistic\_spin\_node**数据结构会定义成**per\-CPU变量(！！！**), 即**每个CPU有一个node结构(！！！**). 

```c
[kernel/locking/osq_lock.c]
static DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);
```

## 2.2 MCS锁初始化

MCS锁在**osq\_lock\_init**()函数中初始化, 例如**Mutex初始化**时会**初始化一个MCS锁(配置了CONFIG\_MUTEX\_SPIN\_ON\_OWNER**), 详见\_\_mutex\_init()函数中的**osq\_lock\_init**()函数. 

```c
[kernel/locking/mutex.c]
void
__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)
{
	atomic_set(&lock->count, 1);
	spin_lock_init(&lock->wait_lock);
	INIT_LIST_HEAD(&lock->wait_list);
	mutex_clear_owner(lock);
#ifdef CONFIG_MUTEX_SPIN_ON_OWNER
	osq_lock_init(&lock->osq);
#endif

	debug_mutex_init(lock, name, key);
}
EXPORT_SYMBOL(__mutex_init);

[include/linux/osq_lock.h]
static inline void osq_lock_init(struct optimistic_spin_queue *lock)
{
	atomic_set(&lock->tail, OSQ_UNLOCKED_VAL);
}
```

## 2.3 申请MCS锁

**osq\_lock**()函数用于**申请MCS锁**, 下面来看该函数是如何实现的. 

参数就是**想要申请的MCS锁对应的optimistic\_spin\_queue**, 总结:

(1) 获取**当前进程所在CPU**的struct optimistic\_spin\_node节点(这是Per\-CPU的)

(2) 给当前CPU编号, 0表示没有CPU, 1表示CPU0, 类推

(3) 将**lock\-\>tail设置为当前CPU编号**

(4) **原有tail**等于OSQ\_UNLOCKED\_VAL(也就是**0**)那么说明**没有CPU持锁**, 直接**退出返回True**

(5) 通过获得原有tail的CPU节点optimistic\_spin\_node(这是Per\-CPU的)

(6) 将当前optimistic\_spin\_node节点加入MCS链表(通过Per\-CPU的optimistic\_spin\_node实现)

(7) while循环, 查询当前optimistic\_spin\_node节点的locked是否是1(因为前继节点释放锁会将其下一节点的locked设为1, 然后释放锁), 如果是1, 说明前继节点释放了锁, 那么当前进程退出自旋, 直接退出返回True

(8) while循环, 判断不为1, 当前进程自旋等待: 里面判断下是否需要重新调度(更高优先级进程抢占或被调度器要求调度), 是的话放弃自旋等待, 退出MCS链表, 删除MCS链表节点, 退出返回False

```c
[kernel/locking/osq_lock.c]
bool osq_lock(struct optimistic_spin_queue *lock)
{
    // 位置1
	struct optimistic_spin_node *node = this_cpu_ptr(&osq_node);
	struct optimistic_spin_node *prev, *next;
	// 位置2
	int curr = encode_cpu(smp_processor_id());
	int old;

	node->locked = 0;
	node->next = NULL;
	node->cpu = curr;
    // 位置3
	old = atomic_xchg(&lock->tail, curr);
	if (old == OSQ_UNLOCKED_VAL)
		return true;
```

位置1, node指向**当前CPU**的struct optimistic\_spin\_node节点. 

位置2, struct optimistic\_spin\_node数据结构中**cpu成员**用于表示**CPU编号**, 它的**编号方式和CPU编号方式不太一样**, **0表示没有CPU** , **1表示CPU0**, 以此类推. 

位置3, 使用**原子交换函数atomic\_xchg**()交换**全局lock->tail和当前CPU编号**, 如果**lock->tail的旧值等于初始化值OSQ\_UNLOCKED\_VAL**(值为0), 说明还**没有人持有锁**, 那么让**lock\->tail等于当前CPU编号**表示**当前CPU成功持有了锁**, 这是最快捷的方式. 如果lock\->tail的旧值**不等于**OSQ\_UNLOCICED\_VAL, 获取锁失败. 下面看看**如果没能成功获取锁**的情况, 即**lock\->tail的值指向其他CPU编号**, 说明**有人持有了该锁**. 

```c
[osq_lock()]
    prev = decode_cpu(old);
    // 位置1
	node->prev = prev;
	ACCESS_ONCE(prev->next) = node;

    // 位置2
	while (!ACCESS_ONCE(node->locked)) {
		/*
		 * If we need to reschedule bail... so we can block.
		 */
		// 位置3
		if (need_resched())
			goto unqueue;

		cpu_relax_lowlatency();
	}
	return true;
```

之前获取锁失败, 变量old的值(**lock->tail的旧值**)指向某个CPU编号, 那么**decode\_cpu**()函数返回的是**变量old指向的CPU所属的节点**. 

位置1后两行代码, 把**当前curr\_node节点**插入**MCS链表**中, **当前节点**curr\_node\->prev指向**前继节点**, 而前继节点prev\_node\->next指向当前节点. 

位置2, **while循环**一直**查询当前节点curr\_node->locked是否变成了1**, 因为**前继节点prev\_node释放锁**时会把它的**下一个节点中的locked成员设置为1(！！！**), 然后才能成功**释放锁**. 在理想情况下, **前继节点释放锁**, 那么**当前进程也退出自旋**, 返回true. 

位置3, 在**自旋等待过程**中, 如果有**更高优先级进程抢占**或者**被调度器要求调度出去**, 那应该**放弃自旋等待**, **退出MCS链表(！！！**), 跳转到unqueue标签处处理**MCS链表删除节点**的情况. unqueue标签处是异常情况处理, 正常情况是要在while循环中等待锁. 

OSQ锁的实现比较复杂的原因在于**OSQ锁**必须要处理**need\_resched**()的异常情况, 否则可以设计得很简洁. 

unqueue标签处实现**删除链表操作**, 这里仅仅使用了原子比较交换指令, 并没有使用其他的锁, 这是无锁并发编程的精髓体现. 

```c
[osq_lock()]
unqueue:
	/*
	 * Step - A  -- stabilize @prev
	 *
	 * Undo our @prev->next assignment; this will make @prev's
	 * unlock()/unqueue() wait for a next pointer since @lock points to us
	 * (or later).
	 */

	for (;;) {
	    // 位置1
		if (prev->next == node &&
		    cmpxchg(&prev->next, node, NULL) == node)
			break;

		/*
		 * We can only fail the cmpxchg() racing against an unlock(),
		 * in which case we should observe @node->locked becomming
		 * true.
		 */
		// 位置2
		if (smp_load_acquire(&node->locked))
			return true;

		cpu_relax_lowlatency();

		/*
		 * Or we race against a concurrent unqueue()'s step-B, in which
		 * case its step-C will write us a new @node->prev pointer.
		 */
		// 位置3
		prev = ACCESS_ONCE(node->prev);
	}

	/*
	 * Step - B -- stabilize @next
	 *
	 * Similar to unlock(), wait for @node->next or move @lock from @node
	 * back to @prev.
	 */

	next = osq_wait_next(lock, node, prev);
	if (!next)
		return false;

	/*
	 * Step - C -- unlink
	 *
	 * @prev is stable because its still waiting for a new @prev->next
	 * pointer, @next is stable because our @node->next pointer is NULL and
	 * it will wait in Step-A.
	 */

	ACCESS_ONCE(next->prev) = prev;
	ACCESS_ONCE(prev->next) = next;

	return false;
```

删除MCS链表节点分为3步.

(1) 解除前继节点(prev\_node)的next指针的指向.

(2) 解除当前节点(curr\_node)的next指针的指向, 并且找出当前节点下一个确定的节点next\_node. 

(3) 让前继节点prev\_node\->next指向next\_node, next\_node\->prev指针指向prev\_node.

位置1, prev\_node节点是之前获取的前继节点. 如果前继节点的next指针指向当前节点, 说明这期间还没有人来修改链表, 接着用cmpxchg()函数原子地判断前继节点的next指针是否指向当前节点. 如果是, 则把prev\->next指针指向NULL, 并且判断返回的前继节点的next指针是否指向当前节点. 如果上述判断都正确, 那么就达到步 骤 (1 ) 解除前继节点next指针指向的目的了. 

位置2, 如果上述原子比较并交换指令判断失败, 说明这期间有人修改了MCS链表. 利用这个间隙, smp\_load\_acquire()宏再一次判断当前节点是否持有了锁. smp\_load\_acquire()宏定义如下: 

```c
[arch/arm/include/asm/barrier.h]
#define smp_load_acquire(p)						\
({									\
	typeof(*p) ___p1 = ACCESS_ONCE(*p);				\
	compiletime_assert_atomic_type(*p);				\
	smp_mb();							\
	___p1;								\
})
```

ACCESS\_ONCE()宏使用volatile关键字强制重新加载p的值, smp\_mb()保证内存屏障之前的读写指令都执行完毕. 如果这时判断当前节点curr\_node->locked为1, 说明当前节点持有了锁, 返回true. 读者可能会有疑问, 为什么当前节点莫名其妙地持有了锁呢？这是前继节点释放锁并且把锁传递给当前节点的. 

位置3, 之前cmpxchg()判断失败说明当前节点的前继节点prev\_node发生了变化, 这里重新加载新的前继节点, 继续下一次循环. 

步骤(1)是处理前继节点prev\_node的next指针指向问题, 步骤(2)处理当前节点curr\_node的 next指针指向问题, 关键实现是在osq\_wait\_next()函数里. 

```c
[osq_lock() ->osci_wait_next()]
[kernel/locking/osq_lock.c]

static inline struct optimistic_spin_node *
osq_wait_next(struct optimistic_spin_queue *lock,
	      struct optimistic_spin_node *node,
	      struct optimistic_spin_node *prev)
{
	struct optimistic_spin_node *next = NULL;
	int curr = encode_cpu(smp_processor_id());
	int old;

	old = prev ? prev->cpu : OSQ_UNLOCKED_VAL;

	for (;;) {
	    // 位置1
		if (atomic_read(&lock->tail) == curr &&
		    atomic_cmpxchg(&lock->tail, curr, old) == curr) {
			break;
		}
        // 位置2
		if (node->next) {
			next = xchg(&node->next, NULL);
			if (next)
				break;
		}

		cpu_relax_lowlatency();
	}

	return next;
}
```

变量curr指当前进程所在的CPU编号, 变量old指前继节点prev\_node所在的CPU编号. 如果前继节点为空, 那么old值为0. 

位置1, 判断当前节点curr\_node是否为MCS链表中的最后一个节点, 如果是, 说明当前节点是队列尾, 即没有后继节点, 直接返回next为NULL. 为什么利用原子地判断lock\->tail值是否等于curr即可判断当前节点是否在队列尾呢？

如图4.2所示, 如果当前节点curr\_node是MCS链表的队列尾, curr值和lock\->tail值相等. 如果在这期间有人正在申请锁, 那么curr值为2, 但是lock\->tail值会变成其他值, 这是osq\_lock()函数的第11行代码中的atomic\_xchg()函数修改了lock\->tail值. 如图4.2所示, CPU2 加入该锁的争斗, lock\->tail=3. 

![config](./images/6.png)

位置2, 如果当前节点curr\_node有后继节点, 那么把当前节点curr\_node\->next指针设置为NULL, 解除当前节点next指针的指向, 并且返回后继节点next\_node, 这样就完成了步骤(2)的目标. 第23行的cpu\_relax\_lowlatency()函数在ARM中是一条barrier()指令. 

步骤(3), 后继节点next\_node的prev指针指向前继节点prev\_node, 前继节点prev\_node的next指针指向后继节点next\_node, 这样就完成了当前节点curr\_node脱离MCS链表的操作. 最后返回false, 因为没有成功获取锁. 

如图4.3所示是MCS锁的架构图. 

![config](./images/7.png)

## 2.4 释放MCS锁

总结:

(1) lock\-\>tail刚好是当前CPU编号, 说明没人竞争锁, 直接将lock\-\>tail设为0, 退出

(2) 后继节点存在, 将后继节点的next\_node\-\>locked设为1, 相当于传递锁

(3) 后继节点为空, 说明有人擅自离队, 那么重新确定或等待后继节点

接下来看MCS锁是如何解锁的. 

```c
[kernel/locking/osq_lock.c]
void osq_unlock(struct optimistic_spin_queue *lock)
{
	struct optimistic_spin_node *node, *next;
	int curr = encode_cpu(smp_processor_id());

	/*
	 * Fast path for the uncontended case.
	 */
	// 位置1
	if (likely(atomic_cmpxchg(&lock->tail, curr, OSQ_UNLOCKED_VAL) == curr))
		return;

	/*
	 * Second most likely case.
	 */
	node = this_cpu_ptr(&osq_node);
	next = xchg(&node->next, NULL);
	if (next) {
		ACCESS_ONCE(next->locked) = 1;
		return;
	}

	next = osq_wait_next(lock, node, NULL);
	if (next)
		ACCESS_ONCE(next->locked) = 1;
}
```

位置1, 如果lock\->tail保存的CPU编号正好是当前进程的CPU编号, 说明没有人来竞争该锁, 那么直接把lock->tail设置为0 释放锁, 这是最理想的情况, 代码中把此情况描述为"fastpath"快车道. 注意此处依然要使用原子比较交换函数atomic\_cmpxchg(). 

下面进入慢车道, 首先当前节点的next指针指向NULL. 如果当前节点有后继节点, 那么把后继节点next\_node->locked 成员设置为1 , 相当于把锁传递给后继节点, 这里相当于告诉后继节点, 锁己经传递给你了. 

如果后继节点next\_node为空, 说明在执行osq\_unlock()期间有人擅自离队, 那么只能调用osq\_wait\_next()函数来确定或者等待确定的后继节点, 也许当前节点就在队列尾, 当然也会有"后继无人"的情况. 

# 3 Mutex锁的实现

## 3.1 Mutex锁初始化

**Mutex锁的初始化**有两种方式, 一种是**静态使用DEFINE\_MUTEX宏**, 另一种是在内核代码中**动态使用mutex\_init()函数**. 

```c
[include/linux/mutex.h]
#define DEFINE_MUTEX(mutexname) \
	struct mutex mutexname = __MUTEX_INITIALIZER(mutexname)
	
#define __MUTEX_INITIALIZER(lockname) \
		{ .count = ATOMIC_INIT(1) \
		, .wait_lock = __SPIN_LOCK_UNLOCKED(lockname.wait_lock) \
		, .wait_list = LIST_HEAD_INIT(lockname.wait_list) 
		}
```

## 3.2 Mutex锁申请

传参是mutex锁, 总结:

(1) 如果mutex\->count减1**等于0**, 说明没人持有锁, 直接**申请成功(快车道**)

(2) 如果小于0, 说明已经被人持有, 慢车道申请

(3) 如果最终拿到锁后, 设置**mutex\-\>owner为当前进程(释放时候会置位NULL, 就是根据这个判断是否释放锁**)

(4) 退出

看**mutex\_lock**()函数是如何实现的. 

```c
[kernel/locking/mutex.c]
void __sched mutex_lock(struct mutex *lock)
{
	might_sleep();
	/*
	 * The locking fastpath is the 1->0 transition from
	 * 'unlocked' into 'locked' state.
	 */
	__mutex_fastpath_lock(&lock->count, __mutex_lock_slowpath);
	// 位置1
	mutex_set_owner(lock);
}
EXPORT_SYMBOL(mutex_lock);
```

进入申请Mutex锁的快车道的条件是**count计数原子地减1后等于0**. 如果count计数原子地减1之后**小于0**, 说明该锁**己经被人持有**, 那么要进入**慢车道\_\_mutex\_lock\_slowpath**(). 

位置1, mutex\_set\_owner()和读写信号量一样, 在**成功持有锁**之后要设置**lock\->owner**指向**当前进程的task\_struct**数据结构. 

### 3.2.1 慢车道\_\_mutex\_lock\_slowpath()申请

总结:

(1) 关**内核抢占**

(2) 自旋等待获取锁**成功**, **打开抢占**, **退出**

(2.1) 锁持有者没有正在运行(锁持有者在临界区执行时被调度出去了, 也就是睡眠了, 即on\_cpu=0), 不符合自旋等待条件; 或调度器需要调度其他进程(need\_resched()), 当前进程也只能被迫退出自旋等待, 去(2.5)

(2.2) 申请OSQ锁(即MCS锁), 因为多人参与自旋等待导致CPU cache line bouncing(CPU高速缓存行颠簸), 这里将所有等待Mutex的参与者放入OSQ锁队列, 只有第一个等待者才参与自旋等待, 如果申请失败, 去(2.5)

(2.3) while循环自旋

(2.3.1) 通过lock\-\>owner获取当前锁持有者进程

(2.3.2) 自旋等待锁持有者尽快释放锁: ①while循环: 判断锁持有者是否正在运行, 若(锁持有者释放锁, 即lock\-\>owner不指向锁持有者<即**锁持有者变化**了>, 跳出当前循环, 去②步骤); 若(锁持有者在临界区执行时被调度出去了, 也就是睡眠了, 即on\_cpu=0), 跳出当前循环, 去②; 若调度器需要调度其他进程(need\_resched()), 跳出当前循环,去②步骤. ②返回lock\-\>owner == NULL(①里面的锁持有者变化, 但是不是给当前进程, 其他用了); **只有释放锁才为true**. 如果返回false(非释放锁退出), 跳出(**2.3)循环**, 去(2.4) ; 否则继续(为NULL, 释放了锁)

(2.3.3) **持有者已经释放了锁**, 当前进程获取锁: 判断lock\-\>count是否为1, 1的话将count设为0, 成功获得锁, **设置lock\-\>owner为当前进程**, 释放OSQ锁, **完全退出**; 不为1, 继续

(2.3.4) owner为NULL并且调度器需要调度, 跳出(2.3)循环, 退出自旋等待, 去(2.4); 当前进程是实时进程, 跳出循环, 退出自旋等待, 去(2.4)

(2.4) 释放OSQ锁

(2.5) 自旋等待获锁失败, 如果调度器需要调度, 让出CPU, 当前进程进入睡眠状态, 返回false

(3) **自旋等待获取锁失败**, 再尝试获取一次, 成功, 去(7) , 否则继续

(4) 将**当前进程的struct mutex\_waiter(每次申请都会有一个**)加入**mutex等待队列wait\_list**, 这里是**先进先出队列**

(5) 循环: 尝试获取锁, 获取失败, 让出CPU, 进入睡眠态; 睡眠进程被唤醒之后成功获取了锁, 退出当前循环, 或者收到异常信号

(6) 成功获取锁而退出循环, 设置当前进程为运行态, 并从等待队列出列, 如果等待队列没有睡眠等待, 设置lock\-\>count为0(表明锁正被人持有且队列无人)

(7) 既然成功获取锁, 设置owner位当前进程, 并打开内核抢占, 退出

\_\_mutex\_lock\_slowpath()函数调用\_\_mutex\_lock\_common()来实现. 

```c
[mutex_lock() -> __mutex_lock_common()]
[kernel/locking/mutex.c]
static __always_inline int __sched
__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,
		    struct lockdep_map *nest_lock, unsigned long ip,
		    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)
{
	struct task_struct *task = current;
	struct mutex_waiter waiter;
	unsigned long flags;
	int ret;
    // 位置1
	preempt_disable();
    // 位置2
	if (mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx)) {
		/* got the lock, yay! */
		preempt_enable();
		return 0;
	}
    ...
}
```

位置1, 关闭内核抢占

位置2, mutex\_optimistic\_spin()函数实现**自旋等待机制**, 这里的实现与读写信号量一样. 该函数比较长, 简化后的代码片段如下: 

```c
[mutex_lock() -> __mutex_lock_common() -> mutex_optimistic_spin()]
[kernel/locking/mutex.c]
static bool mutex_optimistic_spin(struct mutex *lock,
				  struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)
{
	struct task_struct *task = current;
    // 位置1
	if (!mutex_can_spin_on_owner(lock))
		goto done;
    // 位置2
	if (!osq_lock(&lock->osq))
		goto done;
    // 位置3
	while (true) {
		struct task_struct *owner;

		owner = ACCESS_ONCE(lock->owner);
		// 位置4
		if (owner && !mutex_spin_on_owner(lock, owner))
			break;

		/* Try to acquire the mutex if it is unlocked. */
		// 位置5
		if (mutex_try_to_acquire(lock)) {
			mutex_set_owner(lock);
			osq_unlock(&lock->osq);
			return true;
		}
        // 位置6
		if (!owner && (need_resched() || rt_task(task)))
			break;

		cpu_relax_lowlatency();
	}

	osq_unlock(&lock->osq);
done:
    // 位置7
	if (need_resched()) {
		schedule_preempt_disabled();
	}
	return false;
}
```

位置1, mutex\_can\_spin\_on\_owner()函数与之前读写信号量中的rwsem\_can\_spin\_on\_owner()实现类似, 下面是mutex\_can\_spin\_on\_owner()的实现

```c
[mutex_lock() -> mutex_optimistic_spin() -> mutex_can_spin_on_owner()]
[kernel/locking/mutex.c]
static inline int mutex_can_spin_on_owner(struct mutex *lock)
{
	struct task_struct *owner;
	int retval = 1;

	if (need_resched())
		return 0;
    //位置1
	rcu_read_lock();
	owner = ACCESS_ONCE(lock->owner);
	if (owner)
		retval = owner->on_cpu;
	// 位置2
	rcu_read_unlock();
	return retval;
}
```

当**进程持有Mutex锁**时, **lock\-\>owner**指向**该进程的task\_struct**数据结构, **task\_struct\-\>on\_cpu为1**表示**锁持有者正在运行**, 也就是**正在临界区中执行**, 因为**锁持有者释放该锁**后lock\-\>owner指向**NULL**. 

位置1和位置2代码使用了**RCU机制**来**构造一个读临界区**, 主要是为了**保护ower指针指向的struct task\_struct**数据结构**不会因为进程被杀**之后**导致访问ower指针出错**, **RCU读临界区**可以**保护ower指向的task\_struct**数据结构**在读临界区内不会被释放**. 后续在第4.7节中会详细介绍RCU的使用. 

回到mutex\_optimistic\_spin()函数中, 位置1, **返回0**说明**锁持有者并没有正在运行(锁持有者在临界区执行时被调度出去了, 也就是睡眠了, 即on_cpu=0**), 不符合自旋等待机制的条件. 在读写信号量中曾介绍过, **自旋等待**的条件是**持有锁者正在临界区执行**, 自旋等待才有价值. 

位置2, 获取一个**OSQ锁**来进行保护, OSQ锁是自旋锁的一种优化方案, 为什么要申请MCS锁呢？因为接下来要**自旋等待该锁尽快释放**, 因此不希望有其他人参与进来一起自旋等待, **多人参与自旋等待**会导致严重的**CPU高速缓存行颠簸(CPU cacheline bouncing**). 这里把**所有在等待Mutex(！！！**)的参与者**放入OSQ锁的队列(！！！**)中, **只有队列的第一个等待者**可以参与**自旋等待**. 

位置3, **while循环**会**一直自旋**并且**判断锁持有者是否释放了锁**. 其中位置4代码中的 **mutex\_spin\_on\_owner**() 函数一直**自旋等待锁持有者尽快释放锁**. 

```c
[mutex_lock() -> mutex_optimistic_spin() -> mutex_spin_on_owner()]
static noinline
int mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner)
{
	rcu_read_lock();
	while (owner_running(lock, owner)) {
	    // 位置1
		if (need_resched())
			break;

		cpu_relax_lowlatency();
	}
	rcu_read_unlock();
	return lock->owner == NULL;
}
```

为什么mutex\_spin\_on\_owner()函数可以**判断持有锁者是否释放了锁**？在mutex\_lock()函数位置1中, 即**成功获取了锁之后**, 会**设置lock\-\>owner**指向**持有锁的进程的task\_struct**数据结构, 当**释放锁时会把lock\-\>owner设置为NULL**. 

```c
[kernel/locking/mutex.c]
static inline bool owner_running(struct mutex *lock, struct task_struct *owner)
{
	if (lock->owner != owner)
		return false;

	barrier();
	return owner->on_cpu;
}
```

所以在**owner\_running**()函数里只要**判断lock\-\>owner**是否还指向**持有锁的struct task\_struct**数据结构即可知道**是否释放了锁**. 另外如果lock\-\>owner还指向锁持有者的struct task\_struct结构, 那么该函数返回持有锁者的task\_struct\-\>on\_cpu值. 

回到mutex\_spin\_on\_owner()函数中, owner\_running()函数返回**false**, 那么**当前进程**就**没有必要在while循环里一直监视持有锁者**的情况了. 

有**两种情况**导致**退出自旋**, 

- 一是**锁持有者释放了锁**, 即**lock\->owner不指向锁持有者**或者**锁持有者发生了变化(！！！**); 
- 二是**锁持有者没有释放锁**, 但是**锁持有者**在**临界区执行时被调度出去**了, 也就是**睡眠**了, 即**on\_cpu=0**. 

在这两种情况下, **当前进程**都应该**积极主动退出自旋等待机制**. 除此之外, 如果这个过程中**调度器需要调度其他进程(！！！**), 那么**当前进程**也只能被迫**退出自旋等待**, 见位置1代码中的need\_resched()函数. 

mutex\_spin\_on\_owner()函数返回一个判断值, 即**lock\-\>owner==NULL**, **持有锁者释放锁**, **返回true**.

回到mutex\_optimistic\_spin()函数的位置5代码, 既然**持有锁者己经释放了锁**, 那么**当前进程**调用**mutex\_try\_to\_acquire**()函数去尝试**获取该锁**. 

```c
static inline int mutex_is_locked(struct mutex *lock)
{
    return atomic_read (&lock->count) !=1 ;
}

static inline bool mutex_try_to_acquire (struct mutex *lock)
{
    return !mutex_is_locked (lock) &&
        (atomic_cmpxchg (&lock->count, 1, 0) == 1);
}
```

mutex\_try\_to\_acquire()函数首先读取**原子变量lock\-\>count**的值, 判断**是否为1**, 如果是1, 那么使用atomic\_cmpxchg()函数把count设置为0, **成功获取了锁**. 

mutex\_try\_to\_acquire()函数为什么首先调用atomic\_read()原子读函数去判断lock->count是否为1, 再调用atomic\_cmpxchg()函数去原子比较判断呢？为什么不直接调用atomic\_cmpxchg()函数呢？首先atomic\_read()函数只是一个简单的读内存, 而atomic\_cmpxchg()或atomic\_xchg()函数是read\-modify\-write指令, 比atomic\_read()函数执行时间要长得多, 并且导致很多cache一致性问题. 因此在调用atomic\_cmpxchg()或atomic\_xchg()函数之前, 首先调用atomic\_read()函数进行读操作, 可以避免大量不必要的cache—致性的带宽.

**获取锁后**需要调用mutex\_set\_owner()函数把**owner**指向为**当前进程的task\_struct**数据结构, 因为后续也可能有其他申请者要自旋等待, 然后返回true. 

如果**获取锁失败**, 那只能**继续while循环**. 位置6代码是**异常情况**, **owner为NULL**, 也有可能是**持有锁者**在**成功获取锁**和**设置owner**的间隙中**被抢占调度**, 另外如果**当前进程**是**实时进程**或者**当前进程需要被调度**, 那么也要**退出自旋等待**. 

**cpu\_relax\_lowlatency**()函数内置了**内存屏障指令**, 保证每次while循环时都能重新加载变量的值. 

位置7代码, 处理**自旋失败**的情况, 如果这时调度器需要调度, 那就调用schedule\_preempt\_disabled()**让出CPU, 最后返回false**. 

回到\_\_mutex\_lock\_common()主函数中, mutex\_optimistic\_spin()函数返回true, 表示成功获取了锁, 打开内核抢占并成功返回. 

下面来看**自旋等待失败**的情况, 继续看\_\_mutex\_lock\_common()主函数. 

```c
    spin_lock_mutex(&lock->wait_lock, flags);
    // 位置1
	if (!mutex_is_locked(lock) && (atomic_xchg(&lock->count, 0) == 1))
		goto skip_wait;

	/* add waiting tasks to the end of the waitqueue (FIFO): */
	// 位置2
	list_add_tail(&waiter.list, &lock->wait_list);
	waiter.task = task;
    // 位置3
	for (;;) {
		if (atomic_read(&lock->count) >= 0 &&
		    (atomic_xchg(&lock->count, -1) == 1))
			break;

		if (unlikely(signal_pending_state(state, task))) {
			ret = -EINTR;
			goto err;
		}

		__set_task_state(task, state);

		/* didn't get the lock, go to sleep: */
		spin_unlock_mutex(&lock->wait_lock, flags);
		schedule_preempt_disabled();
		spin_lock_mutex(&lock->wait_lock, flags);
	}
	__set_task_state(task, TASK_RUNNING);

	mutex_remove_waiter(lock, &waiter, current_thread_info());
	/* set it to 0 if there are no waiters left: */
	if (likely(list_empty(&lock->wait_list)))
		atomic_set(&lock->count, 0);

skip_wait:
    // 位置4
	mutex_set_owner(lock);
	spin_unlock_mutex(&lock->wait_lock, flags);
	preempt_enable();
	return 0;

err:
	...
	return ret;
}
```

位置1代码, **再尝试一次获取锁**, 也许可以幸运地成功获取锁, 那就不需要走**睡眠唤醒的慢车道**了. 位置2代码, 和读写信号量一样, 有一个**struct mutex\_waiter**数据结构的waiter, 把**waiter加入mutex等待队列wait\_list**中, 这里实现的是**先进先出队列**. 

位置3的for循环中, **每次循环首先尝试是否可以获取锁**, 如果**获取失败**, 那么只能调用**schedule\_preempt\_disabled**()函数**让出CPU**, 当前进程进入**睡眠状态**. 注意atomic\_xchg()把count值设置为-1,在后面代码中会判断等待队列中是否还有等待者. 

**退出for循环**的条件是**睡眠进程被唤醒之后成功获取了锁**, 另外一个是**异常情况**, 即收到**异常信号**. 

如果是**成功获取锁而退出for**循环, 那么将设置当前进程为**可运行状态TASK\_RUNNING**, 并从**等待队列中出列**. 如果**等待队列**中**没有人在睡眠等待**, 那么把**count值设置为0(表明锁正被人持有且等待队列没人**). 

位置4, 既然当前进程**成功获取了锁**, 那就设置**owner为当前进程**, 并且**打开内核抢占**, 然后成功返回.

## 3.3 mutex释放锁

总结:

(1) 清除owner

(2) count加1后大于0, 说明队列没人, 成功(快车道)

(3) 先释放锁, 将clock\-\>count设为1, 然后唤醒等待队列第一位的waiter

下面来看mutex\_unlock()函数是如何解锁的. 

```c
void __sched mutex_unlock(struct mutex *lock)
{
#ifndef CONFIG_DEBUG_MUTEXES
	mutex_clear_owner(lock);
#endif
	__mutex_fastpath_unlock(&lock->count, __mutex_unlock_slowpath);
}
EXPORT_SYMBOL(mutex_unlock);
```

首先调用**mutex\_clear\_owner**()清除**lock\-\>owner的指向**. 解锁和加锁一样有快车道和慢车道之分, 解锁的**快车道**是如果**count原子加1后大于0**, 说明**等待队列中没有人**, 那么就**解锁成功**, 否则只能进入**慢车道函数\_\_mutex\_unlock\_slowpath**().

```c
static inline void
__mutex_unlock_common_slowpath(struct mutex *lock, int nested)
{
	unsigned long flags;
    // 位置1
	if (__mutex_slowpath_needs_to_unlock())
		atomic_set(&lock->count, 1);

	spin_lock_mutex(&lock->wait_lock, flags);
	
	if (!list_empty(&lock->wait_list)) {
		/* get the first entry from the wait-list: */
		struct mutex_waiter *waiter =
				list_entry(lock->wait_list.next,
					   struct mutex_waiter, list);

		wake_up_process(waiter->task);
	}

	spin_unlock_mutex(&lock->wait_lock, flags);
}
```

位置1代码, 出于对性能的考虑, 首先释放锁, 然后去唤醒等待队列中的waiters, 这样有机会让其他人可以抢先获得锁. 接下来去唤醒等待队列中的waiters, 注意**只唤醒在等待队列**中排在**第一位的waiter**. 

# 4 小结

## 4.1 MCS锁

传统自旋等待锁, 在多CPU和NUMA系统, 所有自旋等待锁在同一个共享变量自旋, 对同一个变量修改, 由cache一致性原理(例如MESI)导致参与自旋的CPU中的cache line变的无效, 从而导致CPU高速缓存行颠簸现象(CPU cache line bouncing), 即多个CPU上的cache line反复失效.

MCS减少CPU cache line bouncing, 核心思想是每个锁的申请者只在本地CPU的变量上自旋, 而不是全局的变量. 

```c
[include/linux/osq_lock.h]
// Per-CPU的, 表示本地CPU节点
struct optimistic_spin_node {
	struct optimistic_spin_node *next, *prev; // 双向链表
	int locked; /* 1 if lock acquired */ // 加锁状态, 1表明当前能申请
	int cpu; /* encoded CPU # + 1 value */ // CPU编号, 0表示没有CPU, 1表示CPU0, 类推
};
// 一个MCS锁一个
struct optimistic_spin_queue {
	/*
	 * Stores an encoded value of the CPU # of the tail node in the queue.
	 * If the queue is empty, then it's set to OSQ_UNLOCKED_VAL.
	 */
	atomic_t tail;
};
```

初始化: osq\_lock\_init()

申请MCS锁: osq\_lock()

- 给当前进程所在CPU编号, 将lock\-\>tail设为当前CPU编号, 如果原有tail是0, 表明没有CPU, 那直接申请成功
- 通过原有tail获得前继node, 然后将当前node节点加入MCS链表
- 循环自旋等待, 判断当前node的locked是否是1, 1的话说明前继释放了锁, 申请成功, 退出; 不是1, 判断是否需要重新调度(抢占或调度器要求), 是的话放弃自旋等待, 退出MCS链表, 删除MCS链表节点, 申请失败

![config](./images/7.png)

释放MCS锁: osq\_unlock()

- lock\-\>tail是当前CPU, 说明没人竞争, 直接设tail为0, 退出
- 当前节点的后继节点存在, 设置后继node的locked为1, 相当于传递锁

## 4.2 Mutex锁

```c
[include/linux/mutex.h]
struct mutex {
	/* 1: unlocked, 0: locked, negative: locked, possible waiters */
	// 1表示没人持有锁; 0表示锁被持有; 负数表示锁被持有且有人在等待队列中等待
	atomic_t		count; 
	// 保护wait_list睡眠等待队列
	spinlock_t		wait_lock;
	// 所有在该Mutex上睡眠的进程
	struct list_head	wait_list;
#if defined(CONFIG_MUTEX_SPIN_ON_OWNER)
    // 锁持有者的task_struct
	struct task_struct	*owner;
#endif
#ifdef CONFIG_MUTEX_SPIN_ON_OWNER
    // MCS锁
	struct optimistic_spin_queue osq; /* Spinner MCS lock */
#endif
};
```

初始化: 静态DEFINE\_MUTEX宏, 动态使用mutex\_init()函数

申请Mutex锁:

- mutex\-\>count减1等于0, 说明没人持有锁, 直接申请成功, 设置owner为当前进程, 退出
- 申请OSQ锁, 减少CPU cache line bouncing, 会将所有等待Mutex的参与者放入OSQ锁队列, 只有第一个等待者才参与自旋等待
- while循环自旋等待锁持有者释放, 这中间①锁持有者变化 ②锁持有进程被调度出去, 即睡眠(task\-\>on\_cpu=0), ③调度器需要调度其他进程(need\_resched())都会**退出循环**, 但**不是锁持有者释放了锁(lock\-\>owner不是NULL**); 如果是锁持有者释放了锁(lock\-\>owner是NULL), 当前进程获取锁, 设置count为0, 释放OSQ锁, 申请成功, 退出. 
- 上面自旋等待获取锁失败, 再尝试一次申请, 不成功的话只能走睡眠唤醒的慢车道. 
- 将当前进程的waiter进入mutex等待队列wait\_list
- 循环: 获取锁, 失败则让出CPU, 进入睡眠态, 成功则退出循环, 收到异常信号也会退出循环
- 成功获取锁退出循环的话, 设置进程运行态, 从等待队列出列, 如果等待队列为空, 设置lock\-\>count为0(表明锁被人持有且队列无人)
- 设置owner为当前进程

释放Mutex锁:

- 清除owner
- count加1若大于0, 说明队列没人, 成功
- 释放锁, 将count设为1, 然后唤醒队列第一个进程(waiter\-\>task)

从 **Mutex**实现细节的分析可以知道, **Mutex**比**信号量**的实现要**高效很多**. 

- Mutex**最先**实现**自旋等待机制**. 
- Mutex在**睡眠之前尝试获取锁**. 
- Mutex实现**MCS锁**来**避免多个CPU争用锁**而导致**CPU高速缓存行颠簸**现象. 

正是因为**Mutex**的**简洁性**和**高效性**, 因此**Mutex的使用场景**比**信号量**要**更严格**, 使用Mutex需要注意的**约束条件**如下. 

- **同一时刻**只有**一个线程**可以持有Mutex. 
- 只有**锁持有者可以解锁**. 不能在一个进程中持有Mutex, 而在另外一个进程中释放它. 因此Mutex**不适合内核同用户空间复杂的同步场景(！！！**), 信号量和读写信号量比较适合. 
- **不允许递归地加锁和解锁**. 
- 当**进程持有Mutex**时, 进程**不可以退出(！！！**). 
- Mutex必须使用**官方API来初始化**. 
- Mutex可以**睡眠**, 所以**不允许**在**中断处理程序**或者**中断下半部**中使用, 例如tasklet、定时器等. 

在实际工程项目中, 该**如何选择spinlock、信号量和Mutex**呢？

在**中断上下文**中毫不犹豫地使用**spinlock**, 如果**临界区**有**睡眠、隐含睡眠的动作**及**内核API**, 应**避免选择spinlock**. 在**信号量**和**Mutex**中该如何选择呢？除非代码场景**不符合上述Mutex的约束**中有某一条, **否则都优先使用Mutex**. 