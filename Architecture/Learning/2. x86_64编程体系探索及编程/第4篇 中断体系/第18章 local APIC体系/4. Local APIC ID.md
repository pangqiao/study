
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. local APIC ID寄存器](#1-local-apic-id寄存器)
- [2. APIC ID在multi-threading处理器下](#2-apic-id在multi-threading处理器下)
  - [2.1. 检测处理器是否支持multi-threading](#21-检测处理器是否支持multi-threading)
  - [2.2. multi-threading下的APIC ID](#22-multi-threading下的apic-id)
  - [2.3. xAPIC ID](#23-xapic-id)
    - [2.3.1. SMT](#231-smt)
    - [2.3.2. initial xAPIC ID值的查询](#232-initial-xapic-id值的查询)
  - [2.4. x2APIC ID](#24-x2apic-id)
    - [2.4.1. 测试是否支持CPUID 0B leaf](#241-测试是否支持cpuid-0b-leaf)
    - [2.4.2. x2APIC ID值的查询](#242-x2apic-id值的查询)
    - [2.4.3. 枚举x2APIC ID的level数](#243-枚举x2apic-id的level数)
  - [2.5. Intel Hyper-threading技术的处理器](#25-intel-hyper-threading技术的处理器)
  - [2.6. 支持multi-core和Hyper-threading技术的处理器](#26-支持multi-core和hyper-threading技术的处理器)
  - [2.7. 在multi-core和Hyper-threading技术下的x2APIC ID](#27-在multi-core和hyper-threading技术下的x2apic-id)
- [3. multi-threading技术的使用](#3-multi-threading技术的使用)
  - [3.1. 收集处理器的Package/Core/SMT ID](#31-收集处理器的packagecoresmt-id)
  - [3.2. 提取Package/Core/SMT ID值](#32-提取packagecoresmt-id值)
    - [3.2.1. SMT_MASK_WIDTH与CORE_MASK_WIDTH](#321-smt_mask_width与core_mask_width)
    - [3.2.2. SMT_SELECT_MASK与CORE_SELECT_MASK](#322-smt_select_mask与core_select_mask)
    - [3.2.3. 32位x2APIC ID的排列规则](#323-32位x2apic-id的排列规则)
  - [3.3. 分解提取3-level结构的x2APIC ID](#33-分解提取3-level结构的x2apic-id)
    - [3.3.1. 枚举MASK_WIDTH值](#331-枚举mask_width值)
    - [3.3.2. 计算SMT_SELECT_MASK值](#332-计算smt_select_mask值)
    - [3.3.3. 得到SMT_ID值](#333-得到smt_id值)
    - [3.3.4. 计算CORE_SELECT_MASK值](#334-计算core_select_mask值)
    - [3.3.5. 得到Core_ID值](#335-得到core_id值)
    - [3.3.6. 计算PACKAGE_SELECT_MASK值](#336-计算package_select_mask值)
    - [3.3.7. 得到Package_ID值](#337-得到package_id值)
  - [3.4. 分解提取8位的xAPIC ID](#34-分解提取8位的xapic-id)
- [4. multi-threading处理器编程](#4-multi-threading处理器编程)
  - [4.1. 枚举所有处理器的APIC ID](#41-枚举所有处理器的apic-id)
  - [4.2. BSP与AP处理器](#42-bsp与ap处理器)
  - [4.3. 枚举所有processor](#43-枚举所有processor)
  - [4.4. 提供start-up代码](#44-提供start-up代码)

<!-- /code_chunk_output -->

无论是在Intel还是AMD平台上, local APIC ID都非常重要. 在**处理器power\-up或reset**后, **处理器和bus硬件**上赋予**每个local APIC唯一的initial APIC ID值**, 这个唯一的APIC ID值基于**system bus上的拓扑结构**构建, 可以使用下面的方法查询这个值.

① 在处理器支持**CPUID 0B leaf**的情况下, 使用`CPUID.0B: EDX[31: 0]`得到**32位的APIC ID值**.

② **不支持CPUID 0B leaf**时, 使用`CPUID.01: EBX[31: 24]`得到8位的APIC ID值**.

然后, 在**处理器power\-up或者reset**期间, 这个**initial**值被写入到**local APIC ID寄存器**里(在**支持CPUID 0B leaf**但**不支持x2APIC模式**时, **只保存32位APIC ID值的低8位**).

**APIC ID**实际上也是**每个logical processor**在**system bus**(或者Pentium和P6处理器使用的**APIC bus**)上的**唯一编号**. 这个编号可以被使用在**处理器间进行通信**, **系统软件**可以使用这个编号**动态调度任务给某些处理器执行**.

# 1. local APIC ID寄存器

**local APIC ID寄存器**保存着**APIC ID值**, 地址在**偏移量20H**位置上, 如下所示.

![config](./images/13.png)

在P6和Pentium处理器使用的**APIC版本**里, APIC ID值是**4位**. Pentium 4以后的处理器上的**xAPIC版本**里**APIC ID值是8位**, **x2APIC版本**上使用**32位的APIC ID值**(实际上, 在**支持CPUID 0B leaf的处理器**上**APIC ID**都使用**32位的x2APIC ID值！！！**).

在本节后续的内容主要围绕着**8位的xAPIC ID**和**32位的x2APIC ID值**进行探讨.

# 2. APIC ID在multi-threading处理器下

Intel的处理器实现了两种技术:

- 从后期的**Pentium 4** 处理器开始加入的**Hyper-Threading(超线程**)技术, 使用**逻辑core**技术, **两个logical processor**共用一个**physical package(物理处理器**).
- 从**Core duo**处理器开始加入的**multi-core(多处理器核心**)技术, 使用的是**物理core技术**, 一个**physical package**上有**两个物理core单元**.

**multi\-threading**技术**不单指Hyper-Threading(超线程**), 也包括了**multi\-core(多处理器核心**)技术.

- 现在**Intel**的处理器上的**multi\-threading**实现了**Hyper\-Threading**与**multi-core相结合**.
- 而**AMD**的**multi\-threading**技术以**multi\-core**形式实现.

两种技术都有的话, 在**有cluster的MP系统**中, 会有**多个cluster**, **每个cluster**会有多个**physical package(物理处理器**), **一个physical package**会有**多个物理processor core单元(2个, multi-core技术**), **每个物理core单元**内有**多个logical processor(逻辑, Hyper\-Threading技术, 2个**), logical processor就是指**SMT单元**, 用来**执行单元的线程**, 拥有自己的**资源(处理器的stat信息**)和**自己的local APIC**等.

## 2.1. 检测处理器是否支持multi-threading

对于处理器是否支持**multi\-threading**技术, 软件可以使用`CPUID.01: EDX[28]`位进行检测, 为1时表示支持, 如以下代码所示.

代码清单18-9(lib\cpuid.asm):

```x86asm
; -----------------------------------------------------
;  support_multi_threading(): 查询是否支持多线程技术
; -----------------------------------------------------
support_multi_threading:
      mov eax, 1
      cpuid
      bt edx, 28     ;  HTT 位
      setc al
      movzx eax, al
      ret
```

上面这个support\_multi\_threading()函数用来检测处理器**是否支持multi\-threading技术**, 可以使用在Intel和AMD平台上. 然而, 这里**无法得知是支持Hyper\-threading还是multi\-core技术**.

## 2.2. multi-threading下的APIC ID

在**multi\-threading**技术下, **initial APIC ID**通常分成**3\-level或4\-level的拓扑结构**, 因此**一个完整的APIC ID**将分为**3或4个sub\-field(子域**), 某些处理器的**32位x2APIC ID还可以超过4-level**, 这些具体的sub\-field信息需要通过**CPUID的相关leaf**进行查询.

## 2.3. xAPIC ID

当**MP系统里包含cluster**时, **8位的initial APIC ID**被分成**4-level结构**, 最高层为Cluster ID, 下面是一个使用cluster bridge连接各个cluster的示意图, **每个cluster**内有**数个physical package**.

![config](./images/14.png)

在**没有Cluster的MP系统**里, initial xAPIC ID被分成**3-level结构**.

![config](./images/15.png)

如上所示, **8位的initital xAPIC ID结构**的**3个子域**分别如下.

① **Package ID**: APIC ID**最上层是Package ID**, 在一个MP(multi-processor)系统里, system bus会有**多个physical package**, 每个physical package就是**一个物理处理器**. APIC ID里的**package ID**就是用来区分**cluster内(！！！**)(假如**system bus上有cluster**)或者**system bus上的物理处理器**的.

② **Core ID**: Package ID下一层是**Core ID**, 用来区分**physical package**内的**processor core**, 在一个**单核**的处理器上, **Core ID的值为0**.

③ **SMT ID**: Core ID下一层是SMT ID, **每个SMT ID**代表一个**logical processor**, SMT ID用来区分**processor core内的logical processor(！！！**).

这些**Package ID、Core ID及SMT ID**子域的宽度依赖于处理器的实现, **每个处理器在power-up**时, **bus硬件**会赋一个**initial APIC ID给local APIC**, 这个initial APIC ID值可以从**CPUID指令**里查询得到. **软件**可以使用**CPUID的01 leaf和04 leaf**来**查询和枚举initial APIC ID的子域**. 然而值得注意的是, 这个**initial APIC ID值**可能与通过**local APIC ID寄存器**查出来的**ID值不一样**. 在**某些处理器(！！！**)上, **local APIC ID寄存器是可写的**, BIOS或OS可能会写给local APIC ID寄存器不一样的ID值(当然, 改写的可能性极少).

### 2.3.1. SMT

**SMT(Simultaneous Multi\-Threading**)直译为**同步的多线程**, 就是指**Intel的Hyper\-Threading技术**, 在**processor core内**实现**两个共享物理core执行单元的线程**. 这些线程单元拥有自已的处理器资源(**处理器的state信息！！！**), 包括**有自己的local APIC**. logical processor就是指**SMT单元**.

### 2.3.2. initial xAPIC ID值的查询

显然, system bus 硬件产生的8位的initial xAPIC ID会被保存到local APIC ID寄存器里, 软件可以使用CPUID.01: EBX[31: 24]查询得到initial xAPIC ID值.

代码清单18-10(lib\apic.asm):

```x86asm
; -------------------------------------
;  get_apic_id(): 得到 initial apic id
; -------------------------------------
get_apic_id:
       mov eax, 1
       cpuid
       mov eax, ebx
       shr eax, 24
       ret
```

这个get\_apic\_id()函数用来获得当前运行代码的处理器的**8位的initial xAPIC ID值**, 在CPUID指令的01 leaf返回的EBX寄存器[31: 24]位里.

思考一下, 这个initial xAPIC ID值, 只会对**当前运行的线程**(也就是**当前logical processor！！！**)执行后所返回的.

## 2.4. x2APIC ID

在处理器支持**CPUID 0B leaf**或者**支持x2APIC模式**的情况下, 软件可以查询到一个**32位的x2APIC ID值**, 结构如下.

![config](./images/16.png)

**x2APIC ID值可能会超过4个子域**, 依赖于处理器的实现, **有多少个子域**及**每个子域的宽度**必须使用**CPUID指令的0B leaf进行查询和枚举**. 然而在**没有cluster的情况下(cluster为0**), 处理器还是使用3\-level的结构, 也就是**32位的x2APIC ID依然使用了3\-level结构**.

值得注意的是, **CPUID指令的0B leaf**并**不依赖于local APIC的x2APIC模式**.

不支持x2APIC模式的处理器, 并不代表不支持CPUID 0B leaf, 因此, 在不支持x2APIC模式的处理器上, 如果支持CPUID的0B leaf, 软件依然可以使用CPUID 0B leaf来查询32位的x2APIC ID值.

CPUID 0B leaf允许处理器查询超过8位的xAPIC ID值(在xAPIC模式下), 使用CPUID 01 leaf查询得到的8位xAPIC ID值(由CPUID.01: EBX[31: 24]得到)等于使用CPUID 0B leaf查询得到的32位x2APIC ID值的低8位(即CPUID.01: EBX[31: 24]=CPUID.0B: EDX[7: 0]).

只有在处理器支持x2APIC模式情况下, 才可能使用**完整的32位x2APIC ID值**, 操纵**超过256个logical处理器**.

### 2.4.1. 测试是否支持CPUID 0B leaf

CPUID指令的0B leaf用来查询和枚举处理器扩展的拓扑结构, 在近期的处理器上才实现了0B leaf.

代码清单18-11(lib\apic.asm):

```x86asm
;  测试是否支持 leaf 11
       mov eax, 0
       cpuid
       cmp eax, 11
       jb extrac_x2apic_id_done    ;  不支持 0B leaf
```

上面这段代码用来测试是否支持0B leaf, 关于测试CPUID指令支持的**最大leaf(叶号**), 请参考4.3节所述.

### 2.4.2. x2APIC ID值的查询

当处理器**支持CPUID 0B leaf**时, 软件就可以使用**CPUID 0B leaf**来查询x2APIC ID值, 代码如下所示.

代码清单18-12(lib\apic.asm):

```x86asm
; ---------------------------------------
;  get_x2apic_id(): 得到 x2APIC ID
; ---------------------------------------
get_x2apic_id:
       mov eax, 11
       cpuid
       mov eax, edx   ;  返回 x2APIC ID
       ret
```

上面的get\_x2apic\_id()函数用来查询**x2APIC ID值**, CPUID.0B: EDX[31: 0]返回的是**当前运行线程(当前运行的logical processor！！！)下的32位x2APIC ID值**.

### 2.4.3. 枚举x2APIC ID的level数

前面提及, x2APIC ID的子域(level数)可以使用CPUID 0B leaf来枚举. EAX寄存器输入main\-leaf号(即0BH), ECX寄存器输入sub\-leaf号枚举, 最终的结果值表示在physical package内有多少level.

在第1次发起CPUID 0B leaf查询时, 使用EAX=0BH(main-leaf), ECX=0(subleaf), 每次递增ECX, 直到返回的ECX[15: 8]=0为止, 它的算法描述如下.

```c
#define SMT  1
#define CORE  2
#define INVALID 0
int get_x2apic_id_level()
{
   sub_leaf=0;     /* sub-leaf 号 */
   do
   {
       eax=0Bh;     /* EAX=main-leaf */
       ecx=sub_leaf;   /* ECX=sub-leaf */
       cpuid();     /* 执行 CPUID 指令枚举 */
       sub_leaf++;     /* 递增 sub-leaf */
   } while (ecx.level_type ！= INVALID);  /* 返回的 ECX[15: 8] 值不等于0时, 重复迭代*/
   return ecx.level;       /* 返回的 ECX[7: 0] 值就是 level 数 */
}
```

每次执行CPUID指令时, 返回的ECX[15: 8]值是一个level类型, SMT level是1值, 而CORE level是2值, 0是无效, 其他值保留. 在最后一次迭代中, ECX[7: 0]就是level数.

代码清单18-13(lib\apic.asm):

```x86asm
; -------------------------------------------------
;  get_x2apic_id_level(): 得到 x2APIC ID 的 level 数
; -------------------------------------------------
get_x2apic_id_level:
       mov esi, 0
enumerate_loop:
       mov ecx, esi   ;  sub-leaf
       mov eax, 11    ;  main-leaf
       cpuid
       inc esi
       movzx eax, cl   ;  ECX[7: 0]=level数
       shr ecx, 8
       and ecx, 0xff   ;  测试 ECX[15: 8]
       jnz enumerate_loop  ;  ECX[15: 8] ！= 0 时, 重复迭代
       ret
```

上面这个get\_x2apic\_id\_level()函数就实现了枚举出x2APIC ID的level数. 注意, 这个level数是指在package内的level数(即SMT\_ID和CORE\_ID).

![config](./images/17.png)

上面这是使用get\_x2apic\_id\_level()函数枚举的结果, 这个结果里x2APIC ID有2\-level结构, 我们可以对比一下3\-level结构图(除package外).

如果处理器支持CPUID 0B leaf(枚举查询32位的x2APIC ID)但不支持x2APIC模式, 那么只能操作256个logical processor. system bus上有超过256个logical processor的话, 超出的处理器在xAPIC模式下并不能使用到.

## 2.5. Intel Hyper-threading技术的处理器

Intel的Hyper-threading是multi\-threading技术的一种形式, 允许在**一个处理器里实现2个执行线程**, 这些**线程(SMT)共享processor core的执行单元**, 可是**每个SMT有自己的处理器状态(！！！**), 这些SMT代表一个logical processor, 如下所示.

![config](./images/18.png)

我们看到, 上图的MP系统下, 每个physical package中有两个logical processor, 那么在这个system bus上共有4个logical processor.

这些logical processor的APIC ID值如下.

![config](./images/19.png)

因为是**单核Hyper-threading处理器**, 所以**只有一个core**. Core ID都为0值. 我们看到, 这其实是2\-level的APIC ID结构, **Core ID子域被忽略**.

## 2.6. 支持multi-core和Hyper-threading技术的处理器

在Intel的处理器上同时可以支持multi\-core和SMT技术, 下面是使用**8位的xAPIC ID下**的**双核心SMT处理器MP系统结构**.

![config](./images/20.png)

在**system bus**上有**2个physical package(即物理处理器**), **每个package**上有**2个processor core**, 每个处理器核心有**2个logical processor**, 因此在system bus上共有8个logical processor, 它们的APIC ID值如下.

![config](./images/21.png)

在上面的这个**3\-level**的拓扑结构里, APIC ID号规则是先排**package ID**, 再到Core ID, 最下层是SMT ID, 形成最终的8位值.

## 2.7. 在multi-core和Hyper-threading技术下的x2APIC ID

在一个**4核8线程处理器**下, **每个logical processor**使用**x2APIC ID**, 如下所示.

![config](./images/22.png)

处理器支持**multi\-core技术**, **每个物理package**中有**4个processor core**. 同时**每个processor core**支持**2个SMT**. **每个package**里有**8个logical processor**, 在system bus上共有16个logical processor, 那么它们在system bus上的x2APIC ID如下.

![config](./images/23.png)

在上面的表格中, **x2APIC ID**同样使用**3\-level的拓扑结构**, 最高层是**Package ID**, **system bus上含有两个physical package**, 分别为**package 0和package 1**, 那么最上层的值就是0和1. 接着是4个core ID, 从0到3. 最下层是SMT ID, 分别为0和1.

与8位的xAPIC ID不同的是, 上层的不同package ID值造成x2APIC ID值并不连续. (详请参见18.4.3.2节所述. )

# 3. multi-threading技术的使用

在处理器出现**multi\-threading**技术(包括**multi\-core**和**SMT**技术)**前**, 在OS中只能提供软件层上的multi\-threading技术, 由软件模拟multi\-threading技术并**不能真正做到线程的同步执行**, **单处理器上某一时刻只能执行一个任务**.

然而, multi\-core和SMT的出现, 为处理器提供了物理层上的multi\-threading技术. 为多个处理器执行单元可以同步执行多个任务提供了基础设施.

显然, 硬件层上的multi\-threading比软件层上的具有更高的效率和吞吐量.

## 3.1. 收集处理器的Package/Core/SMT ID

在一个**multi\-threading处理器**中, **OS**可以根据**logical processor的APIC ID值**分配和调度任务(线程)在**哪个logical processor里执行**.

处理器在**power\-up或reset后**, system bus上的**logical processor**被赋予**唯一的initial APIC ID值**, **OS初始化**时应该**收集system bus上logical processor的3\-level结构的APIC ID或x2APIC ID值的Package ID、Core ID, 以及SMT ID**, 以便可以在某个logical prcessor上分配执行任务, 如下所示.

![config](./images/24.png)

在Package/Core/SMT ID的收集中, 或许可以实施不同的方案或者策略. 例如在上面的一个4个package的MP系统里, 我们可以将收集到的所有的logical processor统一放在一个数据结构里.

![config](./images/25.png)

上图的结构类似于paging的各级页换转表结构, 在Package\_ID数组里有多少个元素, 则表示有多少个物理处理器.

![config](./images/26.png)

上图中我们以每个logical processor的APIC ID数组为主, 每个APIC ID值对应于各自的Package\_ID表、Core\_ID表, 以及SMT\_ID表的收集形式. logical\_processor_ID表有多少个元素代表有多少个logical processor.

## 3.2. 提取Package/Core/SMT ID值

在收集的过程中, 需要从已知的8位xAPIC ID值或32位的x2APIC ID值中提取出Package ID、Core ID, 以及SMT ID值.

Intel提供了**两种提取Package/Core/SMT ID值的方式**, 对应于8位的APIC ID(xAPIC ID)和32位的x2APIC ID.

① 使用CPUID指令的01 leaf和04 leaf: 这种方式使用在**8位**的APIC ID和xAPIC ID值上.

② 使用CPUID指令0B leaf的扩展枚举拓扑结构功能: 这种方式使用在**32位的x2APIC ID值**上.

![config](./images/27.png)

当处理器支持扩展的CPUID 0B leaf时, 使用0B leaf枚举查询32位的x2APIC ID值, 以及相应的SMT\_MASK\_WIDTH与CORE\_MASK\_WIDTH值进行提取.

如果不支持, 则应使用01 leaf查询8位的APIC ID值, 使用04 leaf查询package内最大的logical processor计算值, 以及package内最大的core计算值, 从而算出SMT\_MASK\_WIDTH和CORE\_MASK\_WIDTH值, 再进行提取工作.

### 3.2.1. SMT_MASK_WIDTH与CORE_MASK_WIDTH

现在, 我们来看看SMT\_MASK\_WIDTH和CORE\_MASK\_WIDTH是什么, 如下所示.

![config](./images/28.png)

SMT\_MASK\_WIDTH值和CORE\_MASK\_WIDTH值, 以及PACKAGE\_MASK\_WIDTH值分别指示SMT/Core/Package子域在APIC ID值中所占位的宽度, 从而可以用来从APIC ID中提取Package/Core/SMT ID值.

以上图的32位x2APIC ID(从CPUID 0B leaf枚举而来)为例:

① SMT\_MASK\_WIDTH的值为1, 那么SMT ID占1位宽.

② CORE\_MASK\_WIDTH的值为4, 那么CORE ID占4位宽, 可是这个CORE\_MASK\_WIDTH值包括SMT\_MASK\_WIDTH在内, 因此CORE\_MASK\_WIDTH实际只有3位.

③ PACKAGE\_MASK\_WIDTH的值为28, 那么Package ID占28位宽(这个值是不确定的).

实际上, 除了SMT\_MASK\_WIDTH和CORE\_MASK\_WIDTH准确外, 剩下的28位并不只是代表PACKAGE\_MASK\_WIDTH(或许还会有Cluster甚至其他level结构的子域), 在3\-level的结构里, 高28位就暂且作为PACKAGE\_MASK\_WIDTH值. 28位加上CORE\_MASK\_WIDTH的4位就是32位的x2APIC ID.

在CPUID 0B leaf里, SMT\_MASK\_WIDTH和CORE\_MASK\_WIDTH的值直接来自枚举所返回的EAX[4: 0]值. 而在CPUID 04 leaf里, SMT\_MASK\_WIDTH和CORE\_MASK\_WIDTH的值需要计算得到.

### 3.2.2. SMT_SELECT_MASK与CORE_SELECT_MASK

SELECT\_MASK用来enable/disalbe相应的域(即Package/Core/SMT域), 从而能在APIC ID里提取Package/Core/SMT ID值, 如下所示.

![config](./images/29.png)

这些SELECT\_MASK值是基于MASK\_WIDTH值计算而来的. CORE\_MASK\_WIDTH=4(包括SMT\_MASK\_WIDTH值), 因此它的SELECT\_MASK值为0EH(即1110B).

### 3.2.3. 32位x2APIC ID的排列规则

根据前面所述, x2APIC ID值的排列规则是由Package/Core/SMT的MASK\_WIDTH值造成.

![config](./images/30.png)

根据上图所示, 对照前面18.4.2.6节在MP系统下4核8线程的处理器的x2APIC ID.

① 当Package=0, Core=3, SMT=1时, 它的x2APIC ID为07H.

② 当Package=1, Core=3, SMT=1时, 它的x2APIC ID为17H.

这就是package值不同造成x2APIC ID不连续的原因. 然而8位的xAPIC ID会使用不同的排列规则, 我们在后面将会看到.

## 3.3. 分解提取3-level结构的x2APIC ID

Intel为x2APIC ID专门开辟了一个CPUID 0B leaf来枚举32位的x2APIC ID拓扑结构. 前面我们已经了解过使用CPUID0B leaf来查询x2APIC ID值和level数.

### 3.3.1. 枚举MASK_WIDTH值

CPUID.0B: EAX[4: 0]可以获得Core/SMT的MASK\_WIDTH值, 依赖于ECX输入的sub\-leaf号, 下面是类C的算法.

```c
#define SMT  1   /* level-type 为 SMT */
#define CORE  2   /* level-type 为 CORE */
#define INVALID 0
int smt_mask_width=0;
int core_mask_width=0;
int package_mask_width=0;
void get_mask_width()
{
   sub_leaf=0;    /* 第1次枚举时的 sub-leaf 值为0 */
   do
   {
      eax=11;    /* main-leaf */
      ecx=sub_leaf;  /* sub-leaf */
      cpuid();    /* 执行 CPUID 指令 */
      sub_leaf++;    /* 在接下来的枚举中, 每次递增 sub_leaf */
      /*
       * 当 ECX[15: 8] 为 1 时, eax[4: 0] 得到 SMT_MASK_WIDTH 值
       * 当 ECX[15: 8] 为 2 时, eax[4: 0] 得到 CORE_MASK_WIDTH 值
       * 当 ECX[15: 8] 为 0 时, 枚举结束
       */
      if (ecx[15: 8] == SMT)
          smt_mask_width=eax[4: 0];
      else if (ecx[15: 8] == CORE)
          core_mask_width=eax[4: 0];
      else
      {
          /* 当 ECX[15: 8] == 0 时, ECX[7: 0] == 0 时, CPUID 0B leaf 枚举失败 */
          if (ECX[15: 0] == 0)
          {
              /* 这种情况下, 只能使用 01 leaf 和 04 leaf 来提取 8 位的 xAPIC ID 值 */
          }
      }
   } while (ecx[15: 8] ！= INVALID);  /* 返回 ECX[15: 8] ！= 0 时, 重复迭代 */
   /* 3-level 结构中, 剩下属于 PACKAGE_MASK_WIDTH 值 */
   package_mask_width=32 - core_mask_width;
}
```
在开始枚举时, 输入EAX=0BH的main-leaf值, ECX=0H的sub\-leaf值, 每次迭代sub\-leaf都增1(即ECX递增). ECX[15: 8]返回的是level的类型(包括: 1为SMT类型, 2为CORE类型).

① CPUID指令返回的ECX[15: 8]=1时, 说明是SMT level, 那么EAX[4: 0]返回的是SMT_MASK_WIDTH值.

② 当ECX[15: 8]=2时, 说明是CORE level, 那么EAX[4: 0]返回的是CORE_MASK_WIDTH值.

③ 当ECX[15: 8]=0时, 所有的level都枚举完了(实际上只有2个level, 即SMT和CORE类型).

④ 当第一次枚举时输入ECX=0(sub-leaf为0), 即返回的ECX[7: 0]=0时, 如果ECX[15: 8]为0, 说明枚举失败(可能并不支持CPUID 0B leaf功能).

最后, 当SMT\_MASK\_WIDTH和CORE\_MASK\_WIDTH值都得到后, 在3\-level结构里高位剩下的位宽就是PACKAGE\_MASK_WIDTH值. 关于CPUID 0B leaf的详细说明最好参考Intel64手册Volume 2A中CPUID指令的说明.

### 3.3.2. 计算SMT_SELECT_MASK值

当得到SMT\_MASK\_WIDTH值后, 使用下列的算法来得到SMT\_SELECT\_MASK值.

```
SMT_SELECT_MASK=～(0xFFFFFFFF << SMT_MASK_WIDTH)
```

以SMT\_MASK\_WIDTH=1为例.

```
① 0xFFFFFFFF\<\<SMT\_MASK\_WIDTH的结果为0xFFFFFFFE.

② 0xFFFFFFFE取反的结果就是0x00000001.
```

使用这个算法来得到SMT\_SELECT\_WIDTH值, 这是Intel推荐的. 当然, 我们也可以有自己的算法, 如下面是第2种算法.

```
SMT_SELECT_MASK=(1 << SMT_MASK_WIDTH) - 1
```

上面这个算法的结果是一样的.

```
① 1\<\<SMT_MASK_WIDTH的结果为2.

② 2\-1的结果为1(也就是0x00000001形式).
```

喜欢使用哪个算法, 任君选择, 目的只有一个, 就是求出mask位.

### 3.3.3. 得到SMT_ID值

我们使用上面的SMT\_SELECT\_MASK来得到SMT\_ID值.

```
SMT_ID=x2APIC_ID & SMT_SELECT_MASK
```

简单地说, 以SMT\_MASK\_WIDTH=1为例, 事实上SMT\_ID就是x2APIC ID的Bit 0(只不过其中的算法似乎是绕了个圈). 如果SMT\_MASK\_WIDTH=2, 那么SMT\_ID就是x2APIC ID的[1: 0](共2位).

### 3.3.4. 计算CORE_SELECT_MASK值

由于CPUID 0B leaf得到的CORE_MASK_WIDTH值包含SMT_MASK_WIDTH在内, 因此CORE_SELECT_MASK的计算要有所改变.

```
CORE_SELECT_MASK=(～(0xFFFFFFFF << CORE_MASK_WIDTH)) ^ SMT_SELECT_MASK
```

以CORE\_MASK\_WIDTH=4为例.

```
① ～(0xFFFFFFFF\<\<CORE\_MASK\_WIDTH)的结果是0x0000000F.

② 0x0000000F\^SMT\_SELECT\_MASK的结果是0x0000000E.
```

### 3.3.5. 得到Core_ID值

同样, 使用下面的式子来得到Core\_ID值.

```
Core_ID=(x2APIC_ID & CORE_SELECT_MASK) >> SMT_MASK_WIDTH
```

由CORE\_SELECT\_MASK提取的值需经过右移SMT的宽度才能得到独立的Core\_ID值.

### 3.3.6. 计算PACKAGE_SELECT_MASK值

在3\-level结构中, CPUID 0B leaf中无须得到PACKAGE_MASK_WIDTH值, 因为除了Core和SMT外, 剩下就是Package level了. PACKAGE_SELECT_MASK值的计算直接依赖于CORE_MASK_WIDTH值.

```
PACKAGE_SELECT_MASK=0xFFFFFFFF << CORE_MASK_WIDTH
```

这个CORE\_MASK\_WIDTH包含了SMT\_MASK\_WIDTH在内, 以CORE\_MASK\_WIDTH=4为例, 0xFFFFFFFF<\<\4的值为0xFFFFFFF0.

### 3.3.7. 得到Package_ID值

使用下面的式子来得到Package\_ID值.

```
Package_ID=(x2APIC_ID & PACKAGE_SELECT_MASK) >> CORE_MASK_WIDTH
```
同样需要去掉低4位的Core\_ID和SMT\_ID值才能得到独立的Package\_ID值.

实验18\-4: 从x2APIC ID里提取Package\_ID Core\_ID以及SMT\_ID值

下面我们来做实验练习从x2APIC ID提取Package/Core/SMT ID值, 并打印相关信息, 在程序的主体代码里, 使用extrac\_x2apic\_id()函数来提取Package/Core/SMT ID值, 这个函数实现在lib\apic.asm文件里, 比较长, 请读者自行查阅.

![config](./images/31.png)

这个图是在Westmere微架构Core i5处理器上的运行结果, 结果显示:

① x2APIC ID值为0(即在0号logical processor上运行).

② 它的Package/Core/SMT ID值都是0.

那么, 从这个处理器的x2APIC ID提取的结果如下.

① `SMT_MASK_WIDTH=1`, `SMT_SELECT_MASK=1`.

② `CORE_MASK_WIDTH=4`, `CORE_SELECT_MASK=0EH`.

③ `PACKAGE_MASK_WIDTH=28`, `PACKAGE_SELECT_MASK=0xFFFFFFF0`.

正如前面所说, `CORE_MASK_WIDTH` 值包含了 `SMT_SELECT_MASK` 值, 实际它应该为3.

## 3.4. 分解提取8位的xAPIC ID

# 4. multi-threading处理器编程

在**multi\-threading**技术(包括**Hyper\-Threading**与**multi\-core**)处理器下, **system bus**上含有**多个logical processor(逻辑处理器**), 如前面所述, 每个logical processor被赋予唯一的APIC ID值, **APIC ID是在system bus上识别logical processor的标识符**. logical processor之间根据这个APIC ID值相互通信.

## 4.1. 枚举所有处理器的APIC ID

BIOS或OS初始化期间需要枚举出system bus上所有的logical processor信息, 包括: 共有多少个处理器; 它们的APIC ID是多少等. 这些信息需要被记录下来.

**BIOS或OS**的另一个重要工作是**对所有的processor进行必要的设置和初始化**工作.

## 4.2. BSP与AP处理器

在**处理器power-up**或**reset**阶段时, 由**硬件(！！！)选出一个processor作为BSP(bootstrap processor)处理器**, BSP处理器的**IA32\_APIC\_BASE寄存器**的**bit 8被置位**, 指示**属于BSP处理器**.

剩下的**processor都为AP(application processor)处理器**, IA32\_APIC\_BASE寄存器的**bit 8被清0**, 如下所示.

![config](./images/32.png)

在BIOS执行阶段, 由BSP处理器执行BIOS的自举代码, 其余的**AP处理器**处于**等待BSP处理器发送信息状态**. 例如: 在笔者的双核4线程Core i5处理器中, 共有4个logical processor, 典型地: **APIC ID为0的处理器为BSP处理器**.

## 4.3. 枚举所有processor

**BSP处理器**执行**BIOS自举代码**进行初始化后, 需要通过**发送IPI消息！！！**形式(Intel推荐依次发送INIT\-SIPI\-SIPI消息序列)来**唤醒和初始化所有AP处理器**.

典型地, **BSP唤醒AP处理器**执行**BIOS的start-up代码(BIOS的！！！**). BSP和AP处理器在**各自的运行期间**可以读取**local APIC ID寄存器**来得到属于自已的**APIC ID**, 并增加**处理器计数值**.

>实验18-6: 枚举所有的processor和APIC ID值

现在, 我们通过实验18\-6来实现**枚举system bus上共有多少个processor**, 以及列出它们的**APIC ID值**. 这里我们需要**实现IPI(Inter-processor interrupt)消息机制！！！**. **发送IPI消息**需要使用**local APIC**的**ICR(Interrupt Command Register, 中断命令寄存器**), 我们将在稍后探讨IPI机制.

![config](./images/33.png)

如上所示, 完成这个实验需要从**BSP和AP处理器两个角度**进行思考并编写相应的代码, 在**各自运行期间**, 收集**属于自己的信息**. **BSP处理器的职责之一**是**为AP处理器提供Start\-up代码**, 控制**同一时间只允许一个AP处理器运行这段start\-up代码**.

## 4.4. 提供start-up代码

典型地, **start\-up代码**应该**属于BIOS代码的一部分**, **BSP处理器运行时**需要**加载start\-up代码到内存1M(16位实模式)以下4K边界上**, 以**供AP处理器读取运行**.

代码清单18-17(topic18\ex18-6\protected.asm):

```x86asm
; *
; * 下面是 startup routine 代码
; * 引导 AP 处理器执行 setup模块, 执行 protected 模块
; * 使所有 AP 处理器进入protected模式
; *
startup_routine:
       bits 16
       mov ax, 0
       mov ds, ax
       mov es, ax
       mov ss, ax
; *
; * **** 开启计数器 ****
; * 统计每个 AP 处理器从等待到完成初始化所使用指令和 clock数
; *
       mov ecx, IA32_FIXED_CTR_CTRL
       mov eax, 0B0Bh
       mov edx, 0
       wrmsr
       ENABLE_COUNTER 0, (IA32_FIXED_CTR0_EN | IA32_FIXED_CTR2_EN)
; 测试 lock, 同一时刻只允许 1 个 local processor 访问
test_ap_lock:
       lock bts DWORD [vacant], 0
       jc get_ap_lock
       jmp WORD 0: SETUP_SEG                ;  进入实模式的 setup.asm 模块
get_ap_lock:
       jmp test_ap_lock
       bits 32
startup_routine_end:
       jmp $
```

代码清单18\-17是这个实验的start\-up代码入口. 值得注意的是, 当**AP接收到INIT IPI消息**执行**INIT操作**时, 处理器处于实模式状态.

在这个实验里, **BSP和AP执行的代码是完全一样的**(进入setup.asm模块再到protected.asm模块执行), 所不同的是, AP执行插入了上面的startup\_routine入口代码, 用来控制AP处理器接**顺序执行setup.asm和protected.asm模块代码**.

代码清单18-18(topic18\ex18-6\protected.asm):

```x86asm
; ; ;  实验 18-6: 枚举所有的processor和APIC ID值
; ; ;  测试 bootstrap processor 还是 application processor ?
       mov ecx, IA32_APIC_BASE
       rdmsr
       bt eax, 8
       jnc ap_processor
; ;  ** 下面是 BSP 代码 ***
       ; *
       ; * perfmon 初始设置
       ; * 关闭所有 counter 和 PEBS
       ; * 清 overflow 标志位
       ; *
       DISABLE_GLOBAL_COUNTER
       DISABLE_PEBS
       RESET_COUNTER_OVERFLOW
       RESET_PMC
; 设置 APIC performance monitor counter handler
       mov esi, APIC_PERFMON_VECTOR
       mov edi, apic_perfmon_handler
       call set_interrupt_handler
; 设置 APIC timer handler
       mov esi, APIC_TIMER_VECTOR
       mov edi, apic_timer_handler
       call set_interrupt_handler
; 设置 LVT 寄存器
       mov DWORD [APIC_BASE + LVT_PERFMON], FIXED_DELIVERY | APIC_PERFMON_VECTOR
       mov DWORD [APIC_BASE + LVT_TIMER], TIMER_ONE_SHOT | APIC_TIMER_VECTOR
; *
; * 复制 startup routine 代码到 20000h
; * 以便于 AP processor 运行
; *
       mov esi, startup_routine
       mov edi, 20000h
       mov ecx, startup_routine_end - startup_routine
       rep movsb
; *
; * 增加处理器编号计数
; * BSP 处理器为 processor #0
; *
       inc DWORD [processor_index]      ;增加 index 值
       inc DWORD [processor_count]      ;增加 logical processor 数量
       mov ecx, [processor_index]           ;处理器 index 值
       mov edx, [APIC_BASE + APIC_ID]       ;读取 APIC ID 值
       mov [apic_id + ecx * 4], edx         ;保存 APIC ID
; *
; * 分配 stack 空间
; *
; * 分配方法:
; *      ①  每个处理器的 index * STACK_SIZE 得到 stack_offset
; *      2) stack_offset 加上 stack_base 值
; *
       mov eax, PROCESSOR_STACK_SIZE     ;每个处理器的 stack 空间大小
       mul ecx                                     ;  stack_offset=STACK_SIZE * index
       mov esp, PROCESSOR_KERNEL_ESP
       add esp, eax
       mov esi, bp_msg1
       call puts
       mov esi, msg
       call puts
       mov esi, edx
       call print_dword_value
       call println
       mov esi, bp_msg2
       call puts
; *
; * 开放 lock 信号
; *
       mov DWORD [vacant], 0                        ;lock
       ; *
       ; * 下面发送 IPI, 使用 INIT-SIPI-SIPI 序列
       ; * 发送 SIPI 时, 发送 startup routine 地址位于 200000h
       ; *
       mov DWORD [APIC_BASE + ICR0], 000c4500h      ;发送 INIT IPI
       DELAY
       DELAY
       mov DWORD [APIC_BASE + ICR0], 000C4620H      ;发送 Start-up IPI
       DELAY
       mov DWORD [APIC_BASE + ICR0], 000C4620H      ;再次发送 Start-up IPI
       ; * 等所有 AP 完成
test_ap_done:
       cmp DWORD [ap_done], 1
       jne get_ap_done
       mov DWORD [APIC_BASE + TIMER_ICR], 100       ;开启 apic timer
       hlt
       jmp $
get_ap_done:
       jmp test_ap_done
       jmp $
```

上面是这个实验的主体代码, 其主要的工作如下.

① **开启local APIC**.

② **判断当前**执行的处理器是**BSP处理器还是AP处理器**: 通过**IA32\_APIC\_BASE[8]位**判断, BSP与AP处理器执行不同的代码.

③ 在**BSP处理器**代码里, 通过**设置local timer的中断**来执行定时.

④ 复制**start\-up routine代码**到**20000h**位置上, 因为**AP处理器执行的入口**将放在20000h位置上(**通过20000h位置**再转入到**setup.asm**和**protected.asm模块**).

⑤ 读取**APIC ID**保存起来, 并**增加计数值processors**, 置**lock信号vacant为有效(未上锁**).

⑥ 第1次发送**INIT消息**到**所有的AP处理器**, 所有AP处理器执行**INIT操作**.

⑦ 第2次发送**SIPI消息**到**所有的AP处理器**, **vector值**为**0x20**(它**提供20000h的入口地址！！！**).

⑧ 第3次发送**SIPI消息**到**所有的AP处理器**, 由于**SIPI消息可能发送失败**而**不会自动重发**, 因此, 应该再次发送SIPI消息避免上次发送失败.

⑨ 检查所有**AP处理器**是否已经**执行完毕**, 如果是, **开启APIC timer中断**.

⑩ **BSP处理器**进入**timer中断handler执行**, 打印出所有logical processor的汇总信息.

⑪ 在**每个AP处理器**进入**startup routine代码前**必须**测试lock信号是否有效**, **获得lock后(！！！**)才被允许进入startup routine执行. 在得到lock进入**执行代码前**开启两个计数器: 一个是**IA32\_FIXED\_CTR0计数器**用来统计**AP的执行指令数**, 一个是**IA32\_FIXED\_CTR2计数器**用来统计**所使用的clock cycle数**.

⑫ 在**AP处理器**进入到protected.asm模块的**ap\_processor代码**处, 每个AP处理器关闭之前开启的两个计数器, 收集到**执行指令数和clock数信息**, 并打印出来. 在ap\_processor代码里同样是**读取APIC ID值**, 保存起来并**增加处理器计数**.

⑬ 每个**AP处理器执行完**毕后**释放lock信号vacant为有效(置0**), 允许另一个AP处理器进入setup.asm模块执行.

⑭ 最后执行**CLI指令与HLT指令**, 处理器进入**halt状态**.

这个实验的最后结果是, **BSP处理器还在运行**, 而**所有AP处理器最后进入停机状态**, 可以**等待BSP处理器再次发送IPI消息**.

代码清单18-19(topic18\ex18\-6\protected.asm):

```x86asm
; ---------------------------------------------
;  apic_timer_handler(): 这是 APIC TIMER 的 ISR
; ---------------------------------------------
apic_timer_handler:
       jmp do_apic_timer_handler
at_msg2  db 10, '--------- summary -------------', 10
         db  'processor: ', 0
at_msg3  db 'APIC ID : ', 0
do_apic_timer_handler:
       mov esi, at_msg2
       call puts
       mov ebx, [processors_count]
       mov esi, ebx
       call print_dword_decimal
       call println
       mov esi, at_msg3
       call puts
       xor ecx, ecx
at_loop:
       mov esi, [apic_id + ecx * 4]
       call print_dword_value
       mov esi, ', '
       call putc
       inc ecx
       cmp ecx, ebx
       jb at_loop
       mov DWORD [APIC_BASE + EOI], 0
       iret
```

在**BSP处理器**的**执行timer中断handler**里将输出汇总信息: **processor的数量**和**APIC ID值**.

![config](./images/34.png)

上面是在Westmere微架构移动Core i5处理器笔记本式计算机上的运行结果. 我们看到, 这个处理器由于是**双核心4线程的**, 因此共有**4个logical processor**, **BSP处理器**的**APIC ID为0**, 其他3个AP处理器的**APIC ID为1、4、5**. 值得奇怪的是, 4个逻辑处理器的编号并不是接0、1、2、3的顺序排列, 而是0与1对应一个core, 而4与5对应一个core.

实验18-6结果显示另一个比较有趣的地方是, 由于**同一时刻只有一个处理器有权执行startup routine代码**, 而其余的处理器在不断地测试lock, 处于**等待状态**. 因此, 造成**每个AP执行的指令数**和**clock都不一样**.

① Processor #1处理器(APIC ID为01000000H)最先获得startup routine运行权, 所以它无须等待直接进入startup routine运行.

② Processor #3处理器(APIC ID为04000000H)最后获得startup运行权. 它执行的指令数和花费的clock数必然是最多的. 不但要等待前两个处理器完成startup routine代码, 并且大量的时间都在不断地测试lock.

注意: 指令数的显示是十进制格式, clock数是十六进制格式, 如果按照这个值来计算CPI(clock per instruction)值, CPI=60948/2547=23, 我们可以对比实验15-13的结果, 是差不多的.

另一个现象是, 4个logical处理器APIC ID值并不是连贯的. 如果将APIC ID值extract(提取)出Package ID、Core ID, 以及SMT ID, 如下所示.

![config](./images/35.png)

上面是另一个显示结果(分解出Package/Core/SMT ID值), 这个结果显示Package ID为0(表示只有一个物理处理器), 而Core有两个编号(表示有两个核心), 可是Core ID值并不是连续的, 从而造成了system bus上分配的APIC ID值并不是连贯的.