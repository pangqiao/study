
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. 概述](#1-概述)
- [2. 按虚拟平台分类](#2-按虚拟平台分类)
  - [2.1. 完全虚拟化](#21-完全虚拟化)
    - [2.1.1. 软件辅助的完全虚拟化](#211-软件辅助的完全虚拟化)
      - [2.1.1.1. 优先级压缩(Ring Compression)](#2111-优先级压缩ring-compression)
      - [2.1.1.2. 二进制代码翻译(Binary Translation)](#2112-二进制代码翻译binary-translation)
    - [2.1.2. 硬件辅助完全虚拟化](#212-硬件辅助完全虚拟化)
      - [2.1.2.1. 发展以及现状](#2121-发展以及现状)
  - [2.2. 类虚拟化](#22-类虚拟化)
- [3. 按 VMM 实现结构分类](#3-按-vmm-实现结构分类)
  - [3.1. Hypervisor 模型](#31-hypervisor-模型)
    - [3.1.1. Hypervisor 模型的优点](#311-hypervisor-模型的优点)
    - [3.1.2. Hypervisor 模型的缺点](#312-hypervisor-模型的缺点)
  - [3.2. 宿主模型](#32-宿主模型)
    - [3.2.1. 宿主模型的优点](#321-宿主模型的优点)
    - [3.2.2. 宿主模型的缺点](#322-宿主模型的缺点)
  - [3.3. 混合模型](#33-混合模型)
    - [3.3.1. 混合模型的优点](#331-混合模型的优点)
    - [3.3.2. 混合模型的缺点](#332-混合模型的缺点)
- [4. 按软件框架分类](#4-按软件框架分类)
  - [4.1. Type1: 没有宿主机 OS, Hypervisor 直接运行在硬件上](#41-type1-没有宿主机-os-hypervisor-直接运行在硬件上)
  - [4.2. Type2: Hypervisor 运行在宿主机操作系统中](#42-type2-hypervisor-运行在宿主机操作系统中)

<!-- /code_chunk_output -->

# 1. 概述

最理想的虚拟化的两个目标如下:

1) 客户机完全不知道自己运行在虚拟化环境中, 还以为自己运行在原生环境里.

2) 完全不需要 VMM 介入客户机的运行过程.

1.2.2　软件虚拟化和硬件虚拟化

1. 软件虚拟化技术

软件虚拟化, 顾名思义, 就是通过软件模拟来实现 VMM 层, 通过纯软件的环境来模拟执行客户机里的指令.

最纯粹的软件虚拟化实现当属 QEMU. 在没有启用硬件虚拟化辅助的时候, 它通过软件的二进制翻译仿真出目标平台呈现给客户机, 客户机的每一条目标平台指令都会被 QEMU 截取, 并翻译成宿主机平台的指令, 然后交给实际的物理平台执行. 由于每一条都需要这么操作一下, 其虚拟化性能是比较差的, 同时其软件复杂度也大大增加. 但好处是可以呈现各种平台给客户机, 只要其二进制翻译支持.

2. 硬件虚拟化技术

硬件虚拟化技术就是指计算机硬件本身提供能力让客户机指令独立执行, 而不需要(严格来说是不完全需要)VMM 截获重定向.

以 x86 架构为例, 它提供一个略微受限制的硬件运行环境供客户机运行(non-root mode), 在绝大多数情况下, 客户机在此受限环境中运行与原生系统在非虚拟化环境中运行没有什么两样, 不需要像软件虚拟化那样每条指令都先翻译再执行, 而 VMM 运行在 root mode, 拥有完整的硬件访问控制权限. 仅仅在少数必要的时候, 某些客户机指令的运行才需要被 VMM 截获并做相应处理, 之后客户机返回并继续在 non-root mode 中运行. 可以想见, 硬件虚拟化技术的性能接近于原生系统, 并且, 极大地简化了 VMM 的软件设计架构.

Intel 从 2005 年就开始在其 x86 CPU 中加入硬件虚拟化的支持——Intel Virtualization Technology, 简称 Intel VT. 到目前为止, 在所有的 Intel CPU 中, 都可以看到 Intel VT 的身影. 并且, 每一代新的 CPU 中, 都会有新的关于硬件虚拟化支持、改进的 feature 加入. 也因如此, Intel x86 平台是对虚拟化支持最为成熟的平台, 本书将以 Intel x86 平台为例介绍 KVM 的虚拟化.

# 2. 按虚拟平台分类

根据**VMM 提供的虚拟平台类**型可将 VMM 分成两类:

第一类 VMM 虚拟的是**现实存在的平台**, 并且在**客户机操作系统**来看, **虚拟的平台**和**现实的平台是一样**的, **客户机操作系统**察觉不到是运行在一个虚拟平台上. 这样的虚拟平台可以运行现有的操作系统, **无须对操作系统进行修改**, 因此称为**完全虚拟化**(Full Virtualization).

第二类 VMM 虚拟的是**现实中不存在的平台**, 而是经过**VMM 重新定义**的, 这种虚拟化平台需要对所运行的**客户机操作系统**进行或多或少的**修改**使之适应虚拟环境, 因此**客户机 OS 知道其运行在虚拟平台**上, 并且会去主动适应. 这种称为类虚拟化(Para Virtualization).

另外, 一个 VMM 既可以提供完全的虚拟化的虚拟平台, 又提供类虚拟化的虚拟平台.

## 2.1. 完全虚拟化

客户 OS 无须修改就可以运行. 所以客户 OS 会像操作正常的处理器、内存、I/O 设备一样来操作虚拟处理器、虚拟内存和虚拟 I/O 设备. 从实现角度看, **客户机的行为**是通过**指令**反映出来的, 因此 VMM 需要能**正确处理所有可能的命令！！！**.

对于完全虚拟化来说, **所有可能的指令**是指所虚拟的处理器其**手册规范**上定义的**所有指令**.

实现上, 以 x86 架构为例, **完全虚拟化**经历了两个阶段: **软件辅助的完全虚拟化**和**硬件辅助的完全虚拟化**

### 2.1.1. 软件辅助的完全虚拟化

**x86 虚拟化**技术早期, x86 体系**没有在硬件层次！！！上对虚拟化提供支持**, 因此完全虚拟化只能通过**软件实现**.

一个典型做法是**优先级压缩(Ring Compression**)和**二进制代码翻译(Binary Translation**)相结合.

#### 2.1.1.1. 优先级压缩(Ring Compression)

**优先级压缩**的原理是: 由于**VMM**和**客户机**运行在**不同特权级**上, 对应到**x86**上, 通常是**VMM 运行在 Ring 0**, **客户机 OS 内核**运行在**Ring 1**, **客户机 OS 应用程序**运行在**Ring 3**. 当**客户机 OS 内核**执行**相关特权指令**时, 由于在**非特权的 Ring 1**, 因此通常**触发异常**, **VMM 截获**该**特权指令**并进行**虚拟化**.

**Ring Compression**能正确处理**大部分特权指令**, 但是由于**x86 指令体系**在**设计之初**并**没有考虑到虚拟化**, 因此**有些指令**还是**不能通过 Ring Compression 正常处理**, 即在**Ring 1 做特权操作**的时候却**没有触发异常(比如修改 EFLAGES 的 IF 标志**), 从而 VMM 不能截获并做相应处理.

#### 2.1.1.2. 二进制代码翻译(Binary Translation)

**二进制代码翻译方法**因此被引入来处理这些**虚拟化不友好的指令**.

二进制代码翻译的思想很简单, 就是通过**扫描并修改客户机的二进制代码**, 将**难以虚拟化的指令**转化为**支持虚拟化的指令**.

**VMM**通常会对**OS**的**二进制代码进行扫描**, 一旦发现**需要处理的指令**, 就将其翻译成**支持虚拟化的指令块(Cache Block**). 这些**指令块**可以与 VMM 合作**访问受限的虚拟资源！！！**, 或**显式地触发异常！！！** 让 VMM 进一步处理.

此外, 由于**该技术可以修改客户机的二进制代码**, 因此别广泛应用于**性能优化！！！**, 即将某些**造成性能瓶颈的指令**替换成**更高效的指令**来提高性能.

这种方式很难**在架构上保证其完整性**, 因此, x86 在硬件上加入了对虚拟化的支持, 从而在硬件架构上实现了虚拟化.

### 2.1.2. 硬件辅助完全虚拟化

很多问题, 如果在**本身的层次**上难以解决, 那通过**增加一个层次**, 在**其下面一个层次**就会变得容易解决.

硬件辅助虚拟化就是这样一种方式, 既然 OS 是硬件上最后一层系统软件, 如果**硬件本身加入足够的虚拟化功能**, 就可以**截获操作系统对敏感指令的执行**或**对敏感资源的访问**, 从而通过异常方式报告给 VMM, 这就解决了虚拟化的问题.

Intel 的 VT\-x 技术就是这样. VT\-x 在处理器上**新引入了一个新的执行模式**用于**运行虚拟机**. 当虚拟机执行在这个特殊模式中时, 它仍然面对的是**一套完整的处理器寄存器集合和执行环境**, 只是对任何特权操作都会被处理器截获并报告给 VMM. VMM 本身运行在正常模式下, 在接收到处理器的报告后, 通过对目标指令的解码, 找到对应的虚拟化模块进行模拟, 并把最终的效果反映在特殊模式下的环境中.

硬件辅助虚拟化是一种完备的虚拟化方法, 因为内存和外设的访问本身也是由指令来承载, 对处理器指令级别的截获意味 VMM 可以模拟一个与真实主机完全一样的环境.

#### 2.1.2.1. 发展以及现状

与半虚拟化相反的, **全虚拟化(Full Virtualization**)坚持第一个理想化目标: **客户机的操作系统完全不需要改动**. 敏感指令在操作系统和硬件之间被 VMM 捕捉处理, 客户操作系统无须修改, 所有软件都能在虚拟机中运行. 因此, 全虚拟化需要模拟出完整的、和物理平台一模一样的平台给客户机, 这在达到了第一个目标的同时也增加了虚拟化层(VMM)的复杂度.

性能上, 2005 年硬件虚拟化兴起之前, 软件实现的全虚拟化完败于 VMM 和客户机操作系统协同运作的半虚拟化, 这种情况一直延续到 2006 年. 之后以 Intel VT\-x、VT\-d 为代表的硬件虚拟化技术的兴起, 让由硬件虚拟化辅助的全虚拟化全面超过了半虚拟化. 但是, 以 virtio 为代表的半虚拟化技术也一直在演进发展, 性能上只是略逊于全虚拟化, 加之其较少的平台依赖性, 依然受到广泛的欢迎.

## 2.2. 类虚拟化

两个虚拟化目标中, 纯软件的虚拟化可以做到第一个目标, 但性能不是很好, 而且软件设计的复杂度大大增加.

那么如果放弃第一个目标呢?让客户机意识到自己是运行在虚拟化环境里, 并做相应修改以配合 VMM, 这就是半虚拟化(Para\-Virtualization).

- 一方面, 可以提升性能和简化 VMM 软件复杂度;
- 另一方面, 也不需要太依赖硬件虚拟化的支持, 从而使得其软件设计(至少是 VMM 这一侧)可以跨平台且是优雅的.

通过在**源代码级别修改指令**以**回避虚拟化漏洞的方式**来使 VMM 能够对物理资源实现虚拟化.

x86 的难以虚拟化的指令, **完全虚拟化**通过**Binary Translation**在二进制代码级别上**避免虚拟化漏洞**. **类虚拟化**采用另一种思路, 即**修改操作系统的内核**(即 API 级), 使得操作系统内核完全**避免这些难以虚拟化的指令**. 操作系统通常会用到处理器提供的所有功能, 例如特权级别、地址空间和控制寄存器等.

**类虚拟化**首先解决的问题就是**如何插入 VMM**. 典型做法是修改操作系统的处理器相关代码, 让操作系统主动让出特权级别, 而运行在次一级特权级. 这样, 当操作系统试图执行特权指令时, 保护异常被触发, 从而提供截获点给 VMM 来模拟.

既然内核代码需要被修改, 类虚拟化可以进一步用来**优化 I/O**. 即, **类虚拟化不是去模拟真实设备**, 因为太多寄存器模拟会影响性能. 相反, 类虚拟化可以定义出高度优化的 I/O 协议. 这种 I/O 协议**完全基于事务**, 可以达到近物理机的速度.

"本质上, 准虚拟化弱化了对虚拟机特殊指令的被动截获要求, 将其转化成客户机操作系统的主动通知. 但是, 准虚拟化需要修改客户机操作系统的源代码来实现主动通知. "典型的半虚拟化技术就是**virtio**, 使用 virtio 需要在宿主机/VMM 和客户机里都相应地装上驱动.

# 3. 按 VMM 实现结构分类

## 3.1. Hypervisor 模型

在 Hypervisor 模型中, **VMM**首先可被看作是一个**完备的操作系统！！！**, 不过和传统 OS 不同, **VMM 为虚拟化而设计**的, 因此还**具备虚拟化功能**.

从架构看,

- 首先, **所有物理资源**如处理器、内存和 I/O 设备都归**VMM 所有**, 因此, **VMM 管理物理资源**;

- 其次, VMM 需要**向上提供虚拟机**用于**运行客户操作系统**, 因此, **VMM 负责虚拟环境的创建和管理**.

图 3-9 展示了 Hypervisor 的架构, 其中

- **处理器管理代码**(Processor, P)负责**物理处理器的管理和虚拟化！！！**,
- **内存管理代码**(Memory, M)负责**物理内存的管理和虚拟化！！！**,
- **设备模型**(Device Model, DM)负责**I/O 设备的虚拟化**,
- **设备驱动**(Device Driver, DR)负责**I/O 设备的驱动**, 即**物理设备的管理**.

VMM 直接管理所有物理资源, 包括处理器、内存和 I/O 设备, 所以**设备驱动**也是**VMM 的一部分**. 此外, **处理器管理代码**、**内存管理代码**和**设备模型**也是**VMM 的一部分**.

Hypervisor 模型的 VMM:

![](./images/2019-07-01-17-52-21.png)

### 3.1.1. Hypervisor 模型的优点

由于 VMM 同时具备**物理资源的管理功能**和**虚拟化功能**, 所以, **物理资源虚拟化效率更高**.

安全层面, **虚拟机的安全只依赖 VMM 的安全**. 宿主模型中同时依赖 VMM 和宿主机 OS 的安全.

### 3.1.2. Hypervisor 模型的缺点

Hypervisor 模型拥有虚拟化高效率同时也有缺点.

由于 VMM 完全拥有物理资源, 因此, VMM 需要进行**物理资源的管理**, 包括**设备的驱动**. 设备驱动工作量很大, 所以基于 Hypervisor 模型的 VMM 通常根据市场定位, **选择一些 I/O 设备来支持**, 而**不是所有**.

此外, 很多功能必须在 VMM 中**重新实现**, 例如**调度和电源管理等**, 无法像宿主模型那样借助宿主机 OS.

## 3.2. 宿主模型

- **物理资源**由**宿主机 OS 管理**. **宿主机 OS**并**不是为虚拟化设计**的, 因此本身不具备虚拟化功能, 有些实现中还包括**用户态进程**, 如负责 I/O 虚拟化的用户态设备模型.

- **VMM**通过调用**宿主机 OS**的服务来**获得资源**, 实现处理器、内存和 I/O 设备的虚拟化. VMM 创建虚拟机后, 通常**将虚拟机**作为**宿主机 OS**的**一个进程**参与调度.

图 3\-10 显示宿主模型架构.

- **宿主机 OS**拥有**所有物理资源**, 包括 I/O 设备, 所以**设备驱动位于宿主机操作系统**中.
- VMM(图中**虚拟机管理内核模块**)则包含**处理器虚拟化模块**和**内存虚拟化模块**.

图中**设备模型**实际也是**VMM 一部分**, 具体实现中, 可将**设备模型放在用户态**, 也可放在**内核态**.

宿主模型的 VMM:

![](./images/2019-07-01-17-54-03.png)

### 3.2.1. 宿主模型的优点

宿主模型的**优缺点**和 Hypervisor 模型**恰好相反**.

**宿主模型**最大优点是能充分利用**现有 OS 的设备驱动程序**, **VMM**无须为各类 I/O 设备重新实现驱动程序, 可以专注于**物理资源的虚拟化**.

此外, 宿主模型也可利用**宿主机 OS**的其它功能, 例如调度和电源管理等, 这都**不需要 VMM 重新实现**.

### 3.2.2. 宿主模型的缺点

缺点.

- **VMM**调用**宿主机 OS**的服务**获取资源进行虚拟化**, 系统服务设计之初没考虑虚拟化支持, 效率和功能有影响.
- **安全**, 虚拟机的安全同时依赖**VMM 和宿主机 OS 的安全**.

## 3.3. 混合模型

**VMM 仍然在最底层**, 拥有**所有物理资源**.

与 Hypervisor 不同的是, VMM 会主动让出**大部分 I/O 设备的控制权**, 将他们交给一个运行在**特权虚拟机**中的**特权操作系统**来控制.

相应, VMM 虚拟化的职责也被分担. **处理器和内存的虚拟化**仍然是**VMM**完成, 而**I/O 虚拟化**由**VMM 和特权操作系统共同合作**完成.

图 3\-11 显示混合模型.

- **I/O 设备**由**特权操作系统**控制, 因此, **设备驱动模块**位于**特权操作系统**中.
- **其它物理资源**的管理和虚拟化由**VMM**完成, 因此, **处理器管理代码**和**内存管理代码**在 VMM 中.

混合模型的 VMM:

![](./images/2019-07-01-17-55-53.png)

**I/O 设备的虚拟化**由**VMM**和**特权操作系统**共同完成, 因此, **设备模型模块**位于特权操作系统中, 并且通过相应的通信机制与 VMM 合作.

### 3.3.1. 混合模型的优点

混合模型集中了**上面两种模型的优点**.

VMM 既可利用**现有 OS 的 I/O 设备驱动**. VMM 直接控制处理器、内存等物理资源, 虚拟化效率比较高.

安全性上, 对特权 OS 的权限控制得当, 虚拟机**安全性只依赖 VMM**.

### 3.3.2. 混合模型的缺点

缺点.

**特权 OS**运行在**虚拟机上**, 当需要**特权 OS 提供服务**时, VMM 需要**切换**, 产生上下文切换开销. **切换频繁**时, **上下文切换开销**会造成性能的明显下降.

出于**性能考虑**, 很多功能还是必须在 VMM 中实现, 无法借助特权 OS, 如调度程序和电源管理等.

# 4. 按软件框架分类

从软件框架的角度上, 根据**虚拟化层**是**直接位于硬件之上**还是**在一个宿主操作系统**之上, 将虚拟化划分为 Type1 和 Type2, 如图 1-6 所示.

![](./images/2019-05-12-20-15-55.png)

## 4.1. Type1: 没有宿主机 OS, Hypervisor 直接运行在硬件上

Type1(类型 1)Hypervisor 也叫**native**或 **bare-metal Hypervisor**. 这类**虚拟化层直接运行在硬件之上**, 没有所谓的宿主机操作系统. 它们**直接控制硬件资源以及客户机**. 典型地如 **Xen** 和 VMware ESX.

## 4.2. Type2: Hypervisor 运行在宿主机操作系统中

Type2(类型 2) Hypervisor **运行在一个宿主机操作系统之上**, 如 VMware Workstation; 或**系统**里, 如 KVM. 这类 Hypervisor 通常就是**宿主机操作系统的一个应用程序**, 像其他应用程序一样受宿主机操作系统的管理. 比如**VMware Workstation**就是运行在**Windows 或者 Linux 操作系统**上的**一个程序**而已. **客户机**是在**宿主机操作系统**上的**一个抽象**, 通常抽象为**进程**.