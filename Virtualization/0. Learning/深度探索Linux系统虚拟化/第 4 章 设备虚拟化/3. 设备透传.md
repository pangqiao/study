设备虚拟化如果采用软件模拟的方式，则需要VMM参与进来。为了避免这个开销，Intel尝试从硬件层面对I/O虚拟化进行支持，即将设备直接透传给Guest，Guest绕过VMM直接访问物理设备，无须VMM参与I/O过程，这种方式提供了最佳的I/O虚拟化性能。Intel最初采用的方式是Direct Assignment，即将整个设备透传给某一台虚拟机，不支持多台VM共享同一设备。

对于一台多核的物理机，其上可以运行若干台虚拟机，如果外设只能分配给一台虚拟机使用，那么这种方案显然不具备扩展性。于是设备制造商们试图在硬件层面将一个物理设备虚拟出多个设备，每个设备可以透传给一台虚拟机，这样从硬件设备层面实现共享，而无须由VMM通过软件的方式支持多台虚拟机共享同一物理外设。为了使不同设备制造商的设备可以互相兼容，PCI-SIG制定了一个标准：Single Root I/O Virtualization and Sharing，简称SR-IOV。SR-IOV引入了两个新的Function类型，一个是Physical Function，简称PF; 另一个是Virtual Function，简称VF。一个SR-IOV可以支持多个VF，每一个VF可以分别透传给Guest，如此，就从硬件角度实现了多个Guest分享同一物理设备，如图4-9所示。

![2024-03-01-18-54-24.png](./images/2024-03-01-18-54-24.png)

每个VF都有自己独立的用于数据传输的存储空间、队列、中断及命令处理单元等，但是这些VF的管理仍然在VMM的控制下，VMM通过PF管理这些VF。虚拟机可以直接访问这些VF，而无须再通过VMM中的模拟设备访问物理设备。PF除了提供管理VF的途径外，Host以及其上的应用仍然可以通过PF无差别地访问物理设备。对于那些没有VF驱动的 Guest，虚拟机依然可以通过SR-IOV设备的PF接口共享物理设备。

# 虚拟配置空间

通过将VF透传给Guest的方式，VF的数据访问不再需要通过VMM，大大提高了Guest的I/O性能。但是，如果Guest恶意修改配置空间中的信息，比如中断信息（MSI），则可能导致VF发出中断攻击。因此，出于安全方面的考虑，VF配置空间仍然需要VMM介入，而且后面我们会看到，有些信息，比如寄存器BAR中的地址，必须依照虚拟化场景进行虚拟。Guest不能直接修改设备的配置，当Guest访问VF的配置空间时，将会触发VM exit陷入VMM，VMM将过滤Guest对VF配置空间的访问并作为Guest的代理完成对VF设备的配置空间的操作。这个过程不会卷入数据传输中，因此不影响数据传输的效率。

前面在讨论PCI配置空间及其模拟时，我们看到kvmtool定义了一个数组pci_devices，用来记录虚拟机所有的PCI设备，后来kvmtool将这个数组优化为一棵红黑树。当Guest枚举PCI设备时，kvmtool将以设备号为索引在这个数据结构中查找设备。因此，为了能够让Guest枚举到VF，kvmtool需要将VF注册到这个数据结构中，用户可以通过kvmtool的命令行参数“vfio-pci”指定将哪些VF透传给虚拟机：

```cpp

```

对于VF来说，在系统启动时，虽然Host的BIOS（或者UEFI）已经为VF划分好了内存地址空间并存储在了寄存器BAR中，而且Guest也可以直接读取这个信息。但是，因为Guest不能直接访问Host的物理地址，所以Guest并不能直接使用寄存器BAR中记录的HPA。所以，kvmtool需要对VF配置空间中寄存器BAR的内容进行虚拟，结合内存虚拟化原理，设备板上内存到Guest空间的映射关系如图4-10所示。

![2024-03-01-18-56-10.png](./images/2024-03-01-18-56-10.png)

结合图4-10，kvmtool需要完成两件事：一是将VF配置空间的BAR寄存器中的地址信息修改为GPA，而不是HPA；二是保护模式下的CPU是采用虚拟地址寻址的，所以PA还需要映射为VA，操作系统自身提供了mmap功能完成PA到VA的映射，因此，kvmtool只需要建立GPA到HVA的映射关系。相关代码如下：

```cpp

```

普通的虚拟设备没有真实的配置空间，所以kvmtool需要从0开始组织虚拟设备的配置空间。而VF是有真实的配置空间的，kvmtool需要做的是加工，所以kvmtool首先需要读取VF的配置空间，然后在这个原始数据的基础上进行加工，第11行代码就是读取VF的配置空间并进行解析。然后，kvmtool从Guest地址空间中为VF板上内存分配地址空间，并使用GPA更新寄存器BAR，第13～18行代码就是循环处理所有的寄存器BAR。最后，kvmtool将加工好的配置空间更新回VF真实的配置空间，见第20行代码。函数 vfio_pci_parse_cfg_space读取VF配置空间，具体代码如下。VF中将配置空间分成很多区域，比如每256字节的配置空间是一个区域，每个BAR定义对应一个区域。代码中 VFIO_PCI_CONFIG_REGION_INDEX对应的就是256字节的配置空间，对于PCIe设备，配置空间大小是4096字节。函数vfio_pci_parse_cfg_space首先通过ioctl获取配置空间在VF中的偏移，然后调用函数pread从这个偏移处读取配置空间：

```cpp

```

接下来，kvmtool需要从Guest地址空间中为VF板上内存分配地址空间，并使用GPA更新配置空间中的寄存器BAR，这个逻辑在函数vfio_pci_configure_bar中。函数vfio_pci_configure_bar首先通过ioctl从VF中读取BAR对应的区域的信息，然后根据获取的区域的大小（代码中的map_size）调用函数pci_get_io_space_block从Guest的地址空间中分配地址区间。函数pci_get_io_space_block从变量io_space_blocks指定的地址空间处，依次为PCI设备在Guest的地址空间中分配地址。分配好了Guest的地址区间后，还需要将这个地址区间和Host的BIOS（或者UEFI）为VF分配的真实的物理地址区间一一映射起来，这就是vfio_pci_configure_bar调用vfio_map_region的目的：

```cpp

```

函数vfio_map_region为GPA和HVA建立起映射关系。从内存虚拟化角度，其实就是Host为Guest准备一个内存条:

```cpp

```

显然，对应我们现在的情况，变量guest_phys_addr就是kvmtool为BAR对应的区间在Guest地址空间中分配的地址。变量userspace_addr就是Host的BIOS（或者UEFI）为VF在Host的地址空间分配的地址PA对应的VA，函数vfio_map_region中调用mmap函数就是为了得出VA。确定了变量guest_phys_addr和userspace_addr后，vfio_map_region调用kvm__register_dev_mem请求KVM模块为Guest注册虚拟内存条。当CPU发出对BAR对应的内存地址空间的访问时，EPT或者影子页表会将GPA翻译为VF在Host地址空间中的相应HPA，当这个HPA到达Host bridge时，内存控制器将忽略这个地址，PCI bost bridge或者Root Complex将认领这个地址。函数vfio_map_region的代码如下：

```cpp

```

完成了BAR等寄存器的加工后，kvmtool将调用vfio_pci_fixup_cfg_space将加工好的配置空间更新到VF的配置空间中。比如下面的代码中，我们可以看到，寄存器BAR的信息是kvmtool加工后的信息：

```cpp

```

除了寄存器BAR的虚拟外，还有其他的一些虚拟，比如为了支持MSI-X，需要虚拟配置空间中设备相关的Capability部分。这些逻辑都比较直接，我们不再一一讨论了。

# DMA 重映射

将设备直接透传给Guest后，为了提高数据传输效率，透传设备可以直接访问内存，但是如果Guest可以直接控制设备，那就需要防范恶意的Guest借助透传的设备访问其他Guest或者Host的内存。比如，Device A透传给了Guest-1，但是其有可能访问Guest-2和Host的内存；Device B透传给了Guest-2，但是其也有可能访问Guest-1和Host 的内存，如图4-11所示。

