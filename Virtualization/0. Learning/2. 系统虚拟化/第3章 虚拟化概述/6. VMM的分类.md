
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. 概述](#1-概述)
- [2. 按虚拟平台分类](#2-按虚拟平台分类)
  - [2.1. 完全虚拟化](#21-完全虚拟化)
    - [2.1.1. 软件辅助的完全虚拟化](#211-软件辅助的完全虚拟化)
      - [2.1.1.1. 优先级压缩(Ring Compression)](#2111-优先级压缩ring-compression)
      - [2.1.1.2. 二进制代码翻译(Binary Translation)](#2112-二进制代码翻译binary-translation)
    - [2.1.2. 硬件辅助完全虚拟化](#212-硬件辅助完全虚拟化)
      - [2.1.2.1. 发展以及现状](#2121-发展以及现状)
  - [2.2. 类虚拟化](#22-类虚拟化)
- [3. 按VMM实现结构分类](#3-按vmm实现结构分类)
  - [3.1. Hypervisor模型](#31-hypervisor模型)
    - [3.1.1. Hypervisor模型的优点](#311-hypervisor模型的优点)
    - [3.1.2. Hypervisor模型的缺点](#312-hypervisor模型的缺点)
  - [3.2. 宿主模型](#32-宿主模型)
    - [3.2.1. 宿主模型的优点](#321-宿主模型的优点)
    - [3.2.2. 宿主模型的缺点](#322-宿主模型的缺点)
  - [3.3. 混合模型](#33-混合模型)
    - [3.3.1. 混合模型的优点](#331-混合模型的优点)
    - [3.3.2. 混合模型的缺点](#332-混合模型的缺点)
- [4. 按软件框架分类](#4-按软件框架分类)
  - [4.1. Type1: 没有宿主机OS, Hypervisor直接运行在硬件上](#41-type1-没有宿主机os-hypervisor直接运行在硬件上)
  - [4.2. Type2: Hypervisor运行在宿主机操作系统中](#42-type2-hypervisor运行在宿主机操作系统中)

<!-- /code_chunk_output -->

# 1. 概述

最理想的虚拟化的两个目标如下: 

1)客户机完全不知道自己运行在虚拟化环境中, 还以为自己运行在原生环境里. 

2)完全不需要VMM介入客户机的运行过程. 


1.2.2　软件虚拟化和硬件虚拟化

1.软件虚拟化技术

软件虚拟化, 顾名思义, 就是通过软件模拟来实现VMM层, 通过纯软件的环境来模拟执行客户机里的指令. 

最纯粹的软件虚拟化实现当属QEMU. 在没有启用硬件虚拟化辅助的时候, 它通过软件的二进制翻译仿真出目标平台呈现给客户机, 客户机的每一条目标平台指令都会被QEMU截取, 并翻译成宿主机平台的指令, 然后交给实际的物理平台执行. 由于每一条都需要这么操作一下, 其虚拟化性能是比较差的, 同时其软件复杂度也大大增加. 但好处是可以呈现各种平台给客户机, 只要其二进制翻译支持. 

2.硬件虚拟化技术

硬件虚拟化技术就是指计算机硬件本身提供能力让客户机指令独立执行, 而不需要(严格来说是不完全需要)VMM截获重定向. 

以x86架构为例, 它提供一个略微受限制的硬件运行环境供客户机运行(non-root mode), 在绝大多数情况下, 客户机在此受限环境中运行与原生系统在非虚拟化环境中运行没有什么两样, 不需要像软件虚拟化那样每条指令都先翻译再执行, 而VMM运行在root mode, 拥有完整的硬件访问控制权限. 仅仅在少数必要的时候, 某些客户机指令的运行才需要被VMM截获并做相应处理, 之后客户机返回并继续在non-root mode中运行. 可以想见, 硬件虚拟化技术的性能接近于原生系统, 并且, 极大地简化了VMM的软件设计架构. 

Intel从2005年就开始在其x86 CPU中加入硬件虚拟化的支持——Intel Virtualization Technology, 简称Intel VT. 到目前为止, 在所有的Intel CPU中, 都可以看到Intel VT的身影. 并且, 每一代新的CPU中, 都会有新的关于硬件虚拟化支持、改进的feature加入. 也因如此, Intel x86平台是对虚拟化支持最为成熟的平台, 本书将以Intel x86平台为例介绍KVM的虚拟化. 

# 2. 按虚拟平台分类

根据**VMM提供的虚拟平台类**型可将VMM分成两类: 

第一类VMM虚拟的是**现实存在的平台**, 并且在**客户机操作系统**来看, **虚拟的平台**和**现实的平台是一样**的, **客户机操作系统**察觉不到是运行在一个虚拟平台上. 这样的虚拟平台可以运行现有的操作系统, **无须对操作系统进行修改**, 因此称为**完全虚拟化**(Full Virtualization). 

第二类VMM虚拟的是**现实中不存在的平台**, 而是经过**VMM重新定义**的, 这种虚拟化平台需要对所运行的**客户机操作系统**进行或多或少的**修改**使之适应虚拟环境, 因此**客户机OS知道其运行在虚拟平台**上, 并且会去主动适应. 这种称为类虚拟化(Para Virtualization). 

另外, 一个VMM既可以提供完全的虚拟化的虚拟平台, 又提供类虚拟化的虚拟平台.

## 2.1. 完全虚拟化

客户OS无须修改就可以运行. 所以客户OS会像操作正常的处理器、内存、I/O设备一样来操作虚拟处理器、虚拟内存和虚拟I/O设备. 从实现角度看, **客户机的行为**是通过**指令**反映出来的, 因此VMM需要能**正确处理所有可能的命令！！！**. 

对于完全虚拟化来说, **所有可能的指令**是指所虚拟的处理器其**手册规范**上定义的**所有指令**.

实现上, 以x86架构为例, **完全虚拟化**经历了两个阶段: **软件辅助的完全虚拟化**和**硬件辅助的完全虚拟化**

### 2.1.1. 软件辅助的完全虚拟化

**x86虚拟化**技术早期, x86体系**没有在硬件层次！！！上对虚拟化提供支持**, 因此完全虚拟化只能通过**软件实现**. 

一个典型做法是**优先级压缩(Ring Compression**)和**二进制代码翻译(Binary Translation**)相结合.

#### 2.1.1.1. 优先级压缩(Ring Compression)

**优先级压缩**的原理是: 由于**VMM**和**客户机**运行在**不同特权级**上, 对应到**x86**上, 通常是**VMM运行在Ring 0**, **客户机OS内核**运行在**Ring 1**, **客户机OS应用程序**运行在**Ring 3**. 当**客户机OS内核**执行**相关特权指令**时, 由于在**非特权的Ring 1**, 因此通常**触发异常**, **VMM截获**该**特权指令**并进行**虚拟化**. 

**Ring Compression**能正确处理**大部分特权指令**, 但是由于**x86指令体系**在**设计之初**并**没有考虑到虚拟化**, 因此**有些指令**还是**不能通过Ring Compression正常处理**, 即在**Ring 1做特权操作**的时候却**没有触发异常(比如修改EFLAGES的IF标志**), 从而VMM不能截获并做相应处理. 

#### 2.1.1.2. 二进制代码翻译(Binary Translation)

**二进制代码翻译方法**因此被引入来处理这些**虚拟化不友好的指令**. 

二进制代码翻译的思想很简单, 就是通过**扫描并修改客户机的二进制代码**, 将**难以虚拟化的指令**转化为**支持虚拟化的指令**. 

**VMM**通常会对**OS**的**二进制代码进行扫描**, 一旦发现**需要处理的指令**, 就将其翻译成**支持虚拟化的指令块(Cache Block**). 这些**指令块**可以与VMM合作**访问受限的虚拟资源！！！**, 或**显式地触发异常！！！** 让VMM进一步处理. 

此外, 由于**该技术可以修改客户机的二进制代码**, 因此别广泛应用于**性能优化！！！**, 即将某些**造成性能瓶颈的指令**替换成**更高效的指令**来提高性能.

这种方式很难**在架构上保证其完整性**, 因此, x86在硬件上加入了对虚拟化的支持, 从而在硬件架构上实现了虚拟化.

### 2.1.2. 硬件辅助完全虚拟化

很多问题, 如果在**本身的层次**上难以解决, 那通过**增加一个层次**, 在**其下面一个层次**就会变得容易解决. 

硬件辅助虚拟化就是这样一种方式, 既然OS是硬件上最后一层系统软件, 如果**硬件本身加入足够的虚拟化功能**, 就可以**截获操作系统对敏感指令的执行**或**对敏感资源的访问**, 从而通过异常方式报告给VMM, 这就解决了虚拟化的问题. 

Intel的VT\-x技术就是这样. VT\-x在处理器上**新引入了一个新的执行模式**用于**运行虚拟机**. 当虚拟机执行在这个特殊模式中时, 它仍然面对的是**一套完整的处理器寄存器集合和执行环境**, 只是对任何特权操作都会被处理器截获并报告给VMM. VMM本身运行在正常模式下, 在接收到处理器的报告后, 通过对目标指令的解码, 找到对应的虚拟化模块进行模拟, 并把最终的效果反映在特殊模式下的环境中.

硬件辅助虚拟化是一种完备的虚拟化方法, 因为内存和外设的访问本身也是由指令来承载, 对处理器指令级别的截获意味VMM可以模拟一个与真实主机完全一样的环境. 

#### 2.1.2.1. 发展以及现状

与半虚拟化相反的, **全虚拟化(Full Virtualization**)坚持第一个理想化目标: **客户机的操作系统完全不需要改动**. 敏感指令在操作系统和硬件之间被VMM捕捉处理, 客户操作系统无须修改, 所有软件都能在虚拟机中运行. 因此, 全虚拟化需要模拟出完整的、和物理平台一模一样的平台给客户机, 这在达到了第一个目标的同时也增加了虚拟化层(VMM)的复杂度. 

性能上, 2005年硬件虚拟化兴起之前, 软件实现的全虚拟化完败于VMM和客户机操作系统协同运作的半虚拟化, 这种情况一直延续到2006年. 之后以Intel VT\-x、VT\-d为代表的硬件虚拟化技术的兴起, 让由硬件虚拟化辅助的全虚拟化全面超过了半虚拟化. 但是, 以virtio为代表的半虚拟化技术也一直在演进发展, 性能上只是略逊于全虚拟化, 加之其较少的平台依赖性, 依然受到广泛的欢迎. 

## 2.2. 类虚拟化

两个虚拟化目标中, 纯软件的虚拟化可以做到第一个目标, 但性能不是很好, 而且软件设计的复杂度大大增加. 

那么如果放弃第一个目标呢？让客户机意识到自己是运行在虚拟化环境里, 并做相应修改以配合VMM, 这就是半虚拟化(Para\-Virtualization). 

- 一方面, 可以提升性能和简化VMM软件复杂度; 
- 另一方面, 也不需要太依赖硬件虚拟化的支持, 从而使得其软件设计(至少是VMM这一侧)可以跨平台且是优雅的. 

通过在**源代码级别修改指令**以**回避虚拟化漏洞的方式**来使VMM能够对物理资源实现虚拟化. 

x86的难以虚拟化的指令, **完全虚拟化**通过**Binary Translation**在二进制代码级别上**避免虚拟化漏洞**. **类虚拟化**采用另一种思路, 即**修改操作系统的内核**(即API级), 使得操作系统内核完全**避免这些难以虚拟化的指令**. 操作系统通常会用到处理器提供的所有功能, 例如特权级别、地址空间和控制寄存器等. 

**类虚拟化**首先解决的问题就是**如何插入VMM**. 典型做法是修改操作系统的处理器相关代码, 让操作系统主动让出特权级别, 而运行在次一级特权级. 这样, 当操作系统试图执行特权指令时, 保护异常被触发, 从而提供截获点给VMM来模拟.

既然内核代码需要被修改, 类虚拟化可以进一步用来**优化I/O**. 即, **类虚拟化不是去模拟真实设备**, 因为太多寄存器模拟会影响性能. 相反, 类虚拟化可以定义出高度优化的I/O协议. 这种I/O协议**完全基于事务**, 可以达到近物理机的速度.

"本质上, 准虚拟化弱化了对虚拟机特殊指令的被动截获要求, 将其转化成客户机操作系统的主动通知. 但是, 准虚拟化需要修改客户机操作系统的源代码来实现主动通知. "典型的半虚拟化技术就是**virtio**, 使用virtio需要在宿主机/VMM和客户机里都相应地装上驱动. 

# 3. 按VMM实现结构分类

## 3.1. Hypervisor模型

在Hypervisor模型中, **VMM**首先可被看作是一个**完备的操作系统！！！**, 不过和传统OS不同, **VMM为虚拟化而设计**的, 因此还**具备虚拟化功能**. 

从架构看, 

- 首先, **所有物理资源**如处理器、内存和I/O设备都归**VMM所有**, 因此, **VMM管理物理资源**; 

- 其次, VMM需要**向上提供虚拟机**用于**运行客户操作系统**, 因此, **VMM负责虚拟环境的创建和管理**.

图3\-9展示了Hypervisor的架构, 其中

- **处理器管理代码**(Processor, P)负责**物理处理器的管理和虚拟化！！！**, 
- **内存管理代码**(Memory, M)负责**物理内存的管理和虚拟化！！！**, 
- **设备模型**(Device Model, DM)负责**I/O设备的虚拟化**, 
- **设备驱动**(Device Driver, DR)负责**I/O设备的驱动**, 即**物理设备的管理**. 

VMM直接管理所有物理资源, 包括处理器、内存和I/O设备, 所以**设备驱动**也是**VMM的一部分**. 此外, **处理器管理代码**、**内存管理代码**和**设备模型**也是**VMM的一部分**.

Hypervisor模型的VMM:

![](./images/2019-07-01-17-52-21.png)

### 3.1.1. Hypervisor模型的优点

由于VMM同时具备**物理资源的管理功能**和**虚拟化功能**, 所以, **物理资源虚拟化效率更高**. 

安全层面, **虚拟机的安全只依赖VMM的安全**. 宿主模型中同时依赖VMM和宿主机OS的安全.

### 3.1.2. Hypervisor模型的缺点

Hypervisor模型拥有虚拟化高效率同时也有缺点. 

由于VMM完全拥有物理资源, 因此, VMM需要进行**物理资源的管理**, 包括**设备的驱动**. 设备驱动工作量很大, 所以基于Hypervisor模型的VMM通常根据市场定位, **选择一些I/O设备来支持**, 而**不是所有**. 

此外, 很多功能必须在VMM中**重新实现**, 例如**调度和电源管理等**, 无法像宿主模型那样借助宿主机OS.

## 3.2. 宿主模型

- **物理资源**由**宿主机OS管理**. **宿主机OS**并**不是为虚拟化设计**的, 因此本身不具备虚拟化功能, 有些实现中还包括**用户态进程**, 如负责I/O虚拟化的用户态设备模型. 

- **VMM**通过调用**宿主机OS**的服务来**获得资源**, 实现处理器、内存和I/O设备的虚拟化. VMM创建虚拟机后, 通常**将虚拟机**作为**宿主机OS**的**一个进程**参与调度.

图3\-10显示宿主模型架构. 

- **宿主机OS**拥有**所有物理资源**, 包括I/O设备, 所以**设备驱动位于宿主机操作系统**中. 
- VMM(图中**虚拟机管理内核模块**)则包含**处理器虚拟化模块**和**内存虚拟化模块**. 

图中**设备模型**实际也是**VMM一部分**, 具体实现中, 可将**设备模型放在用户态**, 也可放在**内核态**.

宿主模型的VMM:

![](./images/2019-07-01-17-54-03.png)

### 3.2.1. 宿主模型的优点

宿主模型的**优缺点**和Hypervisor模型**恰好相反**. 

**宿主模型**最大优点是能充分利用**现有OS的设备驱动程序**, **VMM**无须为各类I/O设备重新实现驱动程序, 可以专注于**物理资源的虚拟化**. 

此外, 宿主模型也可利用**宿主机OS**的其它功能, 例如调度和电源管理等, 这都**不需要VMM重新实现**.

### 3.2.2. 宿主模型的缺点

缺点. 

- **VMM**调用**宿主机OS**的服务**获取资源进行虚拟化**, 系统服务设计之初没考虑虚拟化支持, 效率和功能有影响. 
- **安全**, 虚拟机的安全同时依赖**VMM和宿主机OS的安全**.

## 3.3. 混合模型

**VMM仍然在最底层**, 拥有**所有物理资源**. 

与Hypervisor不同的是, VMM会主动让出**大部分I/O设备的控制权**, 将他们交给一个运行在**特权虚拟机**中的**特权操作系统**来控制. 

相应, VMM虚拟化的职责也被分担. **处理器和内存的虚拟化**仍然是**VMM**完成, 而**I/O虚拟化**由**VMM和特权操作系统共同合作**完成.

图3\-11显示混合模型. 

- **I/O设备**由**特权操作系统**控制, 因此, **设备驱动模块**位于**特权操作系统**中. 
- **其它物理资源**的管理和虚拟化由**VMM**完成, 因此, **处理器管理代码**和**内存管理代码**在VMM中.

混合模型的VMM:

![](./images/2019-07-01-17-55-53.png)

**I/O设备的虚拟化**由**VMM**和**特权操作系统**共同完成, 因此, **设备模型模块**位于特权操作系统中, 并且通过相应的通信机制与VMM合作.

### 3.3.1. 混合模型的优点

混合模型集中了**上面两种模型的优点**. 

VMM既可利用**现有OS的I/O设备驱动**. VMM直接控制处理器、内存等物理资源, 虚拟化效率比较高. 

安全性上, 对特权OS的权限控制得当, 虚拟机**安全性只依赖VMM**.

### 3.3.2. 混合模型的缺点

缺点. 

**特权OS**运行在**虚拟机上**, 当需要**特权OS提供服务**时, VMM需要**切换**, 产生上下文切换开销. **切换频繁**时, **上下文切换开销**会造成性能的明显下降. 

出于**性能考虑**, 很多功能还是必须在VMM中实现, 无法借助特权OS, 如调度程序和电源管理等.

# 4. 按软件框架分类

从软件框架的角度上, 根据**虚拟化层**是**直接位于硬件之上**还是**在一个宿主操作系统**之上, 将虚拟化划分为Type1和Type2, 如图1\-6所示. 

![](./images/2019-05-12-20-15-55.png)

## 4.1. Type1: 没有宿主机OS, Hypervisor直接运行在硬件上

Type1(类型1)Hypervisor也叫**native**或**bare\-metal Hypervisor**. 这类**虚拟化层直接运行在硬件之上**, 没有所谓的宿主机操作系统. 它们**直接控制硬件资源以及客户机**. 典型地如**Xen**和VMware ESX. 

## 4.2. Type2: Hypervisor运行在宿主机操作系统中

Type2(类型2)Hypervisor**运行在一个宿主机操作系统之上**, 如VMware Workstation; 或**系统**里, 如KVM. 这类Hypervisor通常就是**宿主机操作系统的一个应用程序**, 像其他应用程序一样受宿主机操作系统的管理. 比如**VMware Workstation**就是运行在**Windows或者Linux操作系统**上的**一个程序**而已. **客户机**是在**宿主机操作系统**上的**一个抽象**, 通常抽象为**进程**. 