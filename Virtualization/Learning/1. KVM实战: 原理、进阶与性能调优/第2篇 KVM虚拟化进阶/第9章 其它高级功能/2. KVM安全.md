
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:#     enforcing - SELinux security policy is enforced.#     permissive - SELinux prints warnings instead of enforcing.#     disabled - No SELinux policy is loaded.SELINUX=enforcing# SELINUXTYPE= can take one of these two values:#     targeted - Targeted processes are protected,#     mls - Multi Level Security protection.SELINUXTYPE=targeted](#this-file-controls-the-state-of-selinux-on-the-system-selinux-can-take-one-of-these-three-values-enforcing-selinux-security-policy-is-enforced-permissive-selinux-prints-warnings-instead-of-enforcing-disabled-no-selinux-policy-is-loadedselinuxenforcing-selinuxtype-can-take-one-of-these-two-values-targeted-targeted-processes-are-protected-mls-multi-level-security-protectionselinuxtypetargeted)
- [依次查看libvirtd、virsh、qemu的安全上下文。[root@kvm-host ~]# ls -Z /usr/sbin/libvirtd-rwxr-xr-x. root root system_u:object_r:virtd_exec_t:s0 /usr/sbin/libvirtd [root@kvm-host ~]# ls -Z /usr/bin/virsh-rwxr-xr-x. root root system_u:object_r:virsh_exec_t:s0 /usr/bin/virsh [root@kvm-host ~]# ls -Z /usr/libexec/qemu-kvm -rwxr-xr-x. root root system_u:object_r:qemu_exec_t:s0 /usr/libexec/qemu-kvm # 查看libvirt创建的客户机镜像的安全上下文。[root@kvm-host ~]# ll -Z *.img-rw-------. root root system_u:object_r:admin_home_t:s0 ia32e_rhel7u3_kvm-clone.img-rw-r--r--. root root system_u:object_r:admin_home_t:s0 ia32e_rhel7u3_kvm.img-rw-r--r--. root root system_u:object_r:admin_home_t:s0 raw_disk.img-rw-r--r--. root root system_u:object_r:admin_home_t:s0 rhel7.img](#依次查看libvirtd-virsh-qemu的安全上下文rootkvm-host-~-ls-z-usrsbinlibvirtd-rwxr-xr-x-root-root-system_uobject_rvirtd_exec_ts0-usrsbinlibvirtd-rootkvm-host-~-ls-z-usrbinvirsh-rwxr-xr-x-root-root-system_uobject_rvirsh_exec_ts0-usrbinvirsh-rootkvm-host-~-ls-z-usrlibexecqemu-kvm-rwxr-xr-x-root-root-system_uobject_rqemu_exec_ts0-usrlibexecqemu-kvm-查看libvirt创建的客户机镜像的安全上下文rootkvm-host-~-ll-z-img-rw-root-root-system_uobject_radmin_home_ts0-ia32e_rhel7u3_kvm-cloneimg-rw-r-r-root-root-system_uobject_radmin_home_ts0-ia32e_rhel7u3_kvmimg-rw-r-r-root-root-system_uobject_radmin_home_ts0-raw_diskimg-rw-r-r-root-root-system_uobject_radmin_home_ts0-rhel7img)

<!-- /code_chunk_output -->

如今，计算机信息安全越来越受到人们的重视，在计算机相关的各种学术会议、论文、期刊中，“安全”（security）一词被经常提及。因为KVM是Linux系统中的一个虚拟化相关的模块，QEMU是Linux系统上一个普通的用户空间进程，所以Linux系统上的各种安全技术、策略对QEMU/KVM都是适用的。在本节中，笔者根据经验选择了其中的一些KVM的安全技术来介绍一下。
9.2.1　SMEP/SMAP/MPX
有一些安全渗透（exploitation）攻击，会诱导系统在最高执行级别（ring0）上访问在用户空间（ring3）中的数据和执行用户空间的某段恶意代码，从而获得系统的控制权或使系统崩溃。
SMEP（Supervision Mode Execution Protection，监督模式执行保护）是Intel在2012年发布的代号为“Ivy Bridge”的新一代CPU上提供的一个安全特性。当控制寄存器CR4寄存器的20位（第21位）被设置为1时，表示SMEP特性是打开状态。SMEP特性让处于管理模式（supervisor mode，当前特权级别CPL＜3）的程序不能获取用户模式（user mode，CPL=3）可以访问的地址空间上的指令，如果管理模式的程序试图获取并执行用户模式的内存上的指令，则会发生一个错误（fault），不能正常执行。在SMEP特性的支持下，运行在管理模式的CPU不能执行用户模式的内存页，这就较好地阻止前面提到的那种渗透攻击。而且由于SMEP是CPU的一个硬件特性，这种安全保护非常方便和高效，其带来的性能开销几乎可以忽略不计。
SMAP（Supervisor Mode Access Prevention）是对SMEP的更进一步的补充，它将保护进一步扩展为Supervisor Mode（典型的如Linux内核态）代码不能直接访问（读或写）用户态的内存页（SMEP是禁止执行权限）。类似的，当它被触犯时，也会产生一个访页异常（Page Fault）。SMAP于Intel Broadwell平台中开始引入。
MPX（Memory Protection Extensions）是对软件（包括内核态的代码和用户态的代码都支持）指针越界的保护。它引入了新的寄存器记录软件运行时一个指针的合法范围，从而保证指针不会越界（无论有意或者无意）。与SMEP和SMAP不同的是，它还引入了新指令，所以要它起作用，不仅需要硬件的支持，也需要编译器的支持，以及软件运行时用到的库里面代码的支持。MPX从Intel Skylake平台以后引入。
基本上，内核（包括KVM）自3.16版本以后对SMEP/SMAP/MPX的支持都已经完备了。一些Linux发行版（如RHEL 7.2/7.3）尽管使用的是以Linux 3.10为基础的内核，但是也都向后移植（backport）了这些的特性。下面我们以SMEP为例，介绍一下如何让KVM客户机也可以使用这个安全特性的步骤。对于SMAP和MPX读者可以自行实践。
1）检查宿主机中的CPU对SMEP特性的支持。命令行如下所示：

[root@kvm-host ~]# cat /proc/cpuinfo | grep "flag" | uniq | grep smepflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch ida arat epb pln pts dtherm intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local

2）加上“-cpu host”参数来启动客户机。命令行如下：

[root@kvm-host ~]# qemu-system-x86_64 -enable-kvm -cpu host -smp 4 -m 8G -drive file=./rhel7.img,format=raw,if=virtio -device virtio-net-pci,netdev=nic0 -netdev bridge,id=nic0,br=virbr0 -snapshot -name SMEP_guest

3）在客户机中检查其CPU是否有SMEP特性的支持。命令行如下：

[root@kvm-guest ~]# cat /proc/cpuinfo | grep "flags" | uniq | grep smepflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology eagerfpu pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat

由上面的输出信息可知，客户机中已经能够检测到SMEP特性了，从而使客户机成为一个有Intel CPU的SMEP特性支持的、较为安全的环境。
9.2.2　控制客户机的资源使用——cgroups
在KVM虚拟化环境中，每个客户机操作系统使用系统的一部分物理资源（包括处理器、内存、磁盘、网络带宽等）。当一个客户机对资源的消耗过大时（特别是QEMU启动客户机时没有能够控制磁盘或网络I/O的选项），它可能会占用该系统的大部分资源，此时，其他的客户机对相同资源的请求就会受到严重影响，可能会导致其他客户机响应速度过慢甚至失去响应。为了让所有客户机都能够按照预先的比例来占用物理资源，我们需要对客户机能使用的物理资源进行控制。第5章中介绍过，通过qemu命令行启动客户机时，可以用“-smp num”参数来控制客户机的CPU个数，使用“-m size”参数来控制客户机的内存大小。不过，这些都是比较粗粒度的控制，例如，不能控制客户机仅使用1个CPU的50%的资源，而且对磁盘I/O、网络I/O等并没有直接的参数来控制。由于每个客户机就是宿主机Linux系统上的一个普通QEMU进程，所以可以通过控制QEMU进程使用的资源来达到控制客户机的目的。
1.cgroups简介

cgroups（即control groups，控制群组）是Linux内核中的一个特性，用于限制、记录和隔离进程组（processgroups）对系统物理资源的使用。cgroups最初是由Google的一些工程师（Paul Menage、Rohit Seth等）在2006年以“进程容器”（process container）的名字实现的，在2007年被重命名为“控制群组”（Control Groups），然后被合并到Linux内核的2.6.24版本中。在加入Linux内核的主干之后，cgroups越来越成熟，有很多新功能和控制器（controller）被加入进去，其功能也越来越强大。cgroups为不同的用户场景提供了一个统一的接口，这些用户场景包括对单一进程的控制，也包括OpenVZ、LXC（Linux Containers）等操作系统级别的虚拟化技术。一些较新的比较流行的Linux发行版，如RHEL、Fedora、SLES、Ubuntu等，都提供了对cgroups的支持。
cgroups提供了如下一些功能：
1）资源限制（Resource limiting），让进程组被设置为使用资源数量不能超过某个界限。如内存子系统可以为进程组设定一个内存使用的上限，一旦进程组使用的内存达到限额，如果再申请内存就会发生缺乏内存的错误（即：OOM，out of memory）。
2）优先级控制（Prioritization），让不同的进程组有不同的优先级。可以让一些进程组占用较大的CPU或磁盘I/O吞吐量的百分比，另一些进程组占用较小的百分比。
3）记录（Accounting），衡量每个进程组（包括KVM客户机）实际占用的资源数量，可以用于对客户机用户进行收费等目的。如使用cpuacct子系统记录某个进程组使用的CPU时间。
4）隔离（Isolation），对不同的进程组使用不同的命名空间（namespace），不同的进程组之间不能看到相互的进程、网络连接、文件访问等信息，如使用ns子系统就可以使不同的进程组使用不同的命名空间。
5）控制（Control），控制进程组的暂停、添加检查点、重启等，如使用freezer子系统可以将进程组挂起和恢复。
cgroups中有如下几个重要的概念，理解它们是了解cgroups的前提条件。
1）任务（task）：在cgroups中，一个任务就是Linux系统上的一个进程或线程。可以将任务添加到一个或多个控制群组中。
2）控制群组（control group）：一个控制群组就是按照某种标准划分的一组任务（进程）。在cgroups中，资源控制都是以控制群组为基本单位来实现的。一个任务可以被添加到某个控制群组，也可以从一个控制群组转移到另一个控制群组。一个控制群组中的进程可以使用以控制群组为单位分配的资源，同时也受到以控制群组为单位而设定的资源限制。
3）层级体系（hierarchy）：简称“层级”，控制群组被组织成有层级关系的一棵控制群组树。控制群组树上的子节点控制群组是父节点控制群组的孩子，可以继承父节点控制群组的一些特定属性。每个层级需要被添加到一个或多个子系统中，受到子系统的控制。
4）子系统（subsytem）：一个子系统就是一个资源控制器（resource controller），如blkio子系统就是控制对物理块设备的I/O访问的控制器。子系统必须附加到一个层级上才能起作用，一个子系统附加到某个层级以后，该子系统会控制这个层级上的所有控制群组。
目前cgroups中主要有如下10个子系统可供使用。
·blkio：这个子系统为块设备（如磁盘、固态硬盘、U盘等）设定读写I/O的访问设置限制。
·cpu：这个子系统通过使用进程调度器提供了对控制群组中的任务在CPU上执行的控制。
·cpuacct：这个子系统为控制群组中的任务所实际使用的CPU资源自动生成报告。
·cpuset：这个子系统为控制群组中的任务分配独立CPU核心（在多核系统）和内存节点。
·devices：这个子系统可以控制一些设备允许或拒绝来自某个控制群组中的任务的访问。
·freezer：这个子系统用于挂起或恢复控制群组中的任务。
·hugetlb：这个子系统用于控制对大页（见7.1节）的使用。
·memory：这个子系统为控制群组中任务能使用的内存设置限制，并能自动生成那些任务所使用的内存资源的报告。
·net_cls：这个子系统使用类别识别符（classid）标记网络数据包，允许Linux流量控制程序（traffic controller）识别来自某个控制群组中任务的数据包。
·net_prio：这个子系统使得其名下cgroups里面的任务，可以就不同的接口设置从该接口出去的包的优先级。
·perf_event：这个子系统主要用于对系统中进程运行的性能监控、采样和分析等。
·pids：这个子系统用于控制cgroups中可以派生（通过fork、clone）出来的子进程、子线程的数量（pid的数量）。
在Redhat系列的系统中，如RHEL 7.3系统的libcgroup这个RPM包提供了lssubsys工具在命令包中查看当前系统支持哪些子系统。命令行操作如下：

[root@kvm-host ~]# uname -aLinux kvm-host 3.10.0-514.el7.x86_64 #1 SMP Wed Oct 19 11:24:13 EDT 2016 x86_64 x86_64 x86_64 GNU/Linux[root@kvm-host ~]# lssubsys cpusetcpu,cpuacctmemorydevicesfreezernet_cls,net_prioblkioperf_eventhugetlbpids

cgroups中层级体系的概念与Linux系统中的进程模型有相似之处。在Linux系统中，所有进程也是组成树状的形式（可以用“pstree”命令查看），除init以外的所有进程都是一个公共父进程，即init进程的子进程。init进程是由Linux内核在启动时执行的，它会启动其他进程（当然普通进程也可以启动自己的子进程）。除init进程外的其他进程从其父进程那里继承环境变量（如$PATH变量）和其他一些属性（如打开的文件描述符）。与Linux进程模型类似，cgroups的层级体系也是树状分层结构的，子节点控制群组继承父节点控制群组的一些属性。尽管有类似的概念和结构，但它们之间也一些区别。最主要的区别是，在Linux系统中可以同时存在cgroups的一个或多个相互独立的层级，而且此时Linux系统中只有一个进程树模型（因为它们有一个相同的父进程init进程）。多个独立的层级的存在也是有其必然性的，因为每个层级都会给添加到一个或多个子系统下。
图9-3展示了cgroups模型的一个示例，其中，cpu、memory、blkio、net_cls是4个子系统，Cgroup Hierarchy A～Cgroup Hierarchy C是3个相互独立的层级，含有“cg”的就是控制群组（包括cpu_mem_cg、blk_cg、cg1、cg4等），qemu-kvm是一个任务（其PID为8201）。cpu和memory子系统同时附加到Cgroup Hierarchy A这个层级上，blkio、net_cls子系统分别附加到Cgroup Hierarchy B和Cgroup Hierarchy C这两个层级上。qemu-kvm任务被添加到这3个层级之中，它分别在cg1、cg3、cg4这3个控制群组中。
cgroups中的子系统、层级、控制群组、任务之间的关系，至少有如下几条规则需要遵循。
1）每个层级可以附加一个或多个子系统。
在图9-3中，Cgroup Hierarchy A就有cpu、memory两个子系统，而Cgroup Hierarchy B只有blkio一个子系统。

图9-3　一个cgroups模型的示例
2）只要其中的一个层级已经附加上一个子系统，任何一个子系统都不能被添加到两个或多个层级上。
在图9-3中，memory子系统就不能同时添加到层级A和层级B之上。
3）一个任务不能同时是同一个层级中的两个或多个控制群组中的成员。一个任务一旦成为同一个层级中的第2个控制群组中的成员，它必须先从第1个控制群组中移除。
在图9-3中，qemu-kvm任务就不能同时是层级A中的cg1和cg2这两个控制群组的共同成员。
4）派生（fork）出来的一个任务会完全继承它父进程的cgroups群组关系。当然，也可以再次调整派生任务的群组关系，使其与它的父进程不同。
如图9-3所示，如果PID为8201的qemu-kvm进程派生出一个子进程，则该子进程也默认是cg1、cg3、cg4这3个控制群组的成员。
5）在每次初始化一个新的层级时，该系统中所有的任务（进程或线程）都将添加该层级默认的控制群组中成为它的成员。该群组被称为根控制群组（root cgroup），在创建层级时自动创建，之后在该层级中创建的所有其他群组都是根控制群组的后代。
2.cgroups操作示例
在了解了cgroups的基本功能和原理后（关于cgroups更多描述可以参考有关文档），本节将介绍如何实际操作cgroups来控制KVM客户机的资源使用。Linux内核提供了一个统一的cgroups接口来访问多个子系统（如cpu、memory、blkio等）。在编译Linux内核时，需要对cgroups相关的项目进行配置，以下是内核中与cgroups相关的一些重要配置。

CONFIG_CGROUP_SCHED=yCONFIG_CGROUPS=y# CONFIG_CGROUP_DEBUG is not setCONFIG_CGROUP_NS=yCONFIG_CGROUP_FREEZER=yCONFIG_CGROUP_DEVICE=yCONFIG_CPUSETS=yCONFIG_PROC_PID_CPUSET=yCONFIG_CGROUP_CPUACCT=yCONFIG_RESOURCE_COUNTERS=yCONFIG_CGROUP_MEM_RES_CTLR=yCONFIG_CGROUP_MEM_RES_CTLR_SWAP=yCONFIG_BLK_CGROUP=y# CONFIG_DEBUG_BLK_CGROUP is not setCONFIG_CGROUP_PERF=yCONFIG_SCHED_AUTOGROUP=yCONFIG_MM_OWNER=y# CONFIG_SYSFS_DEPRECATED_V2 is not setCONFIG_RELAY=yCONFIG_NAMESPACES=yCONFIG_UTS_NS=yCONFIG_IPC_NS=yCONFIG_USER_NS=yCONFIG_PID_NS=yCONFIG_NET_NS=yCONFIG_NET_CLS_CGROUP=yCONFIG_NETPRIO_CGROUP=y

在实际操作过程中，可以通过以下几个方式来使用cgroups。
1）手动地访问cgroups的虚拟文件系统。
2）使用libcgroup软件包中的cgcreate、cgexec、cgclassify等工具来创建和管理cgroups控制群组。
3）通过一些使用cgroups的规则引擎，通常是系统的一个守护进程来读取cgroups相关的配置文件，然后对任务进程相应的设置。例如，在RHEL 6.3系统中，如果安装了libcgroup RPM包，就会有cgconfig这个服务可以使用（用“service cgconfig start”命令启动它），其配置文件默认为/etc/cgconfig.conf文件。
4）通过其他一些软件来间接使用cgroups，如使用操作系统虚拟化技术（LXC等）、libvirt工具等。
下面举个KVM虚拟化实际应用中的例子：一个系统中运行着两个客户机（它们的磁盘镜像文件都在宿主机的本地存储上），每个客户机中都运行着MySQL数据库服务，其中一个数据库的优先级很高（需要尽可能快地响应），另一个优先级不高（慢一点也无所谓）。我们知道，数据库服务是磁盘I/O密集型服务，所以这里通过cgroups的blkio子系统来设置两个客户机对磁盘I/O读写的优先级，从而使优先级高的客户机能够占用更多的宿主机中的I/O资源。采用手动读写cgroups虚拟文件系统的方式实现这个需求的操作步骤如下：
1）启动这两个客户机和其中的MySQL服务器，让其他应用开始使用MySQL服务。这里不再写出启动过程。假设，优先级高的客户机在qemu命令行启动时加上了“-name high_prio”参数来指定其名称，而优先级低的客户机用“-name low_prio”参数。在它们启动时为它们取不同的名称，仅仅是为了在后面的操作中方便区别两个客户机。
2）在blkio的层级下，创建高优先级和低优先级两个群组。命令行操作如下：

[root@kvm-host ~]# cd /sys/fs/cgroup/blkio[root@kvm-host blkio]# mkdir high_prio[root@kvm-host blkio]# mkdir low_prio [root@kvm-host blkio]# ls -l high_prio/total 0-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_merged-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_merged_recursive-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_queued-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_queued_recursive-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_service_bytes-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_service_bytes_recursive-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_serviced-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_serviced_recursive-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_service_time-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_service_time_recursive-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_wait_time-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.io_wait_time_recursive-rw-r--r-- 1 root root 0 Mar 12 15:22 blkio.leaf_weight-rw-r--r-- 1 root root 0 Mar 12 15:22 blkio.leaf_weight_device--w------- 1 root root 0 Mar 12 15:22 blkio.reset_stats-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.sectors-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.sectors_recursive-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.throttle.io_service_bytes-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.throttle.io_serviced-rw-r--r-- 1 root root 0 Mar 12 15:22 blkio.throttle.read_bps_device-rw-r--r-- 1 root root 0 Mar 12 15:22 blkio.throttle.read_iops_device-rw-r--r-- 1 root root 0 Mar 12 15:22 blkio.throttle.write_bps_device-rw-r--r-- 1 root root 0 Mar 12 15:22 blkio.throttle.write_iops_device-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.time-r--r--r-- 1 root root 0 Mar 12 15:22 blkio.time_recursive-rw-r--r-- 1 root root 0 Mar 12 15:22 blkio.weight-rw-r--r-- 1 root root 0 Mar 12 15:22 blkio.weight_device-rw-r--r-- 1 root root 0 Mar 12 15:22 cgroup.clone_children--w--w--w- 1 root root 0 Mar 12 15:22 cgroup.event_control-rw-r--r-- 1 root root 0 Mar 12 15:22 cgroup.procs-rw-r--r-- 1 root root 0 Mar 12 15:22 notify_on_release-rw-r--r-- 1 root root 0 Mar 12 15:22 tasks[root@kvm-host blkio]# cat high_prio/tasks

刚创建好的时候，以high_prio为例，它这个cgroups里面没有task。
3）分别将高优先级和低优先级的客户机的QEMU进程（及其子进程、子线程）的tgid移动到相应的控制群组下面。下面以高优先级客户机为例，低优先级客户机类似处理。

[root@kvm-host ~]# ps -eLf | grep " high_prio"root      89477   6270  89477  0    6 15:17 pts/1    00:00:04 qemu-system-x86_64 -enable-kvm -cpu host -smp 4 -m 8G -drive file=./rhel7.img,format=raw,if=virtio -device virtio-net-pci,netdev=nic0,mac=52:54:00:12:45:78 -netdev bridge,id=nic0,br=virbr0 -snapshot -name high_prioroot      89477   6270  89478  0    6 15:17 pts/1    00:00:00 qemu-system-x86_64 -enable-kvm -cpu host -smp 4 -m 8G -drive file=./rhel7.img,format=raw,if=virtio -device virtio-net-pci,netdev=nic0,mac=52:54:00:12:45:78 -netdev bridge,id=nic0,br=virbr0 -snapshot -name high_prioroot      89477   6270  89485  1    6 15:17 pts/1    00:00:14 qemu-system-x86_64 -enable-kvm -cpu host -smp 4 -m 8G -drive file=./rhel7.img,format=raw,if=virtio -device virtio-net-pci,netdev=nic0,mac=52:54:00:12:45:78 -netdev bridge,id=nic0,br=virbr0 -snapshot -name high_prioroot      89477   6270  89486  1    6 15:17 pts/1    00:00:13 qemu-system-x86_64 -enable-kvm -cpu host -smp 4 -m 8G -drive file=./rhel7.img,format=raw,if=virtio -device virtio-net-pci,netdev=nic0,mac=52:54:00:12:45:78 -netdev bridge,id=nic0,br=virbr0 -snapshot -name high_prioroot      89477   6270  89487  0    6 15:17 pts/1    00:00:09 qemu-system-x86_64 -enable-kvm -cpu host -smp 4 -m 8G -drive file=./rhel7.img,format=raw,if=virtio -device virtio-net-pci,netdev=nic0,mac=52:54:00:12:45:78 -netdev bridge,id=nic0,br=virbr0 -snapshot -name high_prioroot      89477   6270  89488  1    6 15:17 pts/1    00:00:11 qemu-system-x86_64 -enable-kvm -cpu host -smp 4 -m 8G -drive file=./rhel7.img,format=raw,if=virtio -device virtio-net-pci,netdev=nic0,mac=52:54:00:12:45:78 -netdev bridge,id=nic0,br=virbr0 -snapshot -name high_prioroot      91337  44121  91337  0    1 15:35 pts/4    00:00:00 grep --color=auto  high_prio[root@kvm-host blkio]# echo 89477 > high_prio/cgroup.procs

将控制群组正常分组后，分别查看high_prio和low_prio两个控制群组中的任务，命令行如下。其中，89477是高优先级客户机qemu的进程ID（也是这个进程组的tgid），89478、89485、89486等都是ID为89477进程的子线程的ID。低优先级客户机对应的low_prio群组中的信息也与此类似。

[root@kvm-host blkio]# cat high_prio/tasks 894778947889485894868948789488[root@kvm-host blkio]# cat low_prio/tasks 89563895648957189572895738957491766

4）分别设置高低优先级的控制群组中块设备I/O访问的权重。这里假设高低优先级的比例为10∶1。设置权重的命令行如下：

[root@kvm-host blkio]# echo 1000 > high_prio/blkio.weight[root@kvm-host blkio]# echo 100 > low_prio/blkio.weight

顺便提一下，“blkio.weight”是在一个控制群组中设置块设备I/O访问相对比例（即权重）的参数，其取值范围是100~1000的整数。
5）块设备I/O访问控制的效果分析。假设宿主机系统中磁盘I/O访问的最大值是每秒写入66 MB，除客户机的QEMU进程之外的其他所有进程的磁盘I/O访问可以忽略不计，那么在未设置两个客户机的块设备I/O访问权重之前，在满负载的情况下，高优先级和低优先级的客户机对实际磁盘的写入速度会同时达到约33 MB/s。而在通过10∶1的比例设置了它们的权重之后，高优先级客户机对磁盘的写入速度可以达到约60 MB/s，而低优先级的客户机可达到约6 MB/s。
在KVM虚拟化环境中，通过使用cgroups，系统管理员可以对客户机进行细粒度的控制，包括资源分配、优先级调整、拒绝某个资源的访问、监控系统资源利用率。硬件资源可以根据不同的客户机进行“智能”的分组，从整体上提高了资源利用效率，从某种角度来说，也可以提高各个客户机之间的资源隔离性，从而提升KVM虚拟机的安全性。
9.2.3　SELinux和sVirt
1.SELinux简介
SELinux（Security-Enhanced Linux）是一个Linux内核的一个安全特性，通过使用Linux内核中的Linux安全模块（Linux Security Modules，LSM），它提供一种机制来支持访问控制的安全策略，如美国国防部风格的强制访问控制（Mandatory Access Controls，MAC）。简单地说，SELinux提供了一种安全访问机制的体系，在该体系中进程只能访问其任务中所需要的那些文件。SELinux中的许多概念是来自美国国家安全局（National Security Agency，NSA）的一些早期项目。SELinu特性是从2003年发布Linux内核2.6版本开始进入内核主干开发树中的。在一些Linux发型版中，可以通过使用SELinux配置的内核和在用户空间的管理工具来使用SELinux，目前RHEL、Fedora、CentOS、OpenSuse、SLES、Ubuntu等发行版中都提供对SELinux的支持。
使用SELinux可以减轻恶意攻击、恶意软件等带来的灾难损失，并提供对机密性、完整性有较高要求的信息的安全保障。普通的Linux和传统的UNIX操作系统一样，在资源访问控制上采用自由访问控制（Discretionary Access Controls，DAC）策略，只要符合规定的权限（如文件的所有者和文件属性等），就可以访问资源。在这种传统的安全机制下，一些通过setuid或setgid的程序就可能产生安全隐患，甚至有些错误的配置可能引发很大的安全漏洞，让系统处于脆弱的、容易被攻击的状态。而SELinux是基于强制访问控制（MAC）策略的，应用程序或用户必须同时满足传统的DAC和SELinux的MAC访问控制，才能进行资源的访问操作，否则会被拒绝或返回失败。但这个过程不影响其他的应用程序，从而保持了系统的安全性。

强制访问控制（MAC）模式为每一个应用程序都提供了一个虚拟“沙箱”，只允许应用程序执行它设计需要的且在安全策略中明确允许的任务，对每个应用程序只分配它正常工作所需的对应特权。例如，Web服务器可能只能读取网站发布目录中的文件，并监听指定的网络端口。即使攻击者将其攻破，他们也无法执行在安全策略中没有明确允许的任何活动，即使这个进程在超级用户（root）下运行也不行。传统Linux的权限控制仍然会在系统中存在，并且当文件被访问时，此权限控制将先于SELinux安全策略生效。如果传统的权限控制拒绝本次访问，则该访问直接被拒绝，在整个过程无须SELinux参与。但是，如果传统Linux权限允许访问，SELinux此时将进一步对其进行访问控制检查，并根据其源进程和目标对象的安全上下文来判断允许本次访问还是拒绝访问。
2.sVirt简介
在非虚拟化环境中，每台服务器都是物理硬件上隔离的，一般通过网络来进行相互的通信。如果一台服务器被攻击了，一般只会使该服务器不能正常工作，当然针对网络的攻击也可能影响其他服务器。在KVM这样的虚拟化环境中，有多个客户机服务器运行在一个宿主机上，它们使用相同的物理硬件，如果一个客户机被攻击了，攻击者可能会利用被攻陷的服务器发起对宿主机的攻击，如果Hypervisor有bug，则可能会让攻击很容易地从一个客户机蔓延到其他客户机上。
在传统的文件权限管理中，一般是将用户分为所有者（owner）、与所有者相同的用户组（group）和其他用户（others）。在虚拟化应用中，如果使用一个用户账号启动了多个客户机，那么当其中一个客户机QEMU进程有异常行为时，若它对其他客户机的镜像文件有读写权限，可能会让其他客户机也暴露在不安全的环境中。当然可以使一个客户机对应一个用户账号，使用多个账号来分别启动多个不同的客户机，以便使客户机镜像访问权限隔离，而当一个宿主机中有多达数十个客户机时，就需要对应数十个用户账号，这样管理和使用起来都会非常不方便。
sVirt是Redhat公司开发的针对虚拟化环境的一种安全技术，它主要集成了SELinux和虚拟化。sVirt通过对虚拟化客户机使用强制访问控制来提高安全性，它可以阻止因为Hypervisor的bug而导致的从一台客户机向宿主机或其他客户机的攻击。sVirt让客户机之间相互隔离得比较彻底，而且即使某个客户机被攻陷了，也能够限制它发起进一步攻击的能力。
sVirt还是通过SELinux来起作用的，图9-4展示了sVirt阻止来自一个客户机的攻击。

图9-4　宿主机中的sVirt（SELinux）阻止来自客户机的攻击
sVirt框架允许将客户机及其资源都打上唯一的标签，如QEMU进程有一个标签（tag1），其对应的客户机镜像也使用这个标签（tag1），而其他客户机的标签不能与这个标签（tag1）重复。一旦被打上标签，就可以很方便地应用规则来拒绝不同客户机之间的访问，SELinux可以控制仅允许标签相同的QEMU进程访问某个客户机镜像。
3.SELinux和sVirt的配置和操作示例
由于Redhat公司是SELinux的主要开发者之一，更是sVirt最主要的开发者和支持者，因此SELinux和sVirt在Redhat公司支持的系统中使用得最为广泛，RHEL、Fedora的较新的版本都有对sVirt的支持。因为sVirt是以SELinux为基础，并通过SELinux来真正实现访问控制，所以本节以RHEL 7.3系统为例，介绍sVirt的配置和使用也完全与SELinux相关。
（1）SELinux相关的内核配置
查看RHEL 7.3系统内核配中SELinux相关的内容，命令行如下：

[root@kvm-host ~]# grep -i selinux /boot/config-3.10.0-514.el7.x86_64 CONFIG_SECURITY_SELINUX=yCONFIG_SECURITY_SELINUX_BOOTPARAM=yCONFIG_SECURITY_SELINUX_BOOTPARAM_VALUE=1CONFIG_SECURITY_SELINUX_DISABLE=yCONFIG_SECURITY_SELINUX_DEVELOP=yCONFIG_SECURITY_SELINUX_AVC_STATS=yCONFIG_SECURITY_SELINUX_CHECKREQPROT_VALUE=1# CONFIG_SECURITY_SELINUX_POLICYDB_VERSION_MAX is not setCONFIG_DEFAULT_SECURITY_SELINUX=yCONFIG_DEFAULT_SECURITY="selinux"

这里的“CONFIG_SECURITY_SELINUX_BOOTPARAM_VALUE=1”表示在内核启动时默认开启SELinux。也可以在Grub引导程序的内核启动行中添加“selinux=”参数来修改内核启动时的SELinux状态：“selinux=0”参数表示在内核启动时关闭SELinux，“selinux=1”参数表示在内核启动时开启SELinux。
（2）SELinux和sVirt相关的软件包
RHEL 7.3中用rpm命令查询与SELinux、sVirt相关的主要软件包，命令行如下：

[root@kvm-host ~]# rpm -qa | grep selinuxlibselinux-python-2.5-6.el7.x86_64libselinux-2.5-6.el7.x86_64libselinux-devel-2.5-6.el7.x86_64selinux-policy-3.13.1-102.el7.noarchselinux-policy-targeted-3.13.1-102.el7.noarchlibselinux-utils-2.5-6.el7.x86_64[root@kvm-host ~]# rpm -q policycoreutilspolicycoreutils-2.5-8.el7.x86_64

其中，最重要的就是libselinux、selinux-policy、selinux-policy-targeted这3个RPM包，它们提供了SELinux在用户空间的库文件和安全策略配置文件。而libselinux-utils RPM包则提供了设置和管理SELinux的一些工具，如getenforce、setenforce等命令行工具。policycoreutils RPM包提供了一些查询和设置SELinux策略的工具，如setfiles、fixfiles、sestatus、setsebool等命令行工具。另外，因为RHEL中SELinux和sVirt的安全策略是根据libvirt来配置的，所以一般也需要安装libvirt软件包，这样才能更好地发挥sVirt保护虚拟化安全的作用。
（3）SELinux和sVirt的配置文件
SELinux和sVirt的配置文件一般都在/etc/selinux目录之中，如下：

[root@kvm-host ~]# ls /etc/selinux/config  final  semanage.conf  targeted  tmp[root@kvm-host ~]# ls -l /etc/selinux/config -rw-r--r--. 1 root root 546 Sep 26 19:14 /etc/selinux/config

其中最重要的配置文件是“/etc/selinux/config”文件，在该配置文件中修改设置之后需要重启系统才能生效。该配置文件的一个示例如下：

# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:#     enforcing - SELinux security policy is enforced.#     permissive - SELinux prints warnings instead of enforcing.#     disabled - No SELinux policy is loaded.SELINUX=enforcing# SELINUXTYPE= can take one of these two values:#     targeted - Targeted processes are protected,#     mls - Multi Level Security protection.SELINUXTYPE=targeted

其中“SELINUX=”项用于设置SELinux的状态，有3个值可选：“enforcing”是生效状态，它会禁止违反规则策略的行为；“permissive”是较为宽松的状态，它会在发现违反SELinux策略的行为时发出警告（而不是阻止该行为），管理员在看到警告后可以考虑是否修改该策略来满足目前的安全需求；“disabled”是关闭状态，任何SELinux策略都不会生效。
“SELINUXTYPE=”项用于设置SELinux的策略，有两个值可选：一个是目标进程保护策略（targeted），另一个是多级安全保护策略（mls）。目标进程保护策略仅针对部分已经定义为目标的系统服务和进程执行SELinux策略，会执行“/etc/selinux/targeted”目录中各个具体策略；而多级安全保护策略是严格分层级定义的安全策略。一般来说，选择其默认的“targeted”目标进程保护策略即可。
SELinux的状态和策略的类型决定了SELinux工作的行为和方式，而具体策略决定具体的进程访问文件时的安全细节。在目标进程工作模式（targeted）下，具体的策略配置在“/etc/selinux/targeted”目录中详细定义。执行如下命令行可查找与sVirt直接相关的配置文件：

[root@kvm-host targeted]# pwd/etc/selinux/targeted [root@kvm-host targeted]# grep -i svirt * -ractive/file_contexts:/var/lib/kubelet(/.*)?   system_u:object_r:svirt_sandbox_file_t:s0active/file_contexts:/var/lib/docker/vfs(/.*)?   system_u:object_r:svirt_sandbox_file_t:s0active/homedir_template:HOME_DIR/\.libvirt/qemu(/.*)?   system_u:object_r:svirt_home_t:s0<!-- 此处省略几十行输出信息 -->Binary file policy/policy.30 matches

“virtual_domain_context”文件配置了客户机的标签，而“virtual_image_context”文件配置了客户机镜像的标签，“customizable_types”中增加了“svirt_image_t”这个自定义类型。
（4）SELinux相关的命令行工具
在RHEL 7.3中，命令行查询和管理SELinux的工具主要是由“libselinux-utils”和“policycoreutils”这两个RPM包提供的。其中部分命令行工具的使用示例如下：

[root@kvm-host ~]# getenforce Enforcing[root@kvm-host ~]# sestatus SELinux status:                 enabledSELinuxfs mount:                /sys/fs/selinuxSELinux root directory:         /etc/selinuxLoaded policy name:             targetedCurrent mode:                   enforcingMode from config file:          enforcingPolicy MLS status:              enabledPolicy deny_unknown status:     allowedMax kernel policy version:      28 [root@kvm-host ~]# getsebool -a | grep httpdhttpd_anon_write --> offhttpd_builtin_scripting --> onhttpd_can_check_spam --> offhttpd_can_connect_ftp --> offhttpd_can_connect_ldap --> offhttpd_can_connect_mythtv --> offhttpd_can_connect_zabbix --> offhttpd_can_network_connect --> offhttpd_can_network_connect_cobbler --> offhttpd_can_network_connect_db --> off <!-- 省略其他输出信息 -->[root@kvm-host ~]# setsebool httpd_enable_homedirs on [root@kvm-host ~]# getsebool -a | grep httpd_enable_homedirshttpd_enable_homedirs --> on [root@kvm-host ~]# mkdir html[root@kvm-host ~]# ll -Z | grep htmldrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 html [root@kvm-host ~]# chcon -R -t httpd_sys_content_t /root/html[root@kvm-host ~]# ll -Z | grep htmldrwxr-xr-x. root root unconfined_u:object_r:httpd_sys_content_t:s0 html

下面对这几个命令进行简单介绍。
·setenforce：修改SELinux的运行模式，其语法为setenforce[Enforcing|Permissive|1|0]，设置为1或Enforcing就是让其处于生效状态，设置为0或Permissive是让其处于宽松状态（不阻止违反SELinux策略的行为，只是给一个警告提示）。
·getenforce：查询获得SELinux当前的状态，可以是生效（Enforcing）、宽松（Per-missive）和关闭（Disabled）3个状态。
·sestatus：获取运行SELinux系统的状态，通过此命令获取的SELinux信息更加详细。
·getsebool：获取当前SELinux策略中各个配置项的布尔值，每个布尔值有开启（on）和关闭（off）两个状态。
·setsebool：设置SELinux策略中配置项的布尔值。
·chcon：改变文件或目录的SELinux安全上下文，“-t[type]”参数是设置目标安全上下文的类型（TYPE），“-R”参数表示递归地更改目录中所有子目录和文件的安全上下文。另外，“-u[user]”参数更改安全上下文中的用户（User），“-r[role]”参数更改安全上下文中的角色（Role）。
（5）查看SELinux的安全上下文
在SELinux启动后，所有文件和目录都有各自的安全上下文，进程的安全上下文是域（domain）。关于安全上下文，一般遵守如下几个规则。
1）系统根据Linux-PAM（可插拔认证模块，Pluggable Authentication Modules）子系统中的pam_selinux.so模块来设定登录者运行程序的安全上下文。
2）RPM包安装时会根据RPM包内现有的记录来生成安全上下文。
3）手动创建的一个文件或者目录，会根据安全策略中的规则来设置其安全上下文。
4）如果复制文件或目录（用cp命令），会重新生成安全上下文。
5）如果移动文件或目录（用mv命令），其安全上下文保持不变。
安全上下文由用户（User）ID、角色（Role）、类型（Type）3部分组成，这里的用户和角色与普通系统概念中的用户名和用户分组是没有直接关系的。
·用户ID（user）。与Linux系统中的UID类似，提供身份识别的功能，例如：user_u表示普通用户；system_u表示开机过程中系统进程的预设值；root表示超级用户root登录后的预设；unconfined_u为不限制的用户。在默认的目标（targeted）工作模式下，用户ID的设置并不重要。
·角色（role）。普通文件和目录的角色通常是object_r；用户可以具有多个角色，但是在同一时间内只能使用一角色；用户的角色类似于普通系统中的GID（用户组ID），不同的角色具备不同的权限。在默认的目标工作模式下，用户角色的设置也不重要。
·类型（type）。将主体（程序）与客体（程序访问的文件）划分为不同的组，一个组内的各个主体和系统中的客体都定义了一个类型。类型是安全上下文中最重要的值，一般来说，一个主体程序能不能读取到这个文件资源，与类型这一栏的值有关。类型有时会有两个名称：在文件资源（Object）上称为类型（Type）；而在主体程序（Subject）上称为域（Domain）。只有域与类型匹配，一个程序才能正常访问一个文件资源。
·层级（level）。这是多层级安全（MLS）和多类别安全（MCS）的概念。表示为类似s0：c0-c1023的形式。一个层级可以对应1024个具体类别。
一般来说，有3种安全上下文：账号的安全上下文；进程的安全上下文；文件或目录的安全上下文。可以分别用“id-Z”“ps-Z”“ls-Z”等命令进行查看。示例如下：

[root@kvm-host ~]# id -Zunconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023[root@kvm-host ~]# ps -eZ | grep httpdsystem_u:system_r:httpd_t:s0      3389 ?        00:00:00 httpdsystem_u:system_r:httpd_t:s0      3794 ?        00:00:00 httpdsystem_u:system_r:httpd_t:s0      3795 ?        00:00:00 httpdsystem_u:system_r:httpd_t:s0      3796 ?        00:00:00 httpdsystem_u:system_r:httpd_t:s0      3797 ?        00:00:00 httpdsystem_u:system_r:httpd_t:s0      3798 ?        00:00:00 httpd[root@kvm-host ~]# ls -Z /var/www/drwxr-xr-x. root root system_u:object_r:httpd_sys_script_exec_t:s0 cgi-bindrwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 html

另外，chcon命令行工具可以改变文件或目录的SELinux安全上下文内容，对该工具的介绍和使用示例已经在本节前面部分提及了。
（6）sVirt提供的与虚拟化相关的标签
sVirt使用基于进程的机制和约束，为虚拟化客户机提供了一个额外的安全保护层。在一般情况下，只要不违反约束的策略规则，用户是不会感知到sVirt在后台运行的。sVirt和SELinux将客户机用到的资源打上标签，也对相应的QEMU进程打上标签，然后保证只允许具有与被访问资源相对应的类型（type）和相同分类标签的QEMU进程访问某个磁盘镜像文件或其他存储资源。如果有违反策略规则的进程试图非法访问资源，SELinux会直接拒绝它的访问操作，返回一个权限不足的错误提示（通常为“Permission denied”）。
sVirt将SELinux与QEMU/KVM虚拟化进行了结合。sVirt一般的工作方式是：在RHEL系统中使用libvirt的守护进程（libvirtd）在后台管理客户机，在启动客户机之前，libvirt动态选择一个带有两个分类标志的随机的MCS标签（如s0：c1，c2），将该客户机使用到的所有存储资源（包括磁盘镜像、光盘等）都打上相应的标签（svirt_image_t：s0：c1，c2），然后用该标签（svirt_t：c0：c1，c2）执行qemu-kvm进程，从而启动了客户机。
在客户机启动之前，查看一些关键的程序和磁盘镜像的安全上下文。示例如下：

# 依次查看libvirtd、virsh、qemu的安全上下文。[root@kvm-host ~]# ls -Z /usr/sbin/libvirtd-rwxr-xr-x. root root system_u:object_r:virtd_exec_t:s0 /usr/sbin/libvirtd [root@kvm-host ~]# ls -Z /usr/bin/virsh-rwxr-xr-x. root root system_u:object_r:virsh_exec_t:s0 /usr/bin/virsh [root@kvm-host ~]# ls -Z /usr/libexec/qemu-kvm -rwxr-xr-x. root root system_u:object_r:qemu_exec_t:s0 /usr/libexec/qemu-kvm # 查看libvirt创建的客户机镜像的安全上下文。[root@kvm-host ~]# ll -Z *.img-rw-------. root root system_u:object_r:admin_home_t:s0 ia32e_rhel7u3_kvm-clone.img-rw-r--r--. root root system_u:object_r:admin_home_t:s0 ia32e_rhel7u3_kvm.img-rw-r--r--. root root system_u:object_r:admin_home_t:s0 raw_disk.img-rw-r--r--. root root system_u:object_r:admin_home_t:s0 rhel7.img

可以看到，由libvirt创建管理的客户机镜像与其他客户机镜像的安全上下文是一样的（system_u：object_r：admin_home_t：s0）。
然后分别使用上面ia32e_rhel7u3_kvm.img和ia32e_rhel7u3_kvm-clone.img两个磁盘镜像，用libvirt的命令行或者virt-manager图形界面工具启动两个客户机。在客户机启动后，查看磁盘镜像和qemu-kvm进程的安全上下文。命令行如下：

[root@kvm-host ~]# ll -Z *.img-rw-------. qemu qemu system_u:object_r:svirt_image_t:s0:c570,c648 ia32e_rhel7u3_kvm-clone.img-rw-r--r--. qemu qemu system_u:object_r:svirt_image_t:s0:c208,c224 ia32e_rhel7u3_kvm.img-rw-r--r--. root root system_u:object_r:admin_home_t:s0 raw_disk.img-rw-r--r--. root root system_u:object_r:admin_home_t:s0 rhel7.img[root@kvm-host ~]# ps -eZ | grep qemusystem_u:system_r:svirt_t:s0:c208,c224 87761 ?  00:00:18 qemu-kvmsystem_u:system_r:svirt_t:s0:c570,c648 87775 ?  00:00:17 qemu-kvm

由上面的输出信息可知，两个磁盘镜像已经被动态地标记上了不同的标签，两个相应的qemu-kvm进程也被标记上了对应的标签。其中，PID为87761的qemu-kvm进程对应的是ia32e_rhel7u3_kvm.img这个磁盘镜像，由于SELinux和sVirt的配合使用，即使87761 qemu-kvm进程对应的客户机被黑客入侵，其qemu-kvm进程（PID 87761）也无法访问非它自己所有的ia32e_rhel7u3_kvm-clone.img这个镜像文件，也就不会攻击到其他客户机（当然，通过网络发起的攻击除外）。
（7）sVirt根据标签阻止不安全访问的示例
前面已经提及，如果进程与资源的类型和标签不匹配，那么进程对该资源的访问将会被拒绝。真的这么有效吗？下面，笔者通过示例来证明它的有效性：模拟一些不安全的访问，然后查看sVirt和SELinux是否将其阻止。
首先，将bash这个Shell程序复制一份，并将其重命名为svirt-bash，以“svirt_t”类型和“s0：c1，c2”标签执行svirt-bash程序，进入这个Shell环境，用“id-Z”命令查看当前用户的安全上下文。然后创建/tmp/svirt-test.txt这个文件，并写入一些文字，可以看到该文件的安全上下文中类型和标签分别是：svirt_tmp_t和s0：c1，c2。该过程的命令行操作如下（包括部分命令行的注释）：

```
# 复制一个Shell，重命名为/bin/svirt-bash[root@kvm-host ~]# cp /bin/bash /bin/svirt-bash # 默认策略规定，使用svirt_t类型的入口程序必须标记为“qemu_exec_t”#类型，与/usr/libexec/qemu-kvm 文件的安全上下文类似[root@kvm-host ~]# chcon -t qemu_exec_t /bin/svirt-bash # runcon命令以某个特定的SELinux安全上下文来执行某个命令[root@kvm-host ~]# runcon -t svirt_t -l s0:c1,c2 /bin/svirt-bash svirt-bash: /root/.bashrc: Permission denied   #由于类型改变后无法读取.bashrc配置文件，对本次实验无影响，忽略该错误提示# 已经进入使用svirt_t:s0:c1,c2 这样的安全上下文的Shell环境中了svirt-bash-4.2# id -Zunconfined_u:unconfined_r:svirt_t:s0:c1,c2 # 可能会遇到“svirt: child setpgid (89383 to 89383): Permission denied”这样的错误提示# Shell试图为每个命令都设置进程的组ID（setpgid），对本次实验无影响# 在本次实验中忽略setpgid带来的错误提示svirt-bash-4.2# echo "just for testing" >> /tmp/svirt-test.txtsvirt-bash-4.2# ls -Z /tmp/svirt-test.txt -rw-r--r--. root root unconfined_u:object_r:svirt_tmp_t:s0 /tmp/svirt-test.txt # 在另一个shell中，将svirt-test.txt文件设置为层级s0:c1,c2[root@kvm-host ~]# chcon -l s0:c1,c2 /tmp/svirt-test.txt# 在svirt-bash中查看更新过安全上下文的svirt-test.txt文件，并尝试访问svirt-bash-4.2# ls -l /tmp/svirt-test.txt -Z-rw-r--r--. root root unconfined_u:object_r:svirt_tmp_t:s0:c1,c2 /tmp/svirt-test.txtsvirt-bash-4.2# cat /tmp/svirt-test.txt just for testing
```

使用“svirt_t”类型和“s0：c1，c3”（与前面“s0：c1，c2”不同）标签启动svirt-bash这个Shell程序，进到该Shell环境，用“id-Z”命令查看当前用户的安全上下文，用“ls-Z”查看上一步创建的临时测试文件的安全上下文，试着用“cat”命令去读取该测试文件（svirt-test.txt）。该过程的命令行操作如下：

```
[root@kvm-host ~]# runcon -t svirt_t -l s0:c1,c3 /bin/svirt-bashsvirt-bash: /root/.bashrc: Permission deniedsvirt-bash-4.2#svirt-bash-4.2# id -Zunconfined_u:unconfined_r:svirt_t:s0:c1,c3 svirt-bash-4.2# ls -Z /tmp/svirt-test.txt -rw-r--r--. root root unconfined_u:object_r:svirt_tmp_t:s0:c1,c2 /tmp/svirt-test.txt# 在“s0:c1,c3”的标签下，测试文件读取访问被拒绝svirt-bash-4.2# cat /tmp/svirt-test.txt cat: /tmp/svirt-test.txt: Permission denied
```

可知，在标签为“s0：c1，c3”的Shell环境中，不能访问具有“s0：c1，c2”标签的一个临时测试文件，sVirt拒绝本次非法访问，故sVirt基于标签的安全访问控制策略是生效的。
在使用Redhat相关系统（如RHEL、Fedora等）时，如果对KVM虚拟化安全性要求较高，可以选择安装SELinux和sVirt相关的软件包，使用sVirt来加强虚拟化中的安全性。不过，由于SELinux配置还是比较复杂的，其默认策略对其他各种服务的资源访问限制还是较多的（为了安全性），所以受到一些系统管理员的排斥，一些系统管理员经常会关闭SELinux。总之，一切从实际出发，应根据实际项目中对安全性的需求对SELinux和sVirt进行相应的配置。
9.2.4　其他安全策略
1.镜像文件加密
随着网络与计算机技术的发展，数据的一致性和数据的完整性在信息安全中变得越来越重要，对数据进行加密处理对数据的一致性和完整性都有较好的保障。有一种类型的攻击叫作“离线攻击”，如果攻击者在系统关机状态下可以物理接触到磁盘或其他存储介质，就属于“离线攻击”的一种表现形式。假设，在一个公司内部，不同职位的人有不同的职责和权限，系统处于启动状态时的使用者是工作人员A，而系统关机后会存放在另外的位置（或不同部门），而工作人员B可以获得该系统的物理硬件。如果没有保护措施，那么B就可以轻易地越权获得系统中的内容。如果有了良好的加密保护，就可以防止这样的攻击或内部数据泄露事件的发生。
在KVM虚拟化环境中，存放客户机镜像的存储设备（如磁盘、U盘等）可以对整个设备进行加密，如果其分区是LVM，也可以对某个分区进行加密。而对于客户机镜像文件本身，也可以进行加密的处理，如5.4.3节中已经介绍过qcow2镜像文件格式支持加密，这里再简单介绍一下。
“qemu-img convert”命令在“-o encryption”参数的支持下，可以将未加密或已经加密的镜像文件转化为加密的qcow2的文件格式。先创建一个8 GB大小的qcow2格式镜像文件，然后用“qemu-img convert”命令将其加密。命令行操作如下：

[root@kvm-host ~]# qemu-img create -f qcow2 -o size=8G  guest.qcow2Formatting 'guest.qcow2', fmt=qcow2 size=8589934592 encryption=off cluster_size=65536 lazy_refcounts=off refcount_bits=16     [root@kvm-host ~]# qemu-img convert -o encryption -O qcow2 guest.qcow2 encrypted.qcow2Disk image 'encrypted.qcow2' is encrypted.password: ******  #此处输入你需要设置的密码，然后按回车键确认

生成的encrypted.qcow2文件就是已经加密的文件。查看其信息如下所示，可以看到“encrypted：yes”的标志。

[root@kvm-host ~]# qemu-img info encrypted.qcow2image: encrypted.qcow2file format: qcow2virtual size: 8.0G (8589934592 bytes)disk size: 196Kencrypted: yescluster_size: 65536Format specific information:    compat: 1.1    lazy refcounts: false    refcount bits: 16    corrupt: false

在使用加密的qcow2格式的镜像文件启动客户机时，客户机会先不启动而暂停，需要在QEMU monitor中输入“cont”或“c”命令以便继续执行，然后会要求输入已加密qcow2镜像文件的密码，只有密码输入正确才可以正常启动客户机。在QEMU monitor中的命令行示例如下：

(qemu) cide0-hd0 (encryped.qcow2) is encrypted.Password: ******       #此处输入先前设置过的密码(qemu)

当然，在执行“qemu-img create”创建镜像文件时就可以将其创建为加密的qcow2文件格式，但是不能交互式地指定密码。命令行如下：

[root@kvm-host ~]# qemu-img create -f qcow2 -o backing_file=./rhel7.img,encryption encrypted.qcow2Formatting 'encrypted.qcow2', fmt=qcow2 size=42949672960 backing_file=./rhel7.img encryption=on cluster_size=65536 lazy_refcounts=off refcount_bits=16

这样创建的qcow2文件处于加密状态，但是其密码为空，在使用过程中提示输入密码时，直接按回车键即可。对于在创建时已设置为加密状态的qcow2文件，仍然需要用上面介绍过的“qemu-img convert”命令来转换一次，这样才能设置为自己所需的非空密码。
当使用qcow2镜像文件的加密功能时，每次都要输入密码，可能会给大规模地自动化部署KVM客户机带来一定的障碍。其实，输入密码验证的问题也是很容易解决的，例如Linux上的expect工具就很容易解决需要输入密码这样的交互式会话问题。在使用expect进行ssh远程登录过程中，输入密码交互的一段Bash脚本如下：

SSH_Time_Out() {    local host=192.168.111.111local time_out=250local command="ifconfig"    local exp_cmd=$(cat << EOFspawn ssh root@$host $commandset timeout $time_outexpect {    "*assword:"  { send "123456\r"; exp_continue}    "*(yes/no)?" { send "yes\r"; exp_continue }    eof          { exit 0 }}EOF)    expect -c "$exp_cmd"    return $?}

上面的脚本示例实现了用ssh远程登录到一台主机上，并执行了一个ifconfig命令。其中远程主机的root用户的密码是通过expect的脚本来实现自动输入的，expect的超时时间在这里被设置为250秒。
2.虚拟网络的安全
在KVM宿主机中，为了网络安全的目的，可以使用Linux防火墙——iptables工具。使用iptables工具（为IPv4协议）或ip6tables（为IPv6协议），可以创建、维护和检查Linux内核中IP数据报的过滤规则。
而对于客户机的网络，QEMU/KVM提供了多种网络配置方式（见5.5节）。例如：使用NAT方式让客户机获取网络，就可以对外界隐藏客户机内部网络的细节，对客户机网络的安全起到了保护作用。不过，在默认情况下，NAT方式的网络让客户机可以访问外部网络，而外部网络不能直接访问客户机。如果客户机中的服务需要被外部网络直接访问，就需要在宿主机中配置好iptables的端口映射规则，通过宿主机的某个端口映射到客户机的一个对应端口，其具体配置的示例已经在5.5.3节中详细介绍了。
如果物理网卡设备比较充足，而且CPU、芯片组、主板等都支持设备的直接分配技术（如Intel VT-d技术），那么选择使用设备直接分配技术（VT-d）为每个客户机分配一个物理网卡也是一个非常不错的选择。因为在使用设备直接分配使用网卡时，网卡工作效率非常高，而且各个客户机中的网卡在物理上是完全隔离的，提高了客户机的隔离性和安全性，即使一个客户机中网络流量很大（导致了阻塞）也不会影响其他客户机中网络的质量。关于网卡设备的直接分配，可以参考6.2.4节中的详细配置。
3.远程管理的安全
在KVM虚拟化环境中，可以通过VNC的方式远程访问客户机。为了虚拟化管理的安全性，可以为VNC连接设置密码，并且可以设置VNC连接的TLS、X.509等安全认证方式。关于VNC的配置和密码设置等相关内容，可以参考5.6.2节。
如果使用libvirt的应用程序接口来管理虚拟机，包括使用virsh、virt-manager、virt-viewer等工具，为了远程管理的安全性考虑，最好只允许管理工具使用SSH连接或者带有TLS加密验证的TCP套接字来连接到宿主机的libvirt。关于libvirt API的简介及其配置、连接的方式，可以阅读4.1节的内容。
4.普通Linux系统的安全准则
KVM宿主机及运行在KVM上Linux客户机都是普通的Linux操作系统。普通Linux系统的一些安全策略和准则都可以用于提高KVM环境的安全性。
美国国家安全局（National Security Agency，NSA）的一份公开文档中谈及了Redhat Linux系统的安全设置应遵循的几个通用原则，对于任何Linux系统（甚至Windows系统）的安全配置都有一定的借鉴意义。这里简要分享一下，仅供读者参考。
（1）对传送的数据尽可能地进行加密处理
无论是在有线网络还是无线网络上，传输的数据都很容易被监听，所以只要对这些数据的加密方案存在，都应该使用加密方案。即使是预期仅在局域网中传输的数据，也应该做加密处理。对于一些身份认证相关的数据（如密码）等的加密尤其重要。RHEL 5/6/7版本的Linux系统组成的网络中，可以配置为它们之间传输的全部数据都经过加密处理。
（2）安装尽可能少的软件，从而使软件漏洞数量尽可能的少
避免一个软件漏洞最简单的方法就是避免安装那个软件。在RHEL系统中，有RPM软件包管理工具可以比较方便地管理系统中已经安装的软件包。随意安装的软件可能会以多种方式暴露出系统的漏洞：
1）包含setuid程序的软件包可能为本地的攻击者提供一种特权扩大的潜在途径。
2）包含网络服务的软件包可能为基于网络的攻击者提供攻击的机会。
3）包含被本地用户有预期地执行的程序（如图形界面登录后必须执行的程序）的软件可能会给特洛伊木马或者其他隐藏执行的攻击代码提供机会。通常，一个系统上安装的软件包数量可以被大量删减，直到只包含环境或者操作所真正必需的软件。
（3）不同的网络服务尽量运行在不同的系统上
一个服务器（当然也可以是虚拟客户机）应该尽可能地专注于提供一个网络服务。如果这样做，即使一个攻击者成功地渗透了一个网络服务上的软件漏洞，也不会危害到其他服务的正常运行。
（4）配置一些安全工具提高系统的鲁棒性
现存的几个工具可以有效地提高系统的抵抗能力和检测未知攻击的能力。这些工具可以利用较低的配置成本去提高系统面对攻击时的鲁棒性。有一些实际的工具就具有这样的能力，如基于内核的防火墙——iptables，基于内核的安全保护软件——SELinux，以及其他一些日志记录和进程审计的软件基础设施。
（5）使用尽可能少的权限
只授予用户账号和运行的软件最少的必需的权限。例如，仅给真正需要用sudo管理员权限的用户开放sudo的功能（在Ubuntu中默认开放过多的sudo权限可能并不太安全）；限制系统的登录，仅向需要管理系统的用户开放登录的权限。另外，还可以使用SELinux来限制一个软件对系统上其他资源的访问权限，合适的SELinux策略可以让某个进程仅有权限做应该做的事情。
